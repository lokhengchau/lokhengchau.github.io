[
["index.html", "Unofficial Solutions to R for Data Science About", " Unofficial Solutions to R for Data Science Lok H. Chau About "],
["introduction.html", "1 Introduction", " 1 Introduction No exercises. "],
["introduction-1.html", "2 Introduction", " 2 Introduction No exercises. "],
["data-visualization.html", "3 Data visualization 3.1 Introduction 3.2 First steps 3.3 Aesthetic mappings 3.4 Common problems 3.5 Facets 3.6 Geometric objects 3.7 Statistical transformations 3.8 Position adjustments 3.9 Coordinate systems 3.10 The layered grammar of graphics", " 3 Data visualization 3.1 Introduction No exercises. 3.2 First steps 3.2.1 Exercises 1 - Run ggplot(data = mpg). What do you see? ggplot(data = mpg) In this case, nothing is displayed because we have specified neither the mapping and geom. 2 - How many rows are in mpg? How many columns? To get the dimensions of a data matrix, we can simply use the function ‘dim()’. dim(mpg) ## [1] 234 11 The function returns a vector of values. The first element is the number of rows and the second element is the number of columns. For mpg, we have 234 rows and 11 columns. Alternatively, we can use ‘nrow()’ and’ncol()’ to return the number of rows and columns respectively. nrow(mpg) ## [1] 234 ncol(mpg) ## [1] 11 3 - What does the drv variable describe? Read the help for ?mpg to find out. f = front-wheel drive r = rear wheel drive 4 = 4wd 4 -Make a scatterplot of hwy vs cyl. ggplot(data = mpg) + geom_point(mapping = aes(x = cyl, y = hwy)) 5 - What happens if you make a scatterplot of class vs drv? Why is the plot not useful? ggplot(data = mpg) + geom_point(mapping = aes(x = drv, y = class)) In this dataset, both class and drv are categorical variables. The only information this scatter plot reveals is what combinations of class and drv exist in the dataset. For example, there are front-wheel drive compact vehicles, but not front-wheel drive 2 seaters. 3.3 Aesthetic mappings 3.3.1 Exercises 1 - What’s gone wrong with this code? Why are the points not blue? ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, color = &quot;blue&quot;)) In order to manually change the color of every point to blue, color = &quot;blue&quot; should be placed outside the aes() argument. ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy), color = &quot;blue&quot;) 2 - Which variables in mpg are categorical? Which variables are continuous? (Hint: type ?mpg to read the documentation for the dataset). How can you see this information when you run mpg? We can type ?mpg and deduce which variables are categorical and which are continuous based on the descriptions. Or we can use str() to get the types of the variables. str(mpg) ## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 234 obs. of 11 variables: ## $ manufacturer: chr &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; ... ## $ model : chr &quot;a4&quot; &quot;a4&quot; &quot;a4&quot; &quot;a4&quot; ... ## $ displ : num 1.8 1.8 2 2 2.8 2.8 3.1 1.8 1.8 2 ... ## $ year : int 1999 1999 2008 2008 1999 1999 2008 1999 1999 2008 ... ## $ cyl : int 4 4 4 4 6 6 6 4 4 4 ... ## $ trans : chr &quot;auto(l5)&quot; &quot;manual(m5)&quot; &quot;manual(m6)&quot; &quot;auto(av)&quot; ... ## $ drv : chr &quot;f&quot; &quot;f&quot; &quot;f&quot; &quot;f&quot; ... ## $ cty : int 18 21 20 21 16 18 18 18 16 20 ... ## $ hwy : int 29 29 31 30 26 26 27 26 25 28 ... ## $ fl : chr &quot;p&quot; &quot;p&quot; &quot;p&quot; &quot;p&quot; ... ## $ class : chr &quot;compact&quot; &quot;compact&quot; &quot;compact&quot; &quot;compact&quot; ... manufacturer, model, trans, drv, fl, and class are chr variables, which also mean that they are categorical variables. 3 - Map a continuous variable to color, size, and shape. How do these aesthetics behave differently for categorical vs. continuous variables? When mapping a continuous variable, displ, to color, ggplot creats a gradient color scale to represent the values of the continous variable. By default, ggplot creates a color gradient scale from light blue to dark blue, where light blue reresents lower values and dark blue represents higher values. ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, color = displ)) Similiarly, when mapping a continuous variable to shape, ggplot displays larger values with circles with larger area. ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, size = displ)) However, ggplot with throw out an error message if we map a continuous variable to shape. 4 - What happens if you map the same variable to multiple aesthetics? We can map the same variable to multiple aesthetics, as long as the aesethetics are compatiable with the type of the variables (categorical/continuous). For example, we can map drv, which is a categorical variable, to both color and shape. ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, color = drv, shape = drv)) Here, we map a continuous variable, displ, to color and size. ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, color = displ, size = displ)) 5 - What does the stroke aesthetic do? What shapes does it work with? (Hint: use ?geom_point) stroke only works with shapes 21 - 24, which also comes with the fill argument, which controls the color of the fill. size argument controls the size of the fill part, stroke controls the size of the stroke, and color contools the color of the stroke. For example: ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy), shape = 21, fill = &#39;red&#39;, size = 4, stroke = 3, color = &#39;white&#39;) 6 - What happens if you map an aesthetic to something other than a variable name, like aes(colour = displ &lt; 5)? ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, color = displ &lt; 5)) As shown in the above scatter plots, ggplot evaluates displ &lt; 5 and creates a temporary boolean variable indicating whether the observations satisfy the specified condition, and represents TRUE and FALSE with different colors. 3.4 Common problems No exercises. 3.5 Facets 3.5.1 Exercises 1 - What happens if you facet on a continuous variable? ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_wrap(~ cty, nrow = 2) Using facet_wrap() with a continuous variable will work in general, however, it might not be as useful as faceting on a categorical variable with a few levels. The above plot shows hwy vs disp scatter plots facetted by cty. What it does is first converting the continuous variable to a factor, then displays separate plots for each unique value. ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_grid(cty ~ year) Similarly, facet_grid() works with continuous variables as well. 2 - What do the empty cells in plot with facet_grid(drv ~ cyl) mean? How do they relate to this plot? A plot with facet_grid(drv ~ cyl): ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y= hwy)) + facet_grid(drv ~ cyl) Compared with the plot below: ggplot(data = mpg) + geom_point(mapping = aes(x = drv, y = cyl)) The empty grids in facet_grid(drv ~ cyl) tell us that there are no observations in those particular combinations of cyl and drv. The above scatter plot of cyl vs drv gives us the same information. 3 - What plots does the following code make? What does . do? In facet_grid(), rows are facetted by the variable on the left hand side of ~, and columns are facetted by the variable on the right hand side of ~. A . simply means that there will be no facetting in the dimension. ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_grid(drv ~ .) facet_grid(drv ~ . ) - rows are facetted by drv, and no facetting by columns ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_grid(. ~ cyl) facet_grid(. ~ cyl) - columns are facetted by cyl, and no facetting by rows. 4 - Take the first faceted plot in this section: ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_wrap(~ class, nrow = 2) What are the advantages to using faceting instead of the colour aesthetic? What are the disadvantages? How might the balance change if you had a larger dataset? One of the advantages of using facetting instead of coloring is to avoid the possible confusion caused by having several distinct colors shown on the same plot. As the number of unique levels in the mapping categorical increases, it can be difficulty to distinguish between the differnet colors. A possible disadvantage in using facetting is that since the points are on separate plots, direct comparisons might not be as straightforward. 5 - Read ?facet_wrap. What does nrow do? What does ncol do? What other options control the layout of the individual panels? Why doesn’t facet_grid() have nrow and ncol argument? In facet_wrap(), nrow and ncol defines the number of rows and columns of the panels. facet_grid() does not have nrow and ncol since the number of rows and columns are equal to the number of unique levels in the row/column variables. 6 - When using facet_grid() you should usually put the variable with more unique levels in the columns. Why? One logical reason is that since the dependent variables are usually plotted on the y-axis, it is much easier to compare the highs and lows and the trends of the variables if the plots are placed side by side. 3.6 Geometric objects 3.6.1 Exercises 1 - What geom would you use to draw a line chart? A boxplot? A histogram? An area chart? geom_line(), geom_boxplot(), geom_histogram(), and geom_area(). 2 - Run this code in your head and predict what the output will look like. Then, run the code in R and check your predictions. ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) + geom_point() + geom_smooth(se = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; Note: Since the mapping is defined in ggplot(), it is carried over and applied to both geom_point() and geom_smooth(). 3 - What does show.legend = FALSE do? What happens if you remove it? Why do you think I used it earlier in the chapter? show.legend = FALSE hides the legned that is automatically created when we map a variable to an aesthetic, like ‘color’ or ‘size’. Since the default is TRUE, removing this argument will always result in the legend being displayed if there are variables mapped to the asethetics. The last part of the question refers to this code: ggplot(data = mpg) + geom_smooth( mapping = aes(x = displ, y = hwy, color = drv), show.legend = FALSE ) ## `geom_smooth()` using method = &#39;loess&#39; Not exactly sure why, other than intentionally hiding the legend. 4 - What does the se argument to geom_smooth() do? The se argument controls whether the confidence interval around the smooth curve is shown. The default value is TRUE and the default level of CI is .95. The level of CI can be changed via the level argument. 5 - Will these two graphs look different? Why/why not? ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point() + geom_smooth() ggplot() + geom_point(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_smooth(data = mpg, mapping = aes(x = displ, y = hwy)) The two graphs will look exactly the same. In the first code, data and mapping are both defined in ggplot() and are carried over to the geoms. In the second code, data and mapping are defined individually in each geom. 6 - Recreate the R code necessary to generate the following graphs. The codes to recreate the 6 plots are shown below. (Note - not sure about the sizes so the size argument was skipped.) ggplot(data = mpg, mapping = aes(y = hwy, x = displ)) + geom_point() + geom_smooth(se = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; ggplot(data = mpg, mapping = aes(y = hwy, x = displ)) + geom_point() + geom_smooth(mapping = aes(group = drv), se = FALSE, show.legend = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; ggplot(data = mpg, mapping = aes(y = hwy, x = displ)) + geom_point(mapping = aes(color = drv)) + geom_smooth(mapping = aes(color = drv, group = drv), se = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; ggplot(data = mpg, mapping = aes(y = hwy, x = displ)) + geom_point(mapping = aes(color = drv)) + geom_smooth(se = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; ggplot(data = mpg, mapping = aes(y = hwy, x = displ)) + geom_point(mapping = aes(color = drv)) + geom_smooth(mapping = aes(linetype = drv), se = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; ggplot(data = mpg, mapping = aes(y = hwy, x = displ)) + geom_point(mapping = aes(fill = drv), color = &#39;white&#39;, stroke = 2, shape = 21) 3.7 Statistical transformations 3.7.1 Exercises 1 - What is the default geom associated with stat_summary()? How could you rewrite the previous plot to use that geom function instead of the stat function? The default geom for stat_summary() is geom_pointrange(). However, the default stat for geom_pointrage() is stat_identity(), meaning that the medians, mins and maxes must be computed first. The plot can be recreated with the following code: diamonds %&gt;% group_by(cut) %&gt;% summarize(median_y = median(depth), min_y = min(depth), max_y = max(depth)) %&gt;% ggplot() + geom_pointrange(mapping = aes(x = cut, y = median_y, ymin = min_y, ymax = max_y)) + labs(y = &#39;depth&#39;) 2 - What does geom_col() do? How is it different to geom_bar()? Both geom_col() and geom_bar() create bar charts. The major difference is that for geom_bar(), the default stat is stat_count(). It performs statistical transformation by counting the frequencies in each group and then makes the height of the bars proportional to the frequencies. For example: ggplot(data = diamonds) + geom_bar(aes(x = cut)) Whereas for geom_col(), the default stat is geom_identity(). The heights of the bars represent the values in the data. To recreate the above bar chart using geom_col(), we must first calculate the frequncies manually: diamonds %&gt;% group_by(cut) %&gt;% summarise(count = n()) %&gt;% ggplot() + geom_col(mapping = aes(x = cut, y = count)) 3 - Most geoms and stats come in pairs that are almost always used in concert. Read through the documentation and make a list of all the pairs. What do they have in common? The complete list of geoms and stats can be found in the documentation. 4 - What variables does stat_smooth() compute? What parameters control its behaviour? The method argument defines the smoothing method and the variables to compute. The arguments n, span, fullrange, and level controls its behaviour. 5 - In our proportion bar chart, we need to set group = 1. Why? In other words what is the problem with these two graphs? By default, geom_bar() counts the number of occurances in each level of the variable. However, if we want to display the proportions instead of counts, geom_bar() will treat the groups of the variable separately. Since all diamonds in ‘Fair’ are ‘Fair’, and all diamonds in ‘Ideal’ are ‘Idea’, etc., the proportions will always sum up to 1 for each group by default. ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, y = ..prop..)) To override this behavior and actually show the correct proportions relatively to the overall counts, we can specify group = 1: ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, y = ..prop.., group = 1)) Similarly in the second plot, geom_bar first separates the cut levels, then looks each color in each level indiviudally. Since all color ‘D’ in ‘Fair’ are color ‘D’, and all color ‘E’ in ‘Good’ are color ‘E’, etc., the proportion for each color in each cut level is always 1. There are 7 colors in each cut level, so the proportions all sum up to 7. ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = color, y = ..prop..)) To override this behavior, this time we can include group = color. ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = color, y = ..prop.., group = color)) Note that although visually it looks correct, the proportions are still only relatively to the respective colors. For example, the sum of the proportions of color ‘D’ is 1, and since there are 7 colors, the sum of the total height of the 5 bars is 7. Again to remedy this, instead of a stacked bar chart, we can modify the position argument to dodge: ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = color, y = ..prop.., group = color), position = &#39;dodge&#39;) 3.8 Position adjustments 3.8.1 Exercises 1 - What is the problem with this plot? How could you improve it? ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_point() The problem with this plot is that since there are many observations with the same values of cty and hwy, many data points overlap with each other and it fails to show where the mass of the data is. We can use geom_jitter() instead: ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_jitter() geom_jitter is able to display where the data points are concentrated by sacrificing a little bit of statistically accuracy. 2 - What parameters to `geom_jitter() control the amount of jittering? The amount of jittering can be controlled by arguments width and height in geom_jitter(). 3 - Compare and contrast geom_jitter() with geom_count() Both geom_jitter() and geom_count() can better represent the data when there are many overlapping points and show where the mass of the data is. geom_jitter() achieves this by slightly moving the overlapping points vertically and horizontally, sacrificing statistical accuracy while being more clearly in showing the overlapping points. geom_count() counts the overlapping points, and maps the counts to the size of the points instead. ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_count() 4 - What’s the default position adjustment for geom_boxplot()? Create a visualisation of the mpg dataset that demonstrates it. The default positional adjustment is dodge. ggplot(data = mpg) + geom_boxplot(mapping = aes(y = displ, x = drv, color = factor(year))) 3.9 Coordinate systems 3.9.1 Exercises 1 - Turn a stacked bar chart into a pie chart using coord_polar() Using the previous example in the chapter: ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = clarity)) + coord_polar() In the above chart, the pies are angled by the x variable (cut). We can angle the pies by the y variable using the arguement theta: ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = clarity)) + coord_polar(theta = &quot;y&quot;) 2 - What does labs() do? Read the documentation. labs() allows us to modify ploy title, subtitle, axis title, and legend title. 3 - What’s the difference between coord_quickmap() and coord_map()? Type ?coord_map, or read the description in the reference. 4 - What does the plot below tell you about the relationship between city and highway mpg? Why is coord_fixed() important? What does geom_abline() do? ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) + geom_point() + geom_abline() + coord_fixed() The plot shows us that there is a positive linear trend between hwy and cty, and the slope is approximately close 1, meaning that a unit increase in cty is associated with a unit increase in hwy. coord_fixed forces a specified aspect ratio between the physical representation of the units on the axes. The ratio is 1 by default. It is important to fix the aspect ratio in this case because hwy and cty are measured in the same unit (miles per gallon). Any other aspect ratios will give a visually incorrect representation and might lead us to believe that one increasese at a faster rate than the other. geom_abline() adds a diagonal reference line to the plot, thus allows us the confidence earlier that the relationship is positively linear and the slope is close to 1. 3.10 The layered grammar of graphics No exercises "],
["workflow-basics.html", "4 Workflow Basics 4.1 Coding basics 4.2 What’s in a name? 4.3 Calling functions 4.4 Practice", " 4 Workflow Basics 4.1 Coding basics No exercises. 4.2 What’s in a name? No exercises. 4.3 Calling functions No exercises. 4.4 Practice 1 - Why does this code not work? my_variable &lt;- 10 my_varıable #&gt; Error in eval(expr, envir, enclos): object &#39;my_varıable&#39; not found Look carefully! (This may seem like an exercise in pointlessness, but training your brain to notice even the tiniest difference will pay off when programming.) The value 10 is assigned to my_variable, not my_varıable. (Variables are named differently) 2 - Tweak each of the following R commands so that they run correctly: library(tidyverse) ggplot(dota = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) fliter(mpg, cyl = 8) filter(diamond, carat &gt; 3) Spelling is important. There are three typos in the above code: - dota instead of data - the first filter is misspelled as fliter - the dataset diamond should be diamonds The corrected code is shown below: library(tidyverse) ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) filter(mpg, cyl == 8) filter(diamonds, carat &gt; 3) 3 - Press Alt + Shift + K. What happens? How can you get to the same place using the menus? The Keyboard Shortcut Quick Reference pops up. To get to the same place using the menus, click Help on the menu bar, and it is under Keyboard Shortcuts Help. "],
["data-transformation.html", "5 Data transformation 5.1 Introduction 5.2 Filter rows with filter() 5.3 Arrange rows with arrange() 5.4 Select columns with select() 5.5 Add new variables with mutate() 5.6 Grouped summaries with summarise() 5.7 Grouped mutates (and filters)", " 5 Data transformation 5.1 Introduction No exercises. 5.2 Filter rows with filter() 5.2.1 Exercises 1 - Find all flights that 1. Had an arrival delay of two or more hours library(tidyverse) flights &lt;- nycflights13::flights filter(flights, arr_delay &gt;= 120) ## # A tibble: 10,200 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 811 630 101 1047 ## 2 2013 1 1 848 1835 853 1001 ## 3 2013 1 1 957 733 144 1056 ## 4 2013 1 1 1114 900 134 1447 ## 5 2013 1 1 1505 1310 115 1638 ## 6 2013 1 1 1525 1340 105 1831 ## 7 2013 1 1 1549 1445 64.0 1912 ## 8 2013 1 1 1558 1359 119 1718 ## 9 2013 1 1 1732 1630 62.0 2028 ## 10 2013 1 1 1803 1620 103 2008 ## # ... with 10,190 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 2. Flew to Houston (IAH or HOU) filter(flights, dest %in% c(&#39;IAH&#39;, &#39;HOU&#39;)) ## # A tibble: 9,313 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2.00 830 ## 2 2013 1 1 533 529 4.00 850 ## 3 2013 1 1 623 627 - 4.00 933 ## 4 2013 1 1 728 732 - 4.00 1041 ## 5 2013 1 1 739 739 0 1104 ## 6 2013 1 1 908 908 0 1228 ## 7 2013 1 1 1028 1026 2.00 1350 ## 8 2013 1 1 1044 1045 - 1.00 1352 ## 9 2013 1 1 1114 900 134 1447 ## 10 2013 1 1 1205 1200 5.00 1503 ## # ... with 9,303 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 3. Were operated by United, American, or Delta filter(flights, carrier %in% c(&#39;UA&#39;,&#39;AA&#39;,&#39;DL&#39;)) ## # A tibble: 139,504 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2.00 830 ## 2 2013 1 1 533 529 4.00 850 ## 3 2013 1 1 542 540 2.00 923 ## 4 2013 1 1 554 600 -6.00 812 ## 5 2013 1 1 554 558 -4.00 740 ## 6 2013 1 1 558 600 -2.00 753 ## 7 2013 1 1 558 600 -2.00 924 ## 8 2013 1 1 558 600 -2.00 923 ## 9 2013 1 1 559 600 -1.00 941 ## 10 2013 1 1 559 600 -1.00 854 ## # ... with 139,494 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 4. Departed in summer (July, August, and September) filter(flights, month %in% c(7,8,9)) ## # A tibble: 86,326 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 7 1 1 2029 212 236 ## 2 2013 7 1 2 2359 3.00 344 ## 3 2013 7 1 29 2245 104 151 ## 4 2013 7 1 43 2130 193 322 ## 5 2013 7 1 44 2150 174 300 ## 6 2013 7 1 46 2051 235 304 ## 7 2013 7 1 48 2001 287 308 ## 8 2013 7 1 58 2155 183 335 ## 9 2013 7 1 100 2146 194 327 ## 10 2013 7 1 100 2245 135 337 ## # ... with 86,316 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 5. Arrived more than two hours late, but didn’t leave late filter(flights, dep_delay &lt;= 0, arr_delay &gt;= 120) ## # A tibble: 29 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 27 1419 1420 -1.00 1754 ## 2 2013 10 7 1350 1350 0 1736 ## 3 2013 10 7 1357 1359 -2.00 1858 ## 4 2013 10 16 657 700 -3.00 1258 ## 5 2013 11 1 658 700 -2.00 1329 ## 6 2013 3 18 1844 1847 -3.00 39 ## 7 2013 4 17 1635 1640 -5.00 2049 ## 8 2013 4 18 558 600 -2.00 1149 ## 9 2013 4 18 655 700 -5.00 1213 ## 10 2013 5 22 1827 1830 -3.00 2217 ## # ... with 19 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 6. Were delayed by at least an hour, but made up over 30 minutes in flight filter(flights, dep_delay &gt;= 60, dep_delay &gt; arr_delay + 30) ## # A tibble: 1,844 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 2205 1720 285 46 ## 2 2013 1 1 2326 2130 116 131 ## 3 2013 1 3 1503 1221 162 1803 ## 4 2013 1 3 1839 1700 99.0 2056 ## 5 2013 1 3 1850 1745 65.0 2148 ## 6 2013 1 3 1941 1759 102 2246 ## 7 2013 1 3 1950 1845 65.0 2228 ## 8 2013 1 3 2015 1915 60.0 2135 ## 9 2013 1 3 2257 2000 177 45 ## 10 2013 1 4 1917 1700 137 2135 ## # ... with 1,834 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 7. Departed between midnight and 6am (inclusive) filter(flights, dep_time &gt;= 0, dep_time &lt;= 600) ## # A tibble: 9,344 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2.00 830 ## 2 2013 1 1 533 529 4.00 850 ## 3 2013 1 1 542 540 2.00 923 ## 4 2013 1 1 544 545 -1.00 1004 ## 5 2013 1 1 554 600 -6.00 812 ## 6 2013 1 1 554 558 -4.00 740 ## 7 2013 1 1 555 600 -5.00 913 ## 8 2013 1 1 557 600 -3.00 709 ## 9 2013 1 1 557 600 -3.00 838 ## 10 2013 1 1 558 600 -2.00 753 ## # ... with 9,334 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 2 - Another useful dplyr filtering helper is between(). What does it do? Can you use it to simplify the code needed to answer the previous challenges? between() is a shortcut for x &gt;= left &amp; x &lt;= right. Part 7 of the previous question can be rewritten as: filter(flights, between(dep_time, 0 , 600)) ## # A tibble: 9,344 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2.00 830 ## 2 2013 1 1 533 529 4.00 850 ## 3 2013 1 1 542 540 2.00 923 ## 4 2013 1 1 544 545 -1.00 1004 ## 5 2013 1 1 554 600 -6.00 812 ## 6 2013 1 1 554 558 -4.00 740 ## 7 2013 1 1 555 600 -5.00 913 ## 8 2013 1 1 557 600 -3.00 709 ## 9 2013 1 1 557 600 -3.00 838 ## 10 2013 1 1 558 600 -2.00 753 ## # ... with 9,334 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 3 - How many flights have a missing dep_time? What other variables are missing? What might these rows represent? sum(is.na(flights$dep_time)) ## [1] 8255 There are 8255 flights with missing dep_time. For the flights with missing dep_time, dep_delay, arr_time, arr_delay, and air_time are also missing. It means that these are the flights that were cancelled. filter(flights, is.na(dep_time)) ## # A tibble: 8,255 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 NA 1630 NA NA ## 2 2013 1 1 NA 1935 NA NA ## 3 2013 1 1 NA 1500 NA NA ## 4 2013 1 1 NA 600 NA NA ## 5 2013 1 2 NA 1540 NA NA ## 6 2013 1 2 NA 1620 NA NA ## 7 2013 1 2 NA 1355 NA NA ## 8 2013 1 2 NA 1420 NA NA ## 9 2013 1 2 NA 1321 NA NA ## 10 2013 1 2 NA 1545 NA NA ## # ... with 8,245 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 4 - Why is NA ^ 0 not missing? Why is NA | TRUE not missing? Why is FALSE &amp; NA not missing? Can you figure out the general rule? (NA \\* 0 is a tricky counterexample!) One way to think of NA is that it can be a placeholder for any possible values. By this logic: any values raised to the power of 0 is 0 NA | TRUE, anything else OR TRUE is always TRUE NA &amp; FALSE, anything else AND FALSE is always FALSE NA * 0 ? TO DO. 5.3 Arrange rows with arrange() 5.3.1 Exercises 1 - How could you use arrange() to sort all missing values to the start? (Hint: use is.na()). One way to put missing dep_delay to the start: head(arrange(flights, desc(is.na(dep_delay)))) ## # A tibble: 6 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 NA 1630 NA NA ## 2 2013 1 1 NA 1935 NA NA ## 3 2013 1 1 NA 1500 NA NA ## 4 2013 1 1 NA 600 NA NA ## 5 2013 1 2 NA 1540 NA NA ## 6 2013 1 2 NA 1620 NA NA ## # ... with 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, ## # time_hour &lt;dttm&gt; 2 - Sort flights to find the most delayed flights. Find the flights that left earliest. The top 5 most delayed flights: head(arrange(flights, desc(dep_delay))) ## # A tibble: 6 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 9 641 900 1301 1242 ## 2 2013 6 15 1432 1935 1137 1607 ## 3 2013 1 10 1121 1635 1126 1239 ## 4 2013 9 20 1139 1845 1014 1457 ## 5 2013 7 22 845 1600 1005 1044 ## 6 2013 4 10 1100 1900 960 1342 ## # ... with 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, ## # time_hour &lt;dttm&gt; The top 5 flights that left earliest: head(arrange(flights, dep_delay)) ## # A tibble: 6 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 12 7 2040 2123 -43.0 40 ## 2 2013 2 3 2022 2055 -33.0 2240 ## 3 2013 11 10 1408 1440 -32.0 1549 ## 4 2013 1 11 1900 1930 -30.0 2233 ## 5 2013 1 29 1703 1730 -27.0 1947 ## 6 2013 8 9 729 755 -26.0 1002 ## # ... with 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, ## # time_hour &lt;dttm&gt; 3 - Sort flights to find the fastest flights. Top 5 fastest flights: head(arrange(flights, air_time)) ## # A tibble: 6 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 16 1355 1315 40.0 1442 ## 2 2013 4 13 537 527 10.0 622 ## 3 2013 12 6 922 851 31.0 1021 ## 4 2013 2 3 2153 2129 24.0 2247 ## 5 2013 2 5 1303 1315 -12.0 1342 ## 6 2013 2 12 2123 2130 - 7.00 2211 ## # ... with 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, ## # time_hour &lt;dttm&gt; 4 - Which flights travelled the longest? Which travelled the shortest? Top 5 flights that travelled the longest: head(arrange(flights, desc(distance))) ## # A tibble: 6 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 857 900 - 3.00 1516 ## 2 2013 1 2 909 900 9.00 1525 ## 3 2013 1 3 914 900 14.0 1504 ## 4 2013 1 4 900 900 0 1516 ## 5 2013 1 5 858 900 - 2.00 1519 ## 6 2013 1 6 1019 900 79.0 1558 ## # ... with 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, ## # time_hour &lt;dttm&gt; Top 5 flights that travelled the shortest: head(arrange(flights, distance)) ## # A tibble: 6 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 7 27 NA 106 NA NA ## 2 2013 1 3 2127 2129 - 2.00 2222 ## 3 2013 1 4 1240 1200 40.0 1333 ## 4 2013 1 4 1829 1615 134 1937 ## 5 2013 1 4 2128 2129 - 1.00 2218 ## 6 2013 1 5 1155 1200 - 5.00 1241 ## # ... with 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, ## # time_hour &lt;dttm&gt; 5.4 Select columns with select() 5.4.1 Exercises 1 - Brainstorm as many ways as possible to select dep_time, dep_delay, arr_time, and arr_delay from flights. One way to select those variables is to include each of them in the select function: select(flights, dep_time, dep_delay, arr_time, arr_delay) ## # A tibble: 336,776 x 4 ## dep_time dep_delay arr_time arr_delay ## &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 517 2.00 830 11.0 ## 2 533 4.00 850 20.0 ## 3 542 2.00 923 33.0 ## 4 544 -1.00 1004 -18.0 ## 5 554 -6.00 812 -25.0 ## 6 554 -4.00 740 12.0 ## 7 555 -5.00 913 19.0 ## 8 557 -3.00 709 -14.0 ## 9 557 -3.00 838 - 8.00 ## 10 558 -2.00 753 8.00 ## # ... with 336,766 more rows Another way to do it is to use starts_with(): select(flights, starts_with(&#39;dep&#39;), starts_with(&#39;arr&#39;)) ## # A tibble: 336,776 x 4 ## dep_time dep_delay arr_time arr_delay ## &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 517 2.00 830 11.0 ## 2 533 4.00 850 20.0 ## 3 542 2.00 923 33.0 ## 4 544 -1.00 1004 -18.0 ## 5 554 -6.00 812 -25.0 ## 6 554 -4.00 740 12.0 ## 7 555 -5.00 913 19.0 ## 8 557 -3.00 709 -14.0 ## 9 557 -3.00 838 - 8.00 ## 10 558 -2.00 753 8.00 ## # ... with 336,766 more rows 2 - What happens if you include the name of a variable multiple times in a select() call? The repeated variables will not be included. See below. select(flights, dep_time, dep_time, dep_time) ## # A tibble: 336,776 x 1 ## dep_time ## &lt;int&gt; ## 1 517 ## 2 533 ## 3 542 ## 4 544 ## 5 554 ## 6 554 ## 7 555 ## 8 557 ## 9 557 ## 10 558 ## # ... with 336,766 more rows 3 - What does the one_of() function do? Why might it be helpful in conjunction with this vector? vars &lt;- c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;, &quot;dep_delay&quot;, &quot;arr_delay&quot;) ‘one_of()’ allows you to select variables in the character vector. For example: select(flights, one_of(vars)) ## # A tibble: 336,776 x 5 ## year month day dep_delay arr_delay ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2013 1 1 2.00 11.0 ## 2 2013 1 1 4.00 20.0 ## 3 2013 1 1 2.00 33.0 ## 4 2013 1 1 -1.00 -18.0 ## 5 2013 1 1 -6.00 -25.0 ## 6 2013 1 1 -4.00 12.0 ## 7 2013 1 1 -5.00 19.0 ## 8 2013 1 1 -3.00 -14.0 ## 9 2013 1 1 -3.00 - 8.00 ## 10 2013 1 1 -2.00 8.00 ## # ... with 336,766 more rows The 5 variables in the vector vars are selected. 4 - Does the result of running the following code surprise you? How do the select helpers deal with case by default? How can you change that default? select(flights, contains(&quot;TIME&quot;)) ## # A tibble: 336,776 x 6 ## dep_time sched_dep_time arr_time sched_arr_time air_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 517 515 830 819 227 ## 2 533 529 850 830 227 ## 3 542 540 923 850 160 ## 4 544 545 1004 1022 183 ## 5 554 600 812 837 116 ## 6 554 558 740 728 150 ## 7 555 600 913 854 158 ## 8 557 600 709 723 53.0 ## 9 557 600 838 846 140 ## 10 558 600 753 745 138 ## # ... with 336,766 more rows, and 1 more variable: time_hour &lt;dttm&gt; The original code intends to select variables containing the characters TIME. However, the selected variables contain the lower case time instead. By default, contains() is not case sensitive. To override this behaviour, we can use ignore.case = FALSE. For example: select(flights, contains(&quot;TIME&quot;, ignore.case = FALSE)) ## # A tibble: 336,776 x 0 In this case, no variables are being selected because none of the variables contain the character string TIME. 5.5 Add new variables with mutate() 5.5.1 Exercises 1 - Currently dep_time and sched_dep_time are convenient to look at, but hard to compute with because they’re not really continuous numbers. Convert them to a more convenient representation of number of minutes since midnight. flights &lt;- mutate(flights, dep_time_mins = dep_time %/% 100 * 60 + dep_time %% 100, sched_dep_time_mins = sched_dep_time %/% 100 * 60 + sched_dep_time %% 100) select(flights, starts_with(&#39;dep_time&#39;), starts_with(&#39;sched&#39;)) ## # A tibble: 336,776 x 5 ## dep_time dep_time_mins sched_dep_time sched_arr_time sched_dep_time_mi~ ## &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 517 317 515 819 315 ## 2 533 333 529 830 329 ## 3 542 342 540 850 340 ## 4 544 344 545 1022 345 ## 5 554 354 600 837 360 ## 6 554 354 558 728 358 ## 7 555 355 600 854 360 ## 8 557 357 600 723 360 ## 9 557 357 600 846 360 ## 10 558 358 600 745 360 ## # ... with 336,766 more rows 2 - Compare air_time with arr_time - dep_time. What do you expect to see? What do you see? What do you need to do to fix it? air_time is the amount of time spent in the air in minutes, and we would expect to see air_time and arr_time - dep_time to be the same. First, let’s define a new variable flight_time as the difference between arr_time and dep_time. Comparing it with air_time: flights %&gt;% mutate(flight_time = arr_time - dep_time) %&gt;% select(air_time, flight_time) ## # A tibble: 336,776 x 2 ## air_time flight_time ## &lt;dbl&gt; &lt;int&gt; ## 1 227 313 ## 2 227 317 ## 3 160 381 ## 4 183 460 ## 5 116 258 ## 6 150 186 ## 7 158 358 ## 8 53.0 152 ## 9 140 281 ## 10 138 195 ## # ... with 336,766 more rows The computed flight_time is very different from air_time. The difference is mainly due to the fact that the original arr_time and dep_time are not really continuous numbers. To remedy this, arr_time is converted to minutes since midnight, same as previous question, and then flight_time is recalculated. flights &lt;- mutate(flights, arr_time_mins = arr_time %/% 100 * 60 + arr_time %% 100) flights &lt;- mutate(flights, flight_time = arr_time_mins - dep_time_mins) select(flights, air_time, flight_time) ## # A tibble: 336,776 x 2 ## air_time flight_time ## &lt;dbl&gt; &lt;dbl&gt; ## 1 227 193 ## 2 227 197 ## 3 160 221 ## 4 183 260 ## 5 116 138 ## 6 150 106 ## 7 158 198 ## 8 53.0 72.0 ## 9 140 161 ## 10 138 115 ## # ... with 336,766 more rows Again, we see the given air_time is different from the computed flight_time. In fact, only 196 flights have the same air_time and computed flight_time. sum(flights$air_time == flights$flight_time, na.rm = TRUE) ## [1] 196 3 - Compare dep_time, sched_dep_time, and dep_delay. How would you expect those three numbers to be related? select(flights, dep_time, sched_dep_time, dep_delay) ## # A tibble: 336,776 x 3 ## dep_time sched_dep_time dep_delay ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 517 515 2.00 ## 2 533 529 4.00 ## 3 542 540 2.00 ## 4 544 545 -1.00 ## 5 554 600 -6.00 ## 6 554 558 -4.00 ## 7 555 600 -5.00 ## 8 557 600 -3.00 ## 9 557 600 -3.00 ## 10 558 600 -2.00 ## # ... with 336,766 more rows dep_time and sched_dep_time are in clock format. Their difference in minutes is given by dep_delay. 4 - Find the 10 most delayed flights using a ranking function. How do you want to handle ties? Carefully read the documentation for min_rank() head(arrange(flights, min_rank(desc(dep_delay))), 10) ## # A tibble: 10 x 23 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 9 641 900 1301 1242 ## 2 2013 6 15 1432 1935 1137 1607 ## 3 2013 1 10 1121 1635 1126 1239 ## 4 2013 9 20 1139 1845 1014 1457 ## 5 2013 7 22 845 1600 1005 1044 ## 6 2013 4 10 1100 1900 960 1342 ## 7 2013 3 17 2321 810 911 135 ## 8 2013 6 27 959 1900 899 1236 ## 9 2013 7 22 2257 759 898 121 ## 10 2013 12 5 756 1700 896 1058 ## # ... with 16 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, ## # time_hour &lt;dttm&gt;, dep_time_mins &lt;dbl&gt;, sched_dep_time_mins &lt;dbl&gt;, ## # arr_time_mins &lt;dbl&gt;, flight_time &lt;dbl&gt; min_rank() is equivalent to rank() method with the argument ties.method = 'min. It assigns every tied element to the lowest rank. 5 - What does 1:3 + 1:10 return? Why? R performs vectorized calculations. For example, when we add two vectors of the same length together, c(1,2,3) + c(4,5,6), the result will be c(5,7,9). When we add two vectors of different lengths, the shorter vector with be ‘repeated’ to match the length of the longer vector. 1:3 + 1:10 ## Warning in 1:3 + 1:10: longer object length is not a multiple of shorter ## object length ## [1] 2 4 6 5 7 9 8 10 12 11 6 - What trigonometric functions does R provide? Type ?sin to see a complete list of trignomometric functions. 5.6 Grouped summaries with summarise() 5.6.1 Exercises 1 - Brainstorm at least 5 different ways to assess the typical delay characteristics of a group of flights. Consider the following scenarios: - A flight is 15 minutes early 50% of the time, and 15 minutes late 50% of the time. - A flight is always 10 minutes late. - A flight is 30 minutes early 50% of the time, and 30 minutes late 50% of the time. - 99% of the time a flight is on time. 1% of the time it’s 2 hours late. Which is more important: arrival delay or departure delay? Just some personal and non-scientific reasoning, to me, arrival delay is more important than departure delay. 2 - Come up with another approach that will give you the same output as not_cancelled %&gt;% count(dest) and not_cancelled %&gt;% count(tailnum, wt = distance) (without using count()). We can use n() instead in summarize() to obtain the same output as not_cancelled %&gt;% count(dest). flights %&gt;% filter(!is.na(dep_delay), !is.na(arr_delay)) %&gt;% group_by(dest) %&gt;% summarize(count = n()) ## # A tibble: 104 x 2 ## dest count ## &lt;chr&gt; &lt;int&gt; ## 1 ABQ 254 ## 2 ACK 264 ## 3 ALB 418 ## 4 ANC 8 ## 5 ATL 16837 ## 6 AUS 2411 ## 7 AVL 261 ## 8 BDL 412 ## 9 BGR 358 ## 10 BHM 269 ## # ... with 94 more rows And for not_cancelled %&gt;% count(tailnum, wt = distance), we group by tailnum and sum the distance. flights %&gt;% filter(!is.na(dep_delay), !is.na(arr_delay)) %&gt;% group_by(tailnum) %&gt;% summarize(count = sum(distance)) ## # A tibble: 4,037 x 2 ## tailnum count ## &lt;chr&gt; &lt;dbl&gt; ## 1 D942DN 3418 ## 2 N0EGMQ 239143 ## 3 N10156 109664 ## 4 N102UW 25722 ## 5 N103US 24619 ## 6 N104UW 24616 ## 7 N10575 139903 ## 8 N105UW 23618 ## 9 N107US 21677 ## 10 N108UW 32070 ## # ... with 4,027 more rows 3 - Our definition of cancelled flights (is.na(dep_delay) | is.na(arr_delay) ) is slightly suboptimal. Why? Which is the most important column? Let’s see how ‘cancelled flights’ are defined in the flights dataset. Natrually one would think that cancelled flights are those that never departed from the origins and never arrived at the destinations. Checking the NA counts in those columns: flights %&gt;% select(starts_with(&quot;dep&quot;), starts_with(&quot;arr&quot;)) %&gt;% sapply(function(x){sum(is.na(x))}) ## dep_time dep_delay dep_time_mins arr_time arr_delay ## 8255 8255 8255 8713 9430 ## arr_time_mins ## 8713 We see that the NA counts for dep_time and arr_time don’t match. The difference is 8713 - 8255 = 458. One possible explanation is that those flights did actually take off, but arrived at a different airport or were forced to return to the origins. To confirm my hypothesis, we can look at the number of observations with non missing departure time and missing arrival time: nrow(flights %&gt;% filter(!is.na(dep_time), is.na(arr_time))) ## [1] 458 The NA count for arr_delay is a bit mysterious. A closer look at the flights dataset reveals that the NA count for arr_delay is the same as the NA count for air_time. There were flights that did depart and arrive, but with missing air_time and arr_delay. So my conclusion is, depending on how you define cancelled flights (never departed from the origin or never arrived at the destination), dep_time or arr_time should be used to filter cancelled flights. 4 - Look at the number of cancelled flights per day. Is there a pattern? Is the proportion of cancelled flights related to the average delay? Here, I define cancelled flights as those never departed at the origin in the first place. As can be seen in the plot below, there is a positive linear trend. flights %&gt;% group_by(month, day) %&gt;% summarize(avg_dep_delay = mean(dep_delay, na.rm = TRUE), prop_cancelled = sum(is.na(dep_time)/n())) %&gt;% ggplot(mapping = aes(x = avg_dep_delay, y = prop_cancelled)) + geom_point() + geom_smooth(method = &#39;lm&#39;, se = FALSE) 5 - Which carrier has the worst delays? Challenge: can you disentangle the effects of bad airports vs. bad carriers? Why/why not? (Hint: think about flights %&gt;% group_by(carrier, dest) %&gt;% summarise(n())) First we need to decide how we quantify and compare delays between carriers. For this question we’ll just simply calculate the average minutes in arrival and departure delays. worst &lt;- flights %&gt;% group_by(carrier) %&gt;% summarize(avg_arr_delay = mean(arr_delay, na.rm = TRUE), avg_dep_delay = mean(dep_delay, na.rm = TRUE)) Arrange by average arrival delay in minutes: arrange(worst, desc(avg_arr_delay)) ## # A tibble: 16 x 3 ## carrier avg_arr_delay avg_dep_delay ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 F9 21.9 20.2 ## 2 FL 20.1 18.7 ## 3 EV 15.8 20.0 ## 4 YV 15.6 19.0 ## 5 OO 11.9 12.6 ## 6 MQ 10.8 10.6 ## 7 WN 9.65 17.7 ## 8 B6 9.46 13.0 ## 9 9E 7.38 16.7 ## 10 UA 3.56 12.1 ## 11 US 2.13 3.78 ## 12 VX 1.76 12.9 ## 13 DL 1.64 9.26 ## 14 AA 0.364 8.59 ## 15 HA - 6.92 4.90 ## 16 AS - 9.93 5.80 Arrange by average departure delay in minutes: arrange(worst, desc(avg_dep_delay)) ## # A tibble: 16 x 3 ## carrier avg_arr_delay avg_dep_delay ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 F9 21.9 20.2 ## 2 EV 15.8 20.0 ## 3 YV 15.6 19.0 ## 4 FL 20.1 18.7 ## 5 WN 9.65 17.7 ## 6 9E 7.38 16.7 ## 7 B6 9.46 13.0 ## 8 VX 1.76 12.9 ## 9 OO 11.9 12.6 ## 10 UA 3.56 12.1 ## 11 MQ 10.8 10.6 ## 12 DL 1.64 9.26 ## 13 AA 0.364 8.59 ## 14 AS - 9.93 5.80 ## 15 HA - 6.92 4.90 ## 16 US 2.13 3.78 Similarly we can look at which airport has the worst departure delay: flights %&gt;% group_by(origin) %&gt;% summarize(avg_dep_delay = mean(dep_delay, na.rm = TRUE)) ## # A tibble: 3 x 2 ## origin avg_dep_delay ## &lt;chr&gt; &lt;dbl&gt; ## 1 EWR 15.1 ## 2 JFK 12.1 ## 3 LGA 10.3 and the worst arrival delay: flights %&gt;% group_by(origin) %&gt;% summarize(avg_arr_delay = mean(arr_delay, na.rm = TRUE)) ## # A tibble: 3 x 2 ## origin avg_arr_delay ## &lt;chr&gt; &lt;dbl&gt; ## 1 EWR 9.11 ## 2 JFK 5.55 ## 3 LGA 5.78 We can attempt to disentangle the effects of departure delay for carrier 9E: flights %&gt;% group_by(carrier, origin) %&gt;% summarize(avg_dep_delay = mean(dep_delay, na.rm = TRUE)) %&gt;% filter(carrier == &#39;9E&#39;) ## # A tibble: 3 x 3 ## # Groups: carrier [1] ## carrier origin avg_dep_delay ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 9E EWR 5.95 ## 2 9E JFK 19.0 ## 3 9E LGA 8.89 The overall average departure delay is 16.73 minutes from the previous table. However, we can conclude that at least for carrier 9E, on average, the flights were delayed most at JFK. 6 - What does the sort argument to count() do. When might you use it? The sort argument if set to TRUE, will sort the output in descending order. For example, without sort = TRUE: flights %&gt;% filter(!is.na(dep_delay), !is.na(arr_delay)) %&gt;% count(dest) ## # A tibble: 104 x 2 ## dest n ## &lt;chr&gt; &lt;int&gt; ## 1 ABQ 254 ## 2 ACK 264 ## 3 ALB 418 ## 4 ANC 8 ## 5 ATL 16837 ## 6 AUS 2411 ## 7 AVL 261 ## 8 BDL 412 ## 9 BGR 358 ## 10 BHM 269 ## # ... with 94 more rows With sort = TRUE: flights %&gt;% filter(!is.na(dep_delay), !is.na(arr_delay)) %&gt;% count(dest, sort = TRUE) ## # A tibble: 104 x 2 ## dest n ## &lt;chr&gt; &lt;int&gt; ## 1 ATL 16837 ## 2 ORD 16566 ## 3 LAX 16026 ## 4 BOS 15022 ## 5 MCO 13967 ## 6 CLT 13674 ## 7 SFO 13173 ## 8 FLL 11897 ## 9 MIA 11593 ## 10 DCA 9111 ## # ... with 94 more rows 5.7 Grouped mutates (and filters) 5.7.1 Exercises 1 - Refer back to the lists of useful mutate and filtering functions. Describe how each operation changes when you combine it with grouping. Before grouping, functions like mean(), median(), min(), or max() will operation over the whole dataset. For example, applying mean() on a variable before grouping will get the average of the variable over the entire dataset. After grouping, these functions will operate within each group. 2 - Which plane (tailnum) has the worst on-time record? Filter out the on-time departure records and calculate the average departure delay in minutes. flights %&gt;% group_by(tailnum) %&gt;% filter(dep_delay &gt; 0) %&gt;% summarize(avg_delay = mean(dep_delay)) %&gt;% arrange(desc(avg_delay)) ## # A tibble: 3,885 x 2 ## tailnum avg_delay ## &lt;chr&gt; &lt;dbl&gt; ## 1 N844MH 297 ## 2 N452UW 291 ## 3 N922EV 274 ## 4 N587NW 272 ## 5 N911DA 268 ## 6 N665MQ 268 ## 7 N673MQ 257 ## 8 N851NW 233 ## 9 N654UA 227 ## 10 N550NW 212 ## # ... with 3,875 more rows 3 - What time of day should you fly if you want to avoid delays as much as possible? Similar to above question, we filter out the on-time departures and calculate the average departure delay in minuts for each hour. flights %&gt;% filter (dep_delay &gt; 0) %&gt;% group_by(hour) %&gt;% summarize(avg_delay = mean(dep_delay)) %&gt;% arrange(avg_delay) ## # A tibble: 19 x 2 ## hour avg_delay ## &lt;dbl&gt; &lt;dbl&gt; ## 1 5.00 15.3 ## 2 7.00 24.1 ## 3 6.00 24.2 ## 4 9.00 29.7 ## 5 8.00 29.9 ## 6 12.0 32.3 ## 7 11.0 32.5 ## 8 10.0 32.6 ## 9 13.0 33.5 ## 10 14.0 37.1 ## 11 23.0 38.0 ## 12 15.0 38.8 ## 13 16.0 43.4 ## 14 17.0 45.3 ## 15 18.0 46.5 ## 16 22.0 46.5 ## 17 20.0 49.6 ## 18 21.0 50.3 ## 19 19.0 51.1 4 - For each destination, compute the total minutes of delay. For each flight, compute the proportion of the total delay for its destination. We select only dest and arr_delay variables. We also filter out on-time flights or flights that were cancelled. flights %&gt;% select(dest, arr_delay) %&gt;% group_by(dest) %&gt;% filter(arr_delay &gt; 0) %&gt;% mutate(total_delay = sum(arr_delay, na.rm = TRUE), prop_delay = arr_delay / total_delay) ## # A tibble: 133,004 x 4 ## # Groups: dest [103] ## dest arr_delay total_delay prop_delay ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 IAH 11.0 99391 0.000111 ## 2 IAH 20.0 99391 0.000201 ## 3 MIA 33.0 140424 0.000235 ## 4 ORD 12.0 283046 0.0000424 ## 5 FLL 19.0 202605 0.0000938 ## 6 ORD 8.00 283046 0.0000283 ## 7 LAX 7.00 203226 0.0000344 ## 8 DFW 31.0 110009 0.000282 ## 9 ATL 12.0 300299 0.0000400 ## 10 DTW 16.0 138258 0.000116 ## # ... with 132,994 more rows 5 - Delays are typically temporally correlated: even once the problem that caused the initial delay has been resolved, later flights are delayed to allow earlier flights to leave. Using lag() explore how the delay of a flight is related to the delay of the immediately preceding flight. Let’s focus on flights departing from JFK and assume we can ignore the effect of cancelled flights: flights %&gt;% filter(origin == &#39;JFK&#39;) %&gt;% filter(!is.na(dep_delay)) %&gt;% mutate(pre_dep_delay = lag(dep_delay, default = 0)) %&gt;% ggplot(mapping = aes(x = dep_delay, y= pre_dep_delay)) + geom_point(alpha = .5) The mass of data on the bottom left shows that the departure delay and the previous depart delay are related. The correlation is: flights &lt;- flights %&gt;% filter(origin == &#39;JFK&#39;) %&gt;% filter(!is.na(dep_delay)) %&gt;% mutate(pre_dep_delay = lag(dep_delay, default = 0)) cor(flights$dep_delay, flights$pre_dep_delay) ## [1] 0.2928064 6 - Look at each destination. Can you find flights that are suspiciously fast? (i.e. flights that represent a potential data entry error). Compute the air time a flight relative to the shortest flight to that destination. Which flights were most delayed in the air? To find flights that are suspiciously fast, in other words, outliers that are far below than the average air_time, we can compute z-score, or the number of standard deviations below/above the mean air_time. flights %&gt;% filter(!is.na(air_time)) %&gt;% group_by(dest) %&gt;% mutate(air_time_mean = mean(air_time), air_time_sd = sd(air_time), z = (air_time - air_time_mean) / air_time_sd) %&gt;% select(z, air_time_mean, dest, everything()) %&gt;% arrange(z) ## # A tibble: 109,079 x 27 ## # Groups: dest [70] ## z air_time_mean dest year month day dep_time sched_dep_time ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 -4.10 57.1 BUF 2013 11 10 2307 2250 ## 2 -3.80 51.9 ROC 2013 3 25 2340 2250 ## 3 -3.55 329 SEA 2013 7 3 1533 1459 ## 4 -3.51 52.6 ORF 2013 11 3 1720 1645 ## 5 -3.40 66.5 PIT 2013 7 17 1504 1505 ## 6 -3.03 66.5 PIT 2013 5 8 1947 1859 ## 7 -3.03 329 SEA 2013 5 6 1728 1730 ## 8 -2.99 331 PDX 2013 5 6 1753 1755 ## 9 -2.98 329 LAX 2013 9 6 2042 2025 ## 10 -2.97 329 SEA 2013 5 6 1553 1557 ## # ... with 109,069 more rows, and 19 more variables: dep_delay &lt;dbl&gt;, ## # arr_time &lt;int&gt;, sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, ## # flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, air_time &lt;dbl&gt;, ## # distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, ## # dep_time_mins &lt;dbl&gt;, sched_dep_time_mins &lt;dbl&gt;, arr_time_mins &lt;dbl&gt;, ## # flight_time &lt;dbl&gt;, pre_dep_delay &lt;dbl&gt;, air_time_sd &lt;dbl&gt; I would say that air_time that are 2 standard deviations below the are unusually fast. Similarly we can look at which flights are most delayed in the air. flights %&gt;% filter(!is.na(air_time)) %&gt;% group_by(dest) %&gt;% mutate(air_time_mean = mean(air_time), air_time_sd = sd(air_time), z = (air_time - air_time_mean) / air_time_sd) %&gt;% select(z, air_time_mean, dest, everything()) %&gt;% arrange(desc(z)) ## # A tibble: 109,079 x 27 ## # Groups: dest [70] ## z air_time_mean dest year month day dep_time sched_dep_time ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 13.9 44.5 SYR 2013 9 1 2237 1711 ## 2 12.2 42.1 ACK 2013 6 29 755 800 ## 3 11.8 38.5 BOS 2013 7 23 1617 1605 ## 4 10.8 38.5 BOS 2013 7 23 1200 1200 ## 5 10.4 71.9 RDU 2013 9 1 1719 1712 ## 6 10.3 57.1 BUF 2013 12 16 923 925 ## 7 9.91 87.6 DTW 2013 7 27 1654 1620 ## 8 9.74 38.5 BOS 2013 2 17 841 840 ## 9 9.74 38.5 BOS 2013 7 23 1242 1245 ## 10 9.69 51.9 ROC 2013 7 10 2350 2030 ## # ... with 109,069 more rows, and 19 more variables: dep_delay &lt;dbl&gt;, ## # arr_time &lt;int&gt;, sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, ## # flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, air_time &lt;dbl&gt;, ## # distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, ## # dep_time_mins &lt;dbl&gt;, sched_dep_time_mins &lt;dbl&gt;, arr_time_mins &lt;dbl&gt;, ## # flight_time &lt;dbl&gt;, pre_dep_delay &lt;dbl&gt;, air_time_sd &lt;dbl&gt; 10 standard deviations above the mean! 7 - Find all destinations that are flown by at least two carriers. Use that information to rank the carriers. Destinations that are flown by the most number of carriers: flights %&gt;% group_by(dest) %&gt;% summarise(num_carrier = length(unique(carrier))) %&gt;% filter(num_carrier &gt;= 2) %&gt;% arrange(desc(num_carrier)) ## # A tibble: 45 x 2 ## dest num_carrier ## &lt;chr&gt; &lt;int&gt; ## 1 LAX 5 ## 2 SFO 5 ## 3 TPA 5 ## 4 AUS 4 ## 5 BOS 4 ## 6 LAS 4 ## 7 PIT 4 ## 8 ATL 3 ## 9 BNA 3 ## 10 CLT 3 ## # ... with 35 more rows Similiar, we can rank the carriers by counting how many destinations they fly to: flights %&gt;% group_by(carrier) %&gt;% summarise(num_dest = length(unique(dest))) %&gt;% filter(num_dest &gt;= 2) %&gt;% arrange(desc(num_dest)) ## # A tibble: 9 x 2 ## carrier num_dest ## &lt;chr&gt; &lt;int&gt; ## 1 B6 42 ## 2 9E 34 ## 3 DL 29 ## 4 AA 17 ## 5 MQ 11 ## 6 VX 5 ## 7 EV 3 ## 8 US 3 ## 9 UA 2 8 - For each plane, count the number of flights before the first delay of greater than 1 hour. Not sure if this is the most elegant solution. Let’s assume we can ignore the cancelled flights. We group by tailnum, and use cummax() to find the cummulative maxium departure delay. Count the total number of observations with cummulative max less than 60. flights %&gt;% filter(!is.na(dep_delay)) %&gt;% group_by(tailnum) %&gt;% mutate(max_delay = cummax(dep_delay), less_one_hour = max_delay &lt; 60) %&gt;% summarize(count = sum(less_one_hour)) %&gt;% arrange(desc(count)) ## # A tibble: 1,957 x 2 ## tailnum count ## &lt;chr&gt; &lt;int&gt; ## 1 N705TW 159 ## 2 N706TW 149 ## 3 N713TW 128 ## 4 N721TW 120 ## 5 N5FAAA 117 ## 6 N3769L 104 ## 7 N804JB 104 ## 8 N3748Y 103 ## 9 N645JB 94 ## 10 N3742C 91 ## # ... with 1,947 more rows "],
["workflow-scripts.html", "6 Workflow: scripts", " 6 Workflow: scripts No exercises. "],
["exploratory-data-analysis.html", "7 Exploratory Data Analysis 7.1 Introduction 7.2 Questions 7.3 Variation 7.4 Missing values 7.5 Covariation 7.6 Patterns and models 7.7 ggplot2 calls 7.8 Learning more", " 7 Exploratory Data Analysis 7.1 Introduction No exercises. 7.2 Questions No exercises. 7.3 Variation 7.3.1 Exercises 1 - Explore the distribution of each of the x, y, and z variables in diamonds. What do you learn? Think about a diamond and how you might decide which dimension is the length, width, and depth. library(tidyverse) The description of x, y, and z variables are given in ?diamonds. We can still explore the distributions of these three dimensions. One option is to use geom_histogram(). Another option is to use geom_density(), which is a smoothed version of the histogram. Here we will use geom_density() along with geom_rug(), which shows a 1-dimensional distribution at the bottom. ggplot(data = diamonds, mapping = aes(x = x)) + geom_density() + geom_rug() + labs(title = &#39;Distribution of x(length)&#39;) ggplot(data = diamonds, mapping = aes(x = y)) + geom_density() + geom_rug() + labs(title = &#39;Distribution of y(width)&#39;) ggplot(data = diamonds, mapping = aes(x = z)) + geom_density() + geom_rug() + labs(title = &#39;Distribution of z(depth)&#39;) We see that in general, there are more smaller diamonds than bigger ones. Also in y and z dimensions, there are outliers. They could be errros or real diamonds that are exceptionally large. 2 - Explore the distribution of price. Do you discover anything unusual or surprising? (Hint: Carefully think about the binwidth and make sure you try a wide range of values.) Setting the binwidth to 20, we can see that the price distribution is right-skewed and has many ‘spikes’. Most of the diamonds are under 1,000, and interestingly and unusally there are no dimaonds in the price range of around 1,500. There is also an increase in the number of diamonds in the price range of raound 4,500. ggplot(data = diamonds) + geom_histogram(mapping = aes(x = price), binwidth = 20) 3 - How many diamonds are 0.99 carat? How many are 1 carat? What do you think is the cause of the difference? diamonds %&gt;% filter(between(carat, .96, 1.05)) %&gt;% group_by(carat) %&gt;% summarize(count = n()) ## # A tibble: 10 x 2 ## carat count ## &lt;dbl&gt; &lt;int&gt; ## 1 0.960 103 ## 2 0.970 59 ## 3 0.980 31 ## 4 0.990 23 ## 5 1.00 1558 ## 6 1.01 2242 ## 7 1.02 883 ## 8 1.03 523 ## 9 1.04 475 ## 10 1.05 361 I am no diamond expert, but the data shows that there are way more 1ct diamonds than .99ct diamonds. (It could be the tendency of humans to report rounded numbers.) 4 - Compare and contrast coord_cartesian() vs xlim() or ylim() when zooming in on a histogram. What happens if you leave binwidth unset? What happens if you try and zoom so only half a bar shows? Let’s compare the difference between the functions when we set the x limits to 0 and 5000 and y limits to 0 and 700. We use the same histogram from the last question and leave the binwidth to 20. Using coord_cartesian: ggplot(data = diamonds) + geom_histogram(mapping = aes(x = price), binwidth = 20) + coord_cartesian(xlim = c(0,5000), ylim = c(0,700)) One thing to notice that even the x and y limit are set to 5000 and 700 respectively, some data beyond those limits are still being shown. We can override this behavior with expand = FALSE. xlim() and ylim(): ggplot(data = diamonds) + geom_histogram(mapping = aes(x = price), binwidth = 20) + xlim(c(0,5000)) + ylim(c(0,700)) ## Warning: Removed 14714 rows containing non-finite values (stat_bin). ## Warning: Removed 1 rows containing missing values (geom_bar). With xlim() and ylim(), data that are outside of the limits are not shown. It’s fine with the x axis, but do notice that there is a missing bin at around $700. For that particular bin, the height is beyond the y limit of 700. 7.4 Missing values 7.4.1 Exercises 1 - What happens to missing values in a histogram? What happens to missing values in a bar chart? Why is there a difference? In geom_histogram(), the missing values are removed. data.frame(value = c(NA, NA, NA, rnorm(1000,0,1))) %&gt;% ggplot() + geom_histogram(mapping = aes(x = value), bins = 50) ## Warning: Removed 3 rows containing non-finite values (stat_bin). In geom_bar(), the missing values are counted and treated as a category. ggplot(data = data.frame(type = c(&#39;A&#39;,&#39;A&#39;,&#39;B&#39;,&#39;B&#39;,&#39;B&#39;,NA))) + geom_bar(mapping = aes(x = type)) The reason for the difference is that essentially, histograms are used for displaying continuous variables, while bar charts are used for visualizing categorical variables. 2 - What does na.rm = TRUE do in mean() and sum()? If there are missing values in the vector, mean() and sum() will return NA. By including na.rm = TRUE, mean() and sum() will return the average and sum based on the non-missing values in the vector. For example: mean(c(1,2,3,NA,4), na.rm = TRUE) ## [1] 2.5 7.5 Covariation 7.5.1 A categorical and continuous variable 7.5.1.1 Exercises 1 - Use what you’ve learned to improve the visualisation of the departure times of cancelled vs. non-cancelled flights. The problem with the original visualisation of the departure times of cancelled vs. non-cancelled flights is that since there are far less cancelled flights, the distribution of non-cancelled flights looks flat when plotted together with non-cancelled flights. We can use freq_density() to force the area under each curve sums up to 1. nycflights13::flights %&gt;% mutate( cancelled = is.na(dep_time), sched_hour = sched_dep_time %/% 100, sched_min = sched_dep_time %% 100, sched_dep_time = sched_hour + sched_min / 60 ) %&gt;% ggplot(mapping = aes(sched_dep_time)) + geom_density(mapping = aes(colour = cancelled)) Or we can use geom_boxplot(). nycflights13::flights %&gt;% mutate( cancelled = is.na(dep_time), sched_hour = sched_dep_time %/% 100, sched_min = sched_dep_time %% 100, sched_dep_time = sched_hour + sched_min / 60 ) %&gt;% ggplot() + geom_boxplot(mapping = aes(x = cancelled, y = sched_dep_time)) 2 - What variable in the diamonds dataset is most important for predicting the price of a diamond? How is that variable correlated with cut? Why does the combination of those two relationships lead to lower quality diamonds being more expensive? Since cut, color, and clarity are ordered categorical variables, I made an assumption that they could be treated as continuous variables. Checking the correlation matrix: diamonds %&gt;% mutate(cut = as.numeric(cut), color = as.numeric(color), clarity = as.numeric(clarity)) %&gt;% select(price, everything()) %&gt;% cor() ## price carat cut color clarity ## price 1.00000000 0.92159130 -0.05349066 0.17251093 -0.14680007 ## carat 0.92159130 1.00000000 -0.13496702 0.29143675 -0.35284057 ## cut -0.05349066 -0.13496702 1.00000000 -0.02051852 0.18917474 ## color 0.17251093 0.29143675 -0.02051852 1.00000000 0.02563128 ## clarity -0.14680007 -0.35284057 0.18917474 0.02563128 1.00000000 ## depth -0.01064740 0.02822431 -0.21805501 0.04727923 -0.06738444 ## table 0.12713390 0.18161755 -0.43340461 0.02646520 -0.16032684 ## x 0.88443516 0.97509423 -0.12556524 0.27028669 -0.37199853 ## y 0.86542090 0.95172220 -0.12146187 0.26358440 -0.35841962 ## z 0.86124944 0.95338738 -0.14932254 0.26822688 -0.36695200 ## depth table x y z ## price -0.01064740 0.1271339 0.88443516 0.86542090 0.86124944 ## carat 0.02822431 0.1816175 0.97509423 0.95172220 0.95338738 ## cut -0.21805501 -0.4334046 -0.12556524 -0.12146187 -0.14932254 ## color 0.04727923 0.0264652 0.27028669 0.26358440 0.26822688 ## clarity -0.06738444 -0.1603268 -0.37199853 -0.35841962 -0.36695200 ## depth 1.00000000 -0.2957785 -0.02528925 -0.02934067 0.09492388 ## table -0.29577852 1.0000000 0.19534428 0.18376015 0.15092869 ## x -0.02528925 0.1953443 1.00000000 0.97470148 0.97077180 ## y -0.02934067 0.1837601 0.97470148 1.00000000 0.95200572 ## z 0.09492388 0.1509287 0.97077180 0.95200572 1.00000000 carat is the most correlated variable with price, so it is the most important variable in predicting price of diamonds. carat and cut are slightly negatively correlated, meaning diamonds of higher weights tend to have a lower cut rating. To answer the last question, we run an ordinary linear regression with carat, cut and carat*cut, the interaction effect, on price. diamonds_con &lt;- diamonds %&gt;% mutate(cut = as.numeric(cut), color = as.numeric(color), clarity = as.numeric(clarity)) summary(lm(price ~ carat + cut + carat*cut, data = diamonds_con)) ## ## Call: ## lm(formula = price ~ carat + cut + carat * cut, data = diamonds_con) ## ## Residuals: ## Min 1Q Median 3Q Max ## -14108.3 -779.4 -24.8 536.4 12983.9 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -2194.59 48.54 -45.209 &lt;2e-16 *** ## carat 6491.28 49.43 131.321 &lt;2e-16 *** ## cut -30.26 11.73 -2.579 0.0099 ** ## carat:cut 350.18 12.33 28.391 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1511 on 53936 degrees of freedom ## Multiple R-squared: 0.8566, Adjusted R-squared: 0.8566 ## F-statistic: 1.074e+05 on 3 and 53936 DF, p-value: &lt; 2.2e-16 The main effect of cut is -30.26, it does show over and above the effects of carat and the interaction between carat and cut, that higher cut quality leads to lower price. However, in the presense of a highly significant interaction effect, we need to interpret the main effect with interaction effect. Rearanging terms, we get price = cut * (-30.26 + 350.18 * carat) + 6491.28 * carat. Higher cut quality actually does lead to a higher price. 3 - Install the ggstance package, and create a horizontal boxplot. How does this compare to using coord_flip()? We can just simply add ’coord_flip()` to make the boxplot to be shown horizontally: nycflights13::flights %&gt;% mutate( cancelled = is.na(dep_time), sched_hour = sched_dep_time %/% 100, sched_min = sched_dep_time %% 100, sched_dep_time = sched_hour + sched_min / 60 ) %&gt;% ggplot() + geom_boxplot(mapping = aes(x = cancelled, y = sched_dep_time)) + coord_flip() However, when using geom_boxploth() from ggstance, the x and y in mapping need to be switched. library(ggstance) nycflights13::flights %&gt;% mutate( cancelled = is.na(dep_time), sched_hour = sched_dep_time %/% 100, sched_min = sched_dep_time %% 100, sched_dep_time = sched_hour + sched_min / 60 ) %&gt;% ggplot() + geom_boxploth(mapping = aes(y = cancelled, x = sched_dep_time)) 4 - One problem with boxplots is that they were developed in an era of much smaller datasets and tend to display a prohibitively large number of outlying values. One approach to remedy this problem is the letter value plot. Install the lvplot package, and try using geom_lv() to display the distribution of price vs cut. What do you learn? How do you interpret the plots? As stated in the problem, the traditional boxplot displays a large number of outliers: ggplot(data = diamonds) + geom_boxplot(mapping = aes(x = cut, y = price)) A letter value plot: library(lvplot) ggplot(data = diamonds) + geom_lv(mapping = aes(x = cut, y = price)) Interpretations - To Do. 5 - Compare and contrast geom_violin() with a facetted geom_histogram(), or a coloured geom_freqpoly(). What are the pros and cons of each method? Facetted histograms: diamonds %&gt;% ggplot() + geom_histogram(mapping = aes(x = price), binwidth = 50) + facet_grid(cut~.) By default, a facetted plot has fixed x and y scale. In this case, it is hard to see the distribution of price for fair diamonds because there are far less fair diamonds compared with the others. We are free the y scale by adding scales = 'free_y' in facet_grid. However, doing so will make the histograms less comparable in a sense that they will have different y scale. Another point about histogram is that the shape and appearance is sensitive to the number of bins or binwidth. geom_violin(): diamonds %&gt;% ggplot() + geom_violin(mapping = aes(x = cut, y = price)) The violin plot displays a compact view of continuous distributions. The curve in the violion is actually a probabilty density function, so the area always sums up to 1 (or 2 if you consider the mirrored part). However, it does not give us the information of which cut of diamonds are more or less abundant than others. geom_freqpoly: diamonds %&gt;% ggplot() + geom_freqpoly(mapping = aes(x = price, color = cut), binwidth = 50) Similiar to factted histogram, except they are represented as freqploy and plotted on the same graph. 6 - If you have a small dataset, it’s sometimes useful to use geom_jitter() to see the relationship between a continuous and categorical variable. The ggbeeswarm package provides a number of methods similar to geom_jitter(). List them and briefly describe what each one does. ggplot(data = mpg) + geom_jitter(mapping = aes(x = drv, y = displ)) geom_jitter() slightly shifts the data horizontally and vertically randomly to overcome overplotting. library(ggbeeswarm) ggplot(data = mpg) + geom_beeswarm(mapping = aes(x = drv, y = displ), priority = &#39;ascending&#39;) geom_beeswarm() is another way to overcome overplotting. Instead of adding random variations along the x and y axis, it “lines up” the data points and also shows the distribution. 7.5.2 Two categorical variables 7.5.2.1 Exercises 1 - How could you rescale the count dataset above to more clearly show the distribution of cut within colour, or colour within cut? The original plot shows the counts for each combination of cut and color. Since both cut and color are categorical variables, we cannot use geom_density() to show the distribtuion of cut within color, or color with cut. Instead, we can calculate the proportion of each cut within color, and vice versa. Here, we rescale the dataset and show the distribution of cut within color: diamonds %&gt;% count(color, cut) %&gt;% group_by(color) %&gt;% mutate(prop = n / sum(n)) %&gt;% ggplot() + geom_tile(mapping = aes(x = color, y = cut, fill = prop)) + labs(title = &#39;Distribution of cut within color&#39;) 2 - Use geom_tile() together with dplyr to explore how average flight delays vary by destination and month of year. What makes the plot difficult to read? How could you improve it? nycflights13::flights %&gt;% group_by(dest, month) %&gt;% summarize(avg_dep_delay = mean(dep_delay, na.rm = TRUE)) %&gt;% ggplot() + geom_tile(mapping = aes(x = month, y = dest, fill = avg_dep_delay)) The plot is not easy to read because: the color scale range makes it hard to distinguish and compare airports and months there are empty cells, which denote missing values (no flights departed from the airport, different from averaged delayed in 0 minutes) the x label is incorrect We will keep the NA cells for two reasons: not ideal if we remove the entire row. The non-missing cells still represent data. NA actually reflects that no flights departed in the origin airports in that particular month (which is odd, but that’s the data we are given). Let’s just assumme it means something. We will arrange the plot so that airports with missing months will be shown at the bottom, and manually set the gradient scale: nycflights13::flights %&gt;% group_by(dest, month) %&gt;% summarize(avg_dep_delay = mean(dep_delay, na.rm = TRUE)) %&gt;% ungroup() %&gt;% group_by(dest) %&gt;% mutate(n_month = n())%&gt;% ggplot() + geom_tile(mapping = aes(x = factor(month), y = reorder(dest, n_month), fill = avg_dep_delay)) + scale_fill_gradient2(low = &#39;yellow&#39;, mid = &#39;orange&#39;, high = &#39;red&#39;, midpoint = 35) 3 - Why is it slightly better to use aes(x = color, y = cut) rather than aes(x = cut, y = color) in the example above? diamonds %&gt;% count(color, cut) %&gt;% group_by(color) %&gt;% mutate(prop = n / sum(n)) %&gt;% ggplot() + geom_tile(mapping = aes(x = cut, y = color, fill = prop)) + labs(title = &#39;Distribution of cut within color&#39;) 7.5.3 Two continuous variables 7.5.3.1 Exercises 1 - Instead of summarising the conditional distribution with a boxplot, you could use a frequency polygon. What do you need to consider when using cut_width() vs cut_number()? How does that impact a visualisation of the 2d distribution of carat and price? Unlike geom_density(), geom_freqpoly() is a smoothered histogram, so the height of each polygon is affected by the number of observations in each group. Setting the cut_width too small will have too many categories. Some of the categories will have very few observations, resulting in polygons that are flat and close to the x-axis. Compare the cut_width of .2 and .4: diamonds %&gt;% ggplot() + geom_freqpoly(mapping = aes(x = price, color = cut_width(carat, .2)), bins = 30) diamonds %&gt;% ggplot() + geom_freqpoly(mapping = aes(x = price, color = cut_width(carat, .4)), bins = 30) Since most of the diamonds are below 1 carat, in both plots, the polygons of above 1 carat are flat, and some are not distingushable from others. In contrast, cut_number() ensures the same number of observations in each group. diamonds %&gt;% ggplot() + geom_freqpoly(mapping = aes(x = price, color = cut_number(carat, 10)), bins = 30) 2 - Visualise the distribution of carat, partitioned by price. Using geom_density() and partitioning by price with cut_width, it is not surprising to see that diamonds of higher carat are associated with higher price in general. diamonds %&gt;% ggplot() + geom_density(mapping = aes(x = carat, color = cut_width(price, 5000, boundary = 0))) 3 - How does the price distribution of very large diamonds compare to small diamonds. Is it as you expect, or does it surprise you? diamonds %&gt;% ggplot + geom_boxplot(mapping = aes(x = cut_number(carat, 10), y = price)) + coord_flip() The price distribution of very large diamonds are much more variable than the smaller diamonds. Perhaps other factors, such as cut, clarity, and color have heavier influence on the price of larger diamonds. 4 - Combine two of the techniques you’ve learned to visualise the combined distribution of cut, carat, and price. We can use boxplot: diamonds %&gt;% ggplot() + geom_boxplot(mapping = aes(x = cut, y = price, color = cut_number(carat, 5))) Heatmap: diamonds %&gt;% mutate(carat_group = cut_number(carat, 10)) %&gt;% group_by(cut, carat_group) %&gt;% summarize(avg_price = mean(price)) %&gt;% ggplot() + geom_tile(mapping = aes(x = cut, y = carat_group, fill = avg_price)) Facetted geom_bin2d(): diamonds %&gt;% ggplot() + geom_bin2d(mapping = aes(x = carat, y = price)) + facet_grid(cut~.) 5 - Two dimensional plots reveal outliers that are not visible in one dimensional plots. For example, some points in the plot below have an unusual combination of x and y values, which makes the points outliers even though their x and y values appear normal when examined separately. ggplot(data = diamonds) + geom_point(mapping = aes(x = x, y = y)) + coord_cartesian(xlim = c(4, 11), ylim = c(4, 11)) Why is a scatterplot a better display than a binned plot for this case? In the scatterplot above, we can identity the outliers while at the same time observe the strong positive correlation between x and y. Compare this with a binned plot: ggplot(data = diamonds) + geom_bin2d(mapping = aes(x = x, y = y), bins = 800) + coord_cartesian(xlim = c(4, 11), ylim = c(4, 11)) Even though they look similarly, I believe the logical reasoning behind why scatterplot is superior in this case is that it focuses on showing the locations of each individual point, rather than the binned counts, thus it’s more suitable for the purpose of identifying outliers. 7.6 Patterns and models No exercises. 7.7 ggplot2 calls No exercises. 7.8 Learning more No exercises. "],
["workflow-projects.html", "8 Workflow: projects", " 8 Workflow: projects No exercises. "],
["introduction-5.html", "9 Introduction", " 9 Introduction No exercises. "],
["tibbles.html", "10 Tibbles 10.1 Introduction 10.2 Creating tibbles 10.3 Tibbles vs. data.frame 10.4 Interacting with older code 10.5 Exercises", " 10 Tibbles 10.1 Introduction No exercises. 10.2 Creating tibbles No exercises. 10.3 Tibbles vs. data.frame No exercises. 10.4 Interacting with older code No exercises. 10.5 Exercises 1 - How can you tell if an object is a tibble? (Hint: try printing mtcars, which is a regular data frame). There are many ways to tell if an object is a tibble. We can look at the class type: class(mtcars) ## [1] &quot;data.frame&quot; Which shows mtcars is a data.frame. Printing mtcars also reveals that it’s not tibble because it does not print ‘A tibble’ in the first row, it does not only show the first 10 rows, and all the columns do not fit on screen. Also, the type of each column is not reported. 2 - Compare and contrast the following operations on a data.frame and equivalent tibble. What is different? Why might the default data frame behaviours cause you frustration? Creating tibble in R is pretty much the same as creating a data.frame object. library(tidyverse) df &lt;- data.frame(abc = 1, xyz = &quot;a&quot;) tdf &lt;- tibble(abc = 1, xyz = &quot;a&quot;) However, in data.frame, strings are coerced into factors. str(df) ## &#39;data.frame&#39;: 1 obs. of 2 variables: ## $ abc: num 1 ## $ xyz: Factor w/ 1 level &quot;a&quot;: 1 While in tibble, strings are still strings. str(tdf) ## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 1 obs. of 2 variables: ## $ abc: num 1 ## $ xyz: chr &quot;a&quot; tibble does not do partial matching. It’s perfectly fine to do this in data.frame: df$x ## [1] a ## Levels: a but we have to type the complete variable name in tibble: tdf$xyz ## [1] &quot;a&quot; In data.frame, subsetting only one column with [ ]will return a vector, instead of a data.frame with one column: df[,&#39;xyz&#39;] ## [1] a ## Levels: a In tibble, the same operation will return a tibble with a single column: tdf[,&#39;xyz&#39;] ## # A tibble: 1 x 1 ## xyz ## &lt;chr&gt; ## 1 a 3 - If you have the name of a variable stored in an object, e.g. var &lt;- &quot;mpg&quot;, how can you extract the reference variable from a tibble? We will not be able to use $ to subset the columns. Instead we need to use [``]. tibble_mtcars &lt;- as.tibble(mtcars) var &lt;- &#39;mpg&#39; tibble_mtcars[var] ## # A tibble: 32 x 1 ## mpg ## &lt;dbl&gt; ## 1 21.0 ## 2 21.0 ## 3 22.8 ## 4 21.4 ## 5 18.7 ## 6 18.1 ## 7 14.3 ## 8 24.4 ## 9 22.8 ## 10 19.2 ## # ... with 22 more rows 4 - Practice referring to non-syntactic names in the following data frame by: annoying &lt;- tibble( `1` = 1:10, `2` = `1` * 2 + rnorm(length(`1`)) ) 1. Extracting the variable called 1. annoying$`1` ## [1] 1 2 3 4 5 6 7 8 9 10 2. Plotting a scatterplot of 1 vs 2. annoying %&gt;% ggplot() + geom_point(mapping = aes(x = `1`, y = `2`)) 3. Creating a new column called 3 which is 2 divided by 1. annoying$`3` &lt;- annoying$`2` / annoying$`1` annoying ## # A tibble: 10 x 3 ## `1` `2` `3` ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1.90 1.90 ## 2 2 5.10 2.55 ## 3 3 6.48 2.16 ## 4 4 9.01 2.25 ## 5 5 11.3 2.27 ## 6 6 13.7 2.28 ## 7 7 13.9 1.99 ## 8 8 15.7 1.97 ## 9 9 17.6 1.95 ## 10 10 19.5 1.95 4. Renaming the columns to one, two and three. annoying %&gt;% rename(one = `1`, two = `2`, three = `3`) ## # A tibble: 10 x 3 ## one two three ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1.90 1.90 ## 2 2 5.10 2.55 ## 3 3 6.48 2.16 ## 4 4 9.01 2.25 ## 5 5 11.3 2.27 ## 6 6 13.7 2.28 ## 7 7 13.9 1.99 ## 8 8 15.7 1.97 ## 9 9 17.6 1.95 ## 10 10 19.5 1.95 5 - What does tibble::enframe() do? When might you use it? From the documentation, enframe() converts named atomic vectors or lists to two-column data frames. For unnamed vectors, the natural sequence is used as name column. For example: x &lt;- c(Joe = 24, May = 33, Jack = 55) enframe(x, name = &#39;Name&#39;, value = &#39;Age&#39;) ## # A tibble: 3 x 2 ## Name Age ## &lt;chr&gt; &lt;dbl&gt; ## 1 Joe 24.0 ## 2 May 33.0 ## 3 Jack 55.0 6 - What option controls how many additional column names are printed at the footer of a tibble? By default, information of all remaining columns are printed at the footer. To limit the number of additional column information, we can use the argument n_extra. For exampe: print(nycflights13::flights, n_extra = 2) ## # A tibble: 336,776 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2.00 830 ## 2 2013 1 1 533 529 4.00 850 ## 3 2013 1 1 542 540 2.00 923 ## 4 2013 1 1 544 545 -1.00 1004 ## 5 2013 1 1 554 600 -6.00 812 ## 6 2013 1 1 554 558 -4.00 740 ## 7 2013 1 1 555 600 -5.00 913 ## 8 2013 1 1 557 600 -3.00 709 ## 9 2013 1 1 557 600 -3.00 838 ## 10 2013 1 1 558 600 -2.00 753 ## # ... with 336,766 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, ... "],
["data-import.html", "11 Data Import 11.1 Introduction 11.2 Getting started 11.3 Parsing a vector 11.4 Parsing a file 11.5 Writing to a file 11.6 Other types of data", " 11 Data Import 11.1 Introduction No exercises 11.2 Getting started 11.2.1 Exercises library(tidyverse) library(readr) 1 - What function would you use to read a file where fields were separated with |? We can use read_delim(): read_delim(&quot;a|b|c\\n1|2|3\\n4|5|6&quot;, delim = &quot;|&quot;) ## # A tibble: 2 x 3 ## a b c ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 2 3 ## 2 4 5 6 2 - Apart from file, skip, and comment, what other arguments do read_csv() and read_tsv() have in common? read_csv() and read_tsv() have the same arguments. They only difference is that one is comma delimited, and the other is tab delimited. 3 - What are the most important arguments to read_fwf()? The most important argument is col_positions, which defines the column positions. 4 - Sometimes strings in a CSV file contain commas. To prevent them from causing problems they need to be surrounded by a quoting character, like &quot; or '. By convention, read_csv() assumes that the quoting character will be &quot;, and if you want to change it you’ll need to use read_delim() instead. What arguments do you need to specify to read the following text into a data frame? &quot;x,y\\n1,&#39;a,b&#39;&quot; The argument is quote, and we can use it in read_csv(), read_csv2(), and read_tsv() as well. For example: read_csv(&quot;x,y\\n1,&#39;a,b&#39;&quot;, quote = &quot;\\&#39;&quot;) ## # A tibble: 1 x 2 ## x y ## &lt;int&gt; &lt;chr&gt; ## 1 1 a,b 5 - Identify what is wrong with each of the following inline CSV files. What happens when you run the code? read_csv(&quot;a,b\\n1,2,3\\n4,5,6&quot;) ## Warning: 2 parsing failures. ## row # A tibble: 2 x 5 col row col expected actual file expected &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; actual 1 1 &lt;NA&gt; 2 columns 3 columns literal data file 2 2 &lt;NA&gt; 2 columns 3 columns literal data ## # A tibble: 2 x 2 ## a b ## &lt;int&gt; &lt;int&gt; ## 1 1 2 ## 2 4 5 Only two columns names are provided, so the values in the last column are dropped. read_csv(&quot;a,b,c\\n1,2\\n1,2,3,4&quot;) ## Warning: 2 parsing failures. ## row # A tibble: 2 x 5 col row col expected actual file expected &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; actual 1 1 &lt;NA&gt; 3 columns 2 columns literal data file 2 2 &lt;NA&gt; 3 columns 4 columns literal data ## # A tibble: 2 x 3 ## a b c ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 2 NA ## 2 1 2 3 Only three column names are provided. The value in the last column in the last row is dropped, and NA is coerced in the third column of second row. read_csv(&quot;a,b\\n\\&quot;1&quot;) ## Warning: 2 parsing failures. ## row # A tibble: 2 x 5 col row col expected actual file expected &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; actual 1 1 a closing quote at end of file &quot;&quot; literal data file 2 1 &lt;NA&gt; 2 columns 1 columns literal data ## # A tibble: 1 x 2 ## a b ## &lt;int&gt; &lt;chr&gt; ## 1 1 &lt;NA&gt; The open quote \\&quot; is dropped because there is no paired close quote. There is only one value in the second row, so NA is coerced in the second column. read_csv(&quot;a,b\\n1,2\\na,b&quot;) ## # A tibble: 2 x 2 ## a b ## &lt;chr&gt; &lt;chr&gt; ## 1 1 2 ## 2 a b Since the second rows are strings, the entire columns are coerced into strings. read_csv(&quot;a;b\\n1;3&quot;) ## # A tibble: 1 x 1 ## `a;b` ## &lt;chr&gt; ## 1 1;3 read_csv() looks for commas, not semi-colons. Everything is treated as one column name and one value. 11.3 Parsing a vector 11.3.1 Exercises 1 - What are the most important arguments to locale()? locale() comes with a number of arguments. They are all important and useful whne parsing different types of variables. Type ?locale() for a complete list of arguments. 2 - What happens if you try and set decimal_mark and grouping_mark to the same character? What happens to the default value of grouping_mark when you set decimal_mark to ,? What happens to the default value of decimal_mark when you set the grouping_mark to .? Explicitly setting decimal_mark and grouping_mark to the same character will give you an error. If we only set decimal_mark to “,”, grouping_mark will be set to ‘.’ automatically. locale(decimal_mark = &#39;,&#39;) ## &lt;locale&gt; ## Numbers: 123.456,78 ## Formats: %AD / %AT ## Timezone: UTC ## Encoding: UTF-8 ## &lt;date_names&gt; ## Days: Sunday (Sun), Monday (Mon), Tuesday (Tue), Wednesday (Wed), ## Thursday (Thu), Friday (Fri), Saturday (Sat) ## Months: January (Jan), February (Feb), March (Mar), April (Apr), May ## (May), June (Jun), July (Jul), August (Aug), September ## (Sep), October (Oct), November (Nov), December (Dec) ## AM/PM: AM/PM 3 - I didn’t discuss the date_format and time_format options to locale(). What do they do? Construct an example that shows when they might be useful. date_format and time_format specify the default date and time format respectively. parse_date() and parse_time() use the date_format and time_format specified by locale(). For example: parse_date(&quot;01/02/15&quot;, locale = locale(date_format = &quot;%d/%m/%y&quot;)) ## [1] &quot;2015-02-01&quot; Alternatively, we can specify the date format in the format argument: parse_date(&quot;01/02/15&quot;, format = &quot;%d/%m/%y&quot;) ## [1] &quot;2015-02-01&quot; 4 - If you live outside the US, create a new locale object that encapsulates the settings for the types of file you read most commonly. For example, we can change the date_names argument to something else if the spelling of months are different. 5 - What’s the difference between read_csv() and read_csv2()? read_csv() is comma delimited. read_csv2() is semi-colon delimited. 6 - What are the most common encodings used in Europe? What are the most common encodings used in Asia? Do some googling to find out. Check out this Wikipage. 7 - Generate the correct format string to parse each of the following dates and times: d1 &lt;- &quot;January 1, 2010&quot; parse_date(d1, &quot;%B %d, %Y&quot;) ## [1] &quot;2010-01-01&quot; d2 &lt;- &quot;2015-Mar-07&quot; parse_date(d2, &quot;%Y-%b-%d&quot;) ## [1] &quot;2015-03-07&quot; d3 &lt;- &quot;06-Jun-2017&quot; parse_date(d3, &quot;%d-%b-%Y&quot;) ## [1] &quot;2017-06-06&quot; d4 &lt;- c(&quot;August 19 (2015)&quot;, &quot;July 1 (2015)&quot;) parse_date(d4, &quot;%B %d (%Y)&quot;) ## [1] &quot;2015-08-19&quot; &quot;2015-07-01&quot; d5 &lt;- &quot;12/30/14&quot; # Dec 30, 2014 parse_date(d5, &quot;%m/%d/%y&quot;) ## [1] &quot;2014-12-30&quot; t1 &lt;- &quot;1705&quot; parse_time(t1, &quot;%H%M&quot;) ## 17:05:00 t2 &lt;- &quot;11:15:10.12 PM&quot; parse_time(t2, &quot;%I:%M:%OS %p&quot;) ## 23:15:10.12 11.4 Parsing a file No exercises. 11.5 Writing to a file No exercises. 11.6 Other types of data No exercises. "],
["tidy-data.html", "12 Tidy data 12.1 Introduction 12.2 Tidy data 12.3 Spreading and gathering 12.4 Separating and uniting 12.5 Missing values 12.6 Case Study 12.7 Non-tidy data", " 12 Tidy data 12.1 Introduction No exercises. 12.2 Tidy data 12.2.1 Exercises library(tidyverse) 1- Using prose, describe how the variables and observations are organised in each of the sample tables. In table1, each observation has its own row and each variable has its own column. ## # A tibble: 6 x 4 ## country year cases population ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 1272915272 ## 6 China 2000 213766 1280428583 In table2, each row represents the country, year, and the variable type of either case or population. The variable count represents the unique value for the variable type. ## # A tibble: 12 x 4 ## country year type count ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 Afghanistan 1999 cases 745 ## 2 Afghanistan 1999 population 19987071 ## 3 Afghanistan 2000 cases 2666 ## 4 Afghanistan 2000 population 20595360 ## 5 Brazil 1999 cases 37737 ## 6 Brazil 1999 population 172006362 ## 7 Brazil 2000 cases 80488 ## 8 Brazil 2000 population 174504898 ## 9 China 1999 cases 212258 ## 10 China 1999 population 1272915272 ## 11 China 2000 cases 213766 ## 12 China 2000 population 1280428583 In table3, the variables case and count are mutated into a new variable rate. ## # A tibble: 6 x 3 ## country year rate ## * &lt;chr&gt; &lt;int&gt; &lt;chr&gt; ## 1 Afghanistan 1999 745/19987071 ## 2 Afghanistan 2000 2666/20595360 ## 3 Brazil 1999 37737/172006362 ## 4 Brazil 2000 80488/174504898 ## 5 China 1999 212258/1272915272 ## 6 China 2000 213766/1280428583 In table4, cases and population are represented in separate tables. Years 1999 and 2000 are treated as different variables. ## # A tibble: 3 x 3 ## country `1999` `2000` ## * &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 745 2666 ## 2 Brazil 37737 80488 ## 3 China 212258 213766 ## # A tibble: 3 x 3 ## country `1999` `2000` ## * &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 19987071 20595360 ## 2 Brazil 172006362 174504898 ## 3 China 1272915272 1280428583 2 - Compute the rate for table2, and table4a + table4b. You will need to perform four operations: 1. Extract the number of TB cases per country per year. 2. Extract the matching population per country per year. 3. Divide cases by population, and multiply by 10000. 4. Store back in the appropriate place. Which representation is easiest to work with? Which is hardest? Why? Using only the techniques covered so far, for table2: countries &lt;- filter(table2, type == &#39;cases&#39;)$country years &lt;- filter(table2, type == &#39;cases&#39;)$year cases &lt;- filter(table2, type == &#39;cases&#39;)$count populations &lt;- filter(table2, type == &#39;population&#39;)$count table2_rate &lt;- tibble(country = countries, year = years, rate = cases/populations * 10000) table2_rate ## # A tibble: 6 x 3 ## country year rate ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Afghanistan 1999 0.373 ## 2 Afghanistan 2000 1.29 ## 3 Brazil 1999 2.19 ## 4 Brazil 2000 4.61 ## 5 China 1999 1.67 ## 6 China 2000 1.67 and table4a + table4b: countries &lt;- table4a$country cases_1999 &lt;- table4a$`1999` cases_2000 &lt;- table4a$`2000` populations_1999 &lt;- table4b$`1999` populations_2000 &lt;- table4b$`2000` table_1999_rate &lt;- tibble(country = countries, year = 1999, rate = cases_1999 / populations_1999 * 10000) table_2000_rate &lt;- tibble(country = countries, year = 2000, rate = cases_2000 / populations_2000 * 10000) table4_rate &lt;- rbind(table_1999_rate, table_2000_rate) %&gt;% arrange(country) table4_rate ## # A tibble: 6 x 3 ## country year rate ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanistan 1999 0.373 ## 2 Afghanistan 2000 1.29 ## 3 Brazil 1999 2.19 ## 4 Brazil 2000 4.61 ## 5 China 1999 1.67 ## 6 China 2000 1.67 ‘table2’ is much more easier to work with, and involves less intermediate steps. 3 - Recreate the plot showing change in cases over time using table2 instead of table1. What do you need to do first? We need to first filter table2 to include only the rows for cases. table2 %&gt;% filter(type == &#39;cases&#39;) %&gt;% ggplot(aes(x = year, y= count)) + geom_line(mapping = aes(group = country), color = &#39;grey50&#39;) + geom_point(mapping = aes(color = country)) + labs(y = &#39;cases&#39;) + scale_x_continuous(breaks = (c(1999,2000))) 12.3 Spreading and gathering 12.3.1 Exercises 1 - Why are gather() and spread() not perfectly symmetrical? Carefully consider the following example: ## # A tibble: 4 x 3 ## half year return ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1.00 2015 1.88 ## 2 2.00 2015 0.590 ## 3 1.00 2016 0.920 ## 4 2.00 2016 0.170 (Hint: look at the variable types and think about column names.) Both spread() and gather() have a convert argument. What does it do? spread() and gather() are complements but might produce tibbles that are not perfectly symmetrical. Comparing the original stocks and with the maniuplated one: stocks ## # A tibble: 4 x 3 ## year half return ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2015 1.00 1.88 ## 2 2015 2.00 0.590 ## 3 2016 1.00 0.920 ## 4 2016 2.00 0.170 We see that the column positions different. We can show that in the intermediate spread() step, half becomes the first column, and 2015 and 2016 become the second and third column: stocks %&gt;% spread(year, return) ## # A tibble: 2 x 3 ## half `2015` `2016` ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1.00 1.88 0.920 ## 2 2.00 0.590 0.170 Consequently, the column half stays in the first column after gather(). In addition to the positions of columns, the data type for year was converted from dbl to chr. In the intermediate step, spread(), 2015 and 2016 became the names of the variables. So when using gather(), 2015 and 2016 were naturally treated as strings, and the variable type for year became chr. To override this behavior, we can add convert = TRUE in gather(). It is useful if the column names are actually numeric, integer, or logical. stocks %&gt;% spread(year, return) %&gt;% gather(&quot;year&quot;, &quot;return&quot;, `2015`:`2016`, convert = TRUE) ## # A tibble: 4 x 3 ## half year return ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1.00 2015 1.88 ## 2 2.00 2015 0.590 ## 3 1.00 2016 0.920 ## 4 2.00 2016 0.170 2 - Why does this code fail? table4a %&gt;% gather(1999, 2000, key = &quot;year&quot;, value = &quot;cases&quot;) #&gt; Error in combine_vars(vars, ind_list): Position must be between 0 and n We need to add backticks around 1999 and 2000 since the variable names are numeric and hence non-syntatic. table4a %&gt;% gather(`1999`, `2000`, key = &quot;year&quot;, value = &quot;cases&quot;) ## # A tibble: 6 x 3 ## country year cases ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Afghanistan 1999 745 ## 2 Brazil 1999 37737 ## 3 China 1999 212258 ## 4 Afghanistan 2000 2666 ## 5 Brazil 2000 80488 ## 6 China 2000 213766 3 - Why does spreading this tibble fail? How could you add a new column to fix the problem? people &lt;- tribble( ~name, ~key, ~value, #-----------------|--------|------ &quot;Phillip Woods&quot;, &quot;age&quot;, 45, &quot;Phillip Woods&quot;, &quot;height&quot;, 186, &quot;Phillip Woods&quot;, &quot;age&quot;, 50, &quot;Jessica Cordero&quot;, &quot;age&quot;, 37, &quot;Jessica Cordero&quot;, &quot;height&quot;, 156 ) Spreading this tibble will fail because there are duplicated rows, i.e., there are two rows of “Phillip Woods” with key “age”. In other words, a single cell cannot be both 45 and 50 at the same time. We can add a new column to to make those rows to be not duplicates. people %&gt;% group_by(name, key) %&gt;% mutate(id = row_number()) ## # A tibble: 5 x 4 ## # Groups: name, key [4] ## name key value id ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Phillip Woods age 45.0 1 ## 2 Phillip Woods height 186 1 ## 3 Phillip Woods age 50.0 2 ## 4 Jessica Cordero age 37.0 1 ## 5 Jessica Cordero height 156 1 Now we can use spread(): people %&gt;% group_by(name, key) %&gt;% mutate(id = row_number()) %&gt;% spread(key = &quot;key&quot;, value = &quot;value&quot;) %&gt;% select(-id) ## # A tibble: 3 x 3 ## # Groups: name [2] ## name age height ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Jessica Cordero 37.0 156 ## 2 Phillip Woods 45.0 186 ## 3 Phillip Woods 50.0 NA 4 - Tidy the simple tibble below. Do you need to spread or gather it? What are the variables? preg &lt;- tribble( ~pregnant, ~male, ~female, &quot;yes&quot;, NA, 10, &quot;no&quot;, 20, 12 ) This simple tibble appears to represent three observations: 1 - pregnant female of some value 10 2 - non-pregnant male of some value 20 3 - non-pregnant female of some value 12 We can use gather(): preg %&gt;% gather(key = &#39;gender&#39;, value = &#39;value&#39;, 2:3) ## # A tibble: 4 x 3 ## pregnant gender value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 yes male NA ## 2 no male 20.0 ## 3 yes female 10.0 ## 4 no female 12.0 12.4 Separating and uniting 12.4.1 Exercises 1 - What do the extra and fill arguments do in separate()? Experiment with the various options for the following two toy datasets. extra controls what happens when the separated pieces are more than the number of variables defined in into. The default option is warn, which shows a warning and drops extra pieces. The option drop drops extra pieces without giving a warning. tibble(x = c(&quot;a,b,c&quot;, &quot;d,e,f,g&quot;, &quot;h,i,j&quot;)) %&gt;% separate(x, c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;), extra = &#39;drop&#39;) ## # A tibble: 3 x 3 ## one two three ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a b c ## 2 d e f ## 3 h i j The last option merge will only split at most length(into) times. tibble(x = c(&quot;a,b,c&quot;, &quot;d,e,f,g&quot;, &quot;h,i,j&quot;)) %&gt;% separate(x, c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;), extra = &#39;merge&#39;) ## # A tibble: 3 x 3 ## one two three ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a b c ## 2 d e f,g ## 3 h i j fill is similar to extra, except it controls what happens if the separated pieces are less than the number of variables defined in into. By default, it fills with NA on the right and gives a warning. The option right fills with NAs on the right without a warning. tibble(x = c(&quot;a,b,c&quot;, &quot;d,e&quot;, &quot;f,g,i&quot;)) %&gt;% separate(x, c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;), fill = &#39;right&#39;) ## # A tibble: 3 x 3 ## one two three ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a b c ## 2 d e &lt;NA&gt; ## 3 f g i The option left fills with NAs on the left. tibble(x = c(&quot;a,b,c&quot;, &quot;d,e&quot;, &quot;f,g,i&quot;)) %&gt;% separate(x, c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;), fill = &#39;left&#39;) ## # A tibble: 3 x 3 ## one two three ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a b c ## 2 &lt;NA&gt; d e ## 3 f g i 2 - Both unite() and separate() have a remove argument. What does it do? Why would you set it to FALSE? The remove argument is set to TRUE by default. It removes input columns from output data frame. If set to FALSE, the original separate column, or the united columns, are retained in the output. In table3, the year column is separated into century and year, but is retained in the output. table3 %&gt;% separate(year, into = c(&quot;century&quot;, &quot;year&quot;), sep = 2, remove = FALSE) ## # A tibble: 6 x 4 ## country rate century year ## * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 745/19987071 19 99 ## 2 Afghanistan 2666/20595360 20 00 ## 3 Brazil 37737/172006362 19 99 ## 4 Brazil 80488/174504898 20 00 ## 5 China 212258/1272915272 19 99 ## 6 China 213766/1280428583 20 00 In table5, the century and year columns are united as new, but are retained in the output. table5 %&gt;% unite(new, century, year, sep = &quot;&quot;, remove = FALSE) ## # A tibble: 6 x 5 ## country new century year rate ## * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 1999 19 99 745/19987071 ## 2 Afghanistan 2000 20 00 2666/20595360 ## 3 Brazil 1999 19 99 37737/172006362 ## 4 Brazil 2000 20 00 80488/174504898 ## 5 China 1999 19 99 212258/1272915272 ## 6 China 2000 20 00 213766/1280428583 3 - Compare and contrast separate() and extract(). Why are there three variations of separation (by position, by separator, and with groups), but only one unite? extract() uses regluar expression to capture groups and turn groups into multiple columns. There are many ways to separate a column into multiple columns. In contrast, there is only one way to put together multiple columns into a single column. 12.5 Missing values 12.5.1 Exercises 1 - Compare and contrast the fill arguments to spread() and complete(). In spread(), all NAs will be replaced by the fill value. The fill argument only takes in one value. In complete(), NAs under different columns can be replaced by different values. The fill argument takes in a list that specifies the values to replace NA for different columns?fill. 2 - What does the direction argument to fill() do? The default value is down. Any NAs will be replaced by the previous non-missing value. The filling direction can be reversed if .direction is set to up. 12.6 Case Study 12.6.1 Exercises 1 - In this case study I set na.rm = TRUE just to make it easier to check that we had the correct values. Is this reasonable? Think about how missing values are represented in this dataset. Are there implicit missing values? What’s the difference between an NA and zero? First we can check if there are any implicit missing values by looking at the first and the last year of recorded data for each country: who %&gt;% group_by(country) %&gt;% summarize(year_min = min(year), year_max = max(year)) %&gt;% ggplot() + geom_point(mapping = aes(x = country, y = year_min), color = &#39;red&#39;) + geom_point(mapping = aes(x = country , y= year_max), color = &#39;blue&#39;) + coord_flip() We can see that most countries have their first recorded data in 1980, and last recorded data in 2013, with the exception for a few countries. That means that there are implicit missing values - the values in some years for a certain few countries simply do not appear in the data set. Another way to investigate this and to confirm our finding is to look at the number of years of recorded data for each country: who %&gt;% group_by(country) %&gt;% summarize(count = n()) %&gt;% ggplot() + geom_point(mapping = aes(x = country, y = count), color = &#39;green&#39;) + coord_flip() Again, we see that while most countries have 34 years of recorded data, some countries have less. We also check if there are any 0 recorded cases: sum(who %&gt;% select(-c(1:4)) == 0, na.rm = TRUE) ## [1] 11080 There are cases that have a recorded value of 0, which mean they are explicitly stated as no-case. We then also check the number of NAs in each column: who %&gt;% select(-c(1:4)) %&gt;% sapply(function(x){sum(is.na(x))}) ## new_sp_m014 new_sp_m1524 new_sp_m2534 new_sp_m3544 new_sp_m4554 ## 4067 4031 4034 4021 4017 ## new_sp_m5564 new_sp_m65 new_sp_f014 new_sp_f1524 new_sp_f2534 ## 4022 4031 4066 4046 4040 ## new_sp_f3544 new_sp_f4554 new_sp_f5564 new_sp_f65 new_sn_m014 ## 4041 4036 4045 4043 6195 ## new_sn_m1524 new_sn_m2534 new_sn_m3544 new_sn_m4554 new_sn_m5564 ## 6210 6218 6215 6213 6219 ## new_sn_m65 new_sn_f014 new_sn_f1524 new_sn_f2534 new_sn_f3544 ## 6220 6200 6218 6224 6220 ## new_sn_f4554 new_sn_f5564 new_sn_f65 new_ep_m014 new_ep_m1524 ## 6222 6223 6221 6202 6214 ## new_ep_m2534 new_ep_m3544 new_ep_m4554 new_ep_m5564 new_ep_m65 ## 6220 6216 6220 6225 6222 ## new_ep_f014 new_ep_f1524 new_ep_f2534 new_ep_f3544 new_ep_f4554 ## 6208 6219 6219 6219 6223 ## new_ep_f5564 new_ep_f65 newrel_m014 newrel_m1524 newrel_m2534 ## 6223 6226 7050 7058 7057 ## newrel_m3544 newrel_m4554 newrel_m5564 newrel_m65 newrel_f014 ## 7056 7056 7055 7058 7050 ## newrel_f1524 newrel_f2534 newrel_f3544 newrel_f4554 newrel_f5564 ## 7056 7058 7057 7057 7057 ## newrel_f65 ## 7055 These NAs are explicitly stated as missing values. Also notice that the number of NAs in each column are different, which means that in a given year for a country, there are both missing and non-missing cases. Depending on the importance of NAs and their interpretations, setting na.rm = TRUE can be reasonable. 2 - What happens if you neglect the mutate() step? (mutate(key = stringr::str_replace(key, &quot;newrel&quot;, &quot;new_rel&quot;))) The code will not be separated properly into the three columns new, var, and sexage. 3 - I claimed that iso2 and iso3 were redundant with country. Confirm this claim. A crude way to confirm this is to check the number of unique values in country, iso2, and iso3. who %&gt;% select(1:3) %&gt;% sapply(function(x){length(unique(x))}) ## country iso2 iso3 ## 219 219 219 and check the number of unique combinations of these columns who %&gt;% select(1:3) %&gt;% unite(combined, 1:3) %&gt;% select(combined) %&gt;% distinct() %&gt;% nrow() ## [1] 219 Thus we can confirm that for each country, there is only one iso2 code, and also one iso3 code. iso2 and iso3 are redundant columns. 4 - For each country, year, and sex compute the total number of cases of TB. Make an informative visualisation of the data. Starting from the original who dataset: who %&gt;% gather(code, value, new_sp_m014:newrel_f65, na.rm = TRUE) %&gt;% mutate(code = stringr::str_replace(code, &quot;newrel&quot;, &quot;new_rel&quot;)) %&gt;% separate(code, c(&quot;new&quot;, &quot;var&quot;, &quot;sexage&quot;)) %&gt;% select(-new, -iso2, -iso3) %&gt;% separate(sexage, c(&quot;sex&quot;, &quot;age&quot;), sep = 1) %&gt;% group_by(country, year, sex) %&gt;% summarize(total_case = sum(value)) %&gt;% unite(country_sex, country, sex, remove = FALSE) %&gt;% filter(year &gt;= 1995) %&gt;% ggplot() + geom_line(mapping = aes(x = year, y = total_case, color = sex, group = country_sex)) The reason we need to include unite(country_sex, country, sex, remove = FALSE) is that we need to separate the lines not just by country, but by country and gender combinations. This is the most informative plot we can get based on the instruction given. With over 200 countries, coloring the lines by countries will be very confusing, also facetting by countries will create 200 little plots. 12.7 Non-tidy data No exercises. "],
["relational-data.html", "13 Relational data 13.1 Introduction 13.2 nycflights13 13.3 Keys 13.4 Mutating joins 13.5 Filtering joins 13.6 Join problems 13.7 Set operations", " 13 Relational data 13.1 Introduction No exercises. 13.2 nycflights13 13.2.1 Exercises library(tidyverse) library(nycflights13) 1 - Imagine you wanted to draw (approximately) the route each plane flies from its origin to its destination. What variables would you need? What tables would you need to combine? Here I printed out the complete list of variable names in airports, planes, and flights. colnames(airports) ## [1] &quot;faa&quot; &quot;name&quot; &quot;lat&quot; &quot;lon&quot; &quot;alt&quot; &quot;tz&quot; &quot;dst&quot; &quot;tzone&quot; colnames(planes) ## [1] &quot;tailnum&quot; &quot;year&quot; &quot;type&quot; &quot;manufacturer&quot; ## [5] &quot;model&quot; &quot;engines&quot; &quot;seats&quot; &quot;speed&quot; ## [9] &quot;engine&quot; colnames(flights) ## [1] &quot;year&quot; &quot;month&quot; &quot;day&quot; ## [4] &quot;dep_time&quot; &quot;sched_dep_time&quot; &quot;dep_delay&quot; ## [7] &quot;arr_time&quot; &quot;sched_arr_time&quot; &quot;arr_delay&quot; ## [10] &quot;carrier&quot; &quot;flight&quot; &quot;tailnum&quot; ## [13] &quot;origin&quot; &quot;dest&quot; &quot;air_time&quot; ## [16] &quot;distance&quot; &quot;hour&quot; &quot;minute&quot; ## [19] &quot;time_hour&quot; &quot;dep_time_mins&quot; &quot;sched_dep_time_mins&quot; ## [22] &quot;arr_time_mins&quot; &quot;flight_time&quot; &quot;pre_dep_delay&quot; The main two tables we need to combine are airports and flights. We need to match bth origin and dest in flights with faa in airports. If we want additional information about each plane, then we will need to match tailnum in planes with tailnum in flights as well. 2 - I forgot to draw the relationship between weather and airports. What is the relationship and how should it appear in the diagram? Referring to the variable names of the two tables: colnames(weather) ## [1] &quot;origin&quot; &quot;year&quot; &quot;month&quot; &quot;day&quot; &quot;hour&quot; ## [6] &quot;temp&quot; &quot;dewp&quot; &quot;humid&quot; &quot;wind_dir&quot; &quot;wind_speed&quot; ## [11] &quot;wind_gust&quot; &quot;precip&quot; &quot;pressure&quot; &quot;visib&quot; &quot;time_hour&quot; colnames(airports) ## [1] &quot;faa&quot; &quot;name&quot; &quot;lat&quot; &quot;lon&quot; &quot;alt&quot; &quot;tz&quot; &quot;dst&quot; &quot;tzone&quot; The two tables can be matched via the variable origin in weather and faa in airports. 3 - weather only contains information for the origin (NYC) airports. If it contained weather records for all airports in the USA, what additional relation would it define with flights? It would allow us to match the weather at the destinations as well. 4 - We know that some days of the year are special, and fewer people than usual fly on them. How might you represent that data as a data frame? What would be the primary keys of that table? How would it connect to the existing tables? We can create a new table special containing the pertaining information of the special dates. To match special with the exisiting tables, the keys would be year, month, and day. 13.3 Keys 13.3.1 Exercises 1 - Add a surrogate key to flights. flights %&gt;% mutate(index = row_number()) %&gt;% select(index, everything()) ## # A tibble: 109,416 x 25 ## index year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 1 2013 1 1 542 540 2.00 923 ## 2 2 2013 1 1 544 545 - 1.00 1004 ## 3 3 2013 1 1 557 600 - 3.00 838 ## 4 4 2013 1 1 558 600 - 2.00 849 ## 5 5 2013 1 1 558 600 - 2.00 853 ## 6 6 2013 1 1 558 600 - 2.00 924 ## 7 7 2013 1 1 559 559 0 702 ## 8 8 2013 1 1 606 610 - 4.00 837 ## 9 9 2013 1 1 611 600 11.0 945 ## 10 10 2013 1 1 613 610 3.00 925 ## # ... with 109,406 more rows, and 17 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, dep_time_mins &lt;dbl&gt;, ## # sched_dep_time_mins &lt;dbl&gt;, arr_time_mins &lt;dbl&gt;, flight_time &lt;dbl&gt;, ## # pre_dep_delay &lt;dbl&gt; 2 - Identify the keys in the following datasets The primary keys for Lahman::Batting are playerID, yearID, stint, teamID, and lgID. Lahman::Batting %&gt;% group_by(playerID, yearID, stint, teamID, lgID) %&gt;% mutate(n = n()) %&gt;% filter(n &gt; 1) %&gt;% nrow() ## [1] 0 The primary keys for babynames::babynames are year, sex, and name. babynames::babynames %&gt;% group_by(year, sex, name) %&gt;% mutate(n = n()) %&gt;% filter(n &gt; 1) %&gt;% nrow() ## [1] 0 The primary keys for nasaweather::atoms are lat, long, year, and month nasaweather::atmos %&gt;% group_by(lat, long, year, month) %&gt;% mutate(n = n()) %&gt;% filter(n &gt; 1) %&gt;% nrow() ## [1] 0 The primary key for fueleconomy::vehicles is simply id. fueleconomy::vehicles %&gt;% group_by(id) %&gt;% mutate(n = n()) %&gt;% filter(n &gt; 1) %&gt;% nrow() ## [1] 0 It’s a bit tricky for ggplot2::diamdons. My intuition is that each diamond is unique, so it would be most appropriate to add a surrogate key. 3 - Draw a diagram illustrating the connections between the Batting, Master, and Salaries tables in the Lahman package. Draw another diagram that shows the relationship between Master, Managers, AwardsManagers. How would you characterise the relationship between the Batting, Pitching, and Fielding tables? The variables names are printed below: colnames(Lahman::Batting) ## [1] &quot;playerID&quot; &quot;yearID&quot; &quot;stint&quot; &quot;teamID&quot; &quot;lgID&quot; &quot;G&quot; ## [7] &quot;AB&quot; &quot;R&quot; &quot;H&quot; &quot;X2B&quot; &quot;X3B&quot; &quot;HR&quot; ## [13] &quot;RBI&quot; &quot;SB&quot; &quot;CS&quot; &quot;BB&quot; &quot;SO&quot; &quot;IBB&quot; ## [19] &quot;HBP&quot; &quot;SH&quot; &quot;SF&quot; &quot;GIDP&quot; colnames(Lahman::Master) ## [1] &quot;playerID&quot; &quot;birthYear&quot; &quot;birthMonth&quot; &quot;birthDay&quot; ## [5] &quot;birthCountry&quot; &quot;birthState&quot; &quot;birthCity&quot; &quot;deathYear&quot; ## [9] &quot;deathMonth&quot; &quot;deathDay&quot; &quot;deathCountry&quot; &quot;deathState&quot; ## [13] &quot;deathCity&quot; &quot;nameFirst&quot; &quot;nameLast&quot; &quot;nameGiven&quot; ## [17] &quot;weight&quot; &quot;height&quot; &quot;bats&quot; &quot;throws&quot; ## [21] &quot;debut&quot; &quot;finalGame&quot; &quot;retroID&quot; &quot;bbrefID&quot; ## [25] &quot;deathDate&quot; &quot;birthDate&quot; colnames(Lahman::Salaries) ## [1] &quot;yearID&quot; &quot;teamID&quot; &quot;lgID&quot; &quot;playerID&quot; &quot;salary&quot; colnames(Lahman::Managers) ## [1] &quot;playerID&quot; &quot;yearID&quot; &quot;teamID&quot; &quot;lgID&quot; &quot;inseason&quot; &quot;G&quot; ## [7] &quot;W&quot; &quot;L&quot; &quot;rank&quot; &quot;plyrMgr&quot; colnames(Lahman::AwardsManagers) ## [1] &quot;playerID&quot; &quot;awardID&quot; &quot;yearID&quot; &quot;lgID&quot; &quot;tie&quot; &quot;notes&quot; Batting contains batting statistics for players. The primary keys are playerID, yearID, stint, teamID, and lgID. The players’ biographical information are stored in Master and can be matched with playerID. The salary information for each player in each year can be matched with playerID, yearID, teamID, and lgID. Batting and Managers can be matched with playerID, yearID, teamID, and lgID. Mangers and AwardManagers are matched with playerID, yearID, teamID, and lgID. Batting, Pitching, and Fielding can be matched with playerID, yearID, stint, teamID, and lgID. 13.4 Mutating joins 13.4.1 Exercises 1 - Compute the average delay by destination, then join on the airports data frame so you can show the spatial distribution of delays. Here’s an easy way to draw a map of the United States: airports %&gt;% semi_join(flights, c(&quot;faa&quot; = &quot;dest&quot;)) %&gt;% ggplot(aes(lon, lat)) + borders(&quot;state&quot;) + geom_point() + coord_quickmap() Calculate the average arrival delay at each destination airport. Then join with airports to get the log and lat data. (Note: some dest can’t find a match in faa in airports) flights %&gt;% group_by(dest) %&gt;% summarize(avg_arr_delay = mean(arr_delay, na.rm = TRUE)) %&gt;% left_join(airports, by = c(&#39;dest&#39; = &#39;faa&#39;)) %&gt;% ggplot(aes(x = lon, y = lat, size = avg_arr_delay, color = avg_arr_delay)) + borders(&#39;state&#39;) + geom_point() + coord_quickmap() ## Warning: Removed 4 rows containing missing values (geom_point). 2 - Add the location of the origin and destination (i.e. the lat and lon) to flights. To better distingush the added location information between origin and destination, we can define suffix to the names of the variables joined to the exisiting table. To illustrate: flights %&gt;% left_join(airports, by = c(&#39;dest&#39; = &#39;faa&#39;)) %&gt;% left_join(airports, by = c(&#39;origin&#39; = &#39;faa&#39;), suffix = c(&#39;.dest&#39;, &#39;.origin&#39;)) %&gt;% select(dest, origin, contains(&#39;lat&#39;), contains(&#39;lon&#39;)) ## # A tibble: 109,416 x 6 ## dest origin lat.dest lat.origin lon.dest lon.origin ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 MIA JFK 25.8 40.6 - 80.3 -73.8 ## 2 BQN JFK NA 40.6 NA -73.8 ## 3 MCO JFK 28.4 40.6 - 81.3 -73.8 ## 4 PBI JFK 26.7 40.6 - 80.1 -73.8 ## 5 TPA JFK 28.0 40.6 - 82.5 -73.8 ## 6 LAX JFK 33.9 40.6 -118 -73.8 ## 7 BOS JFK 42.4 40.6 - 71.0 -73.8 ## 8 ATL JFK 33.6 40.6 - 84.4 -73.8 ## 9 SFO JFK 37.6 40.6 -122 -73.8 ## 10 RSW JFK 26.5 40.6 - 81.8 -73.8 ## # ... with 109,406 more rows 3 - Is there a relationship between the age of a plane and its delays? We need information from flights and planes. We first calculate the average departure delay and arrival delay for each tailnum, then join with planes through the variable tailnum to get the age information. flights %&gt;% group_by(tailnum) %&gt;% summarise(avg_dep_delay = mean(dep_delay, na.rm = TRUE), avg_arr_delay = mean(arr_delay, na.rm = TRUE)) %&gt;% gather(key = &#39;mode&#39;, value = &#39;delay&#39;, 2:3) %&gt;% left_join(planes, by = &#39;tailnum&#39;) %&gt;% ggplot(mapping = aes(x = year, y = delay)) + geom_point() + geom_smooth(se = FALSE) + facet_grid(.~mode) ## `geom_smooth()` using method = &#39;gam&#39; ## Warning: Removed 1194 rows containing non-finite values (stat_smooth). ## Warning: Removed 1194 rows containing missing values (geom_point). Apparently it is hard to say there is some kind of relationship between delays and year of a plane. 4 - What weather conditions make it more likely to see a delay? Since weather only contains origin airports, we will look at departure delay. flights %&gt;% left_join(weather, by = c(&#39;year&#39;,&#39;month&#39;,&#39;day&#39;,&#39;hour&#39;,&#39;origin&#39;)) %&gt;% gather(key = &#39;condition&#39;, value = &#39;value&#39;, temp:visib) %&gt;% filter(!is.na(dep_delay)) %&gt;% ggplot(mapping = aes(x = value, y = dep_delay)) + geom_point() + facet_wrap(~condition, ncol = 3, scale = &#39;free_x&#39;) ## Warning: Removed 14599 rows containing missing values (geom_point). Can you tell which conditions are correlated with departure delay? Just looking at the individual bivariate relationship between departure delay and each weather condition, there does not seem to be any strong correlation. 5 - What happened on June 13 2013? Display the spatial pattern of delays, and then use Google to cross-reference with the weather. flights %&gt;% filter(year == 2013, month == 6, day == 13) %&gt;% group_by(dest) %&gt;% summarize(avg_arr_delay = mean(arr_delay, na.rm = TRUE)) %&gt;% left_join(airports, by = c(&#39;dest&#39; = &#39;faa&#39;)) %&gt;% ggplot(aes(x = lon, y = lat, size = avg_arr_delay, color = avg_arr_delay)) + borders(&#39;state&#39;) + geom_point(alpha = .5) + scale_color_continuous(low = &#39;yellow&#39;, high = &#39;red&#39;) + coord_quickmap() ## Warning: Removed 4 rows containing missing values (geom_point). 13.5 Filtering joins 13.5.1 Exercises 1 - What does it mean for a flight to have a missing tailnum? What do the tail numbers that don’t have a matching record in planes have in common? (Hint: one variable explains ~90% of the problems.) Flights have a missing tailnum are those that were cancellled, or without missing dep_time, etc. flights %&gt;% filter(is.na(tailnum)) ## # A tibble: 0 x 24 ## # ... with 24 variables: year &lt;int&gt;, month &lt;int&gt;, day &lt;int&gt;, ## # dep_time &lt;int&gt;, sched_dep_time &lt;int&gt;, dep_delay &lt;dbl&gt;, arr_time &lt;int&gt;, ## # sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, ## # tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, ## # distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, ## # dep_time_mins &lt;dbl&gt;, sched_dep_time_mins &lt;dbl&gt;, arr_time_mins &lt;dbl&gt;, ## # flight_time &lt;dbl&gt;, pre_dep_delay &lt;dbl&gt; For those tailnum that don’t have a matching record in plane, it seems most of them come from the same two carriers. flights %&gt;% anti_join(planes, by = &#39;tailnum&#39;) %&gt;% group_by(carrier) %&gt;% summarize(n = n()) %&gt;% arrange(desc(n)) ## # A tibble: 5 x 2 ## carrier n ## &lt;chr&gt; &lt;int&gt; ## 1 AA 8176 ## 2 MQ 6782 ## 3 B6 569 ## 4 UA 307 ## 5 DL 1 2 - Filter flights to only show flights with planes that have flown at least 100 flights. Create a new table that contains planes that have flown over 100 times, then just semi_join(). flights_100 &lt;- flights %&gt;% filter(!is.na(dep_delay)) %&gt;% group_by(tailnum) %&gt;% summarize(n = n()) %&gt;% filter(n &gt; 100) flights %&gt;% semi_join(flights_100, by = &#39;tailnum&#39;) ## # A tibble: 71,102 x 24 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 544 545 -1.00 1004 ## 2 2013 1 1 557 600 -3.00 838 ## 3 2013 1 1 558 600 -2.00 849 ## 4 2013 1 1 558 600 -2.00 853 ## 5 2013 1 1 559 559 0 702 ## 6 2013 1 1 613 610 3.00 925 ## 7 2013 1 1 615 615 0 1039 ## 8 2013 1 1 639 640 -1.00 739 ## 9 2013 1 1 645 647 -2.00 815 ## 10 2013 1 1 651 655 -4.00 936 ## # ... with 71,092 more rows, and 17 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, dep_time_mins &lt;dbl&gt;, ## # sched_dep_time_mins &lt;dbl&gt;, arr_time_mins &lt;dbl&gt;, flight_time &lt;dbl&gt;, ## # pre_dep_delay &lt;dbl&gt; 3 - Combine fueleconomy::vehicles and fueleconomy::common to find only the records for the most common models. fueleconomy::vehicles %&gt;% semi_join(fueleconomy::common, by = c(&#39;make&#39;, &#39;model&#39;)) ## # A tibble: 14,531 x 12 ## id make model year class trans drive cyl displ fuel hwy cty ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 1833 Acura Inte~ 1986 Subc~ Auto~ Fron~ 4 1.60 Regu~ 28 22 ## 2 1834 Acura Inte~ 1986 Subc~ Manu~ Fron~ 4 1.60 Regu~ 28 23 ## 3 3037 Acura Inte~ 1987 Subc~ Auto~ Fron~ 4 1.60 Regu~ 28 22 ## 4 3038 Acura Inte~ 1987 Subc~ Manu~ Fron~ 4 1.60 Regu~ 28 23 ## 5 4183 Acura Inte~ 1988 Subc~ Auto~ Fron~ 4 1.60 Regu~ 27 22 ## 6 4184 Acura Inte~ 1988 Subc~ Manu~ Fron~ 4 1.60 Regu~ 28 23 ## 7 5303 Acura Inte~ 1989 Subc~ Auto~ Fron~ 4 1.60 Regu~ 27 22 ## 8 5304 Acura Inte~ 1989 Subc~ Manu~ Fron~ 4 1.60 Regu~ 28 23 ## 9 6442 Acura Inte~ 1990 Subc~ Auto~ Fron~ 4 1.80 Regu~ 24 20 ## 10 6443 Acura Inte~ 1990 Subc~ Manu~ Fron~ 4 1.80 Regu~ 26 21 ## # ... with 14,521 more rows 4 - Find the 48 hours (over the course of the whole year) that have the worst delays. Cross-reference it with the weather data. Can you see any patterns? Though not technically the same, we’ll calculate the average delay for each day and attempt to identifty the 2-day windows that have the worst delays. We’ll also calculate the average weather coditions. flights_2day &lt;- flights %&gt;% group_by(year, month, day) %&gt;% summarize(avg_dep_delay = mean(dep_delay, na.rm = TRUE), avg_arr_delay = mean(arr_delay, na.rm = TRUE)) %&gt;% unite(date, year, month, day, sep = &#39;-&#39;) %&gt;% mutate(date = parse_date(date, &quot;%Y-%m-%d&quot;)) %&gt;% gather(key = &#39;mode&#39;, value = &#39;delay&#39;, 2:3) %&gt;% mutate(mode = factor(mode, labels = c(&#39;Average arrival delay&#39;, &#39;Average departure delay&#39;))) weather_2day &lt;- weather %&gt;% group_by(year, month, day) %&gt;% summarize(avg_wind_speed = mean(wind_speed, na.rm = TRUE), avg_wind_gust = mean(wind_gust, na.rm = TRUE), avg_precip = mean(precip, na.rm = TRUE), avg_visib = mean(visib, na.rm = TRUE)) %&gt;% unite(date, year, month, day, sep = &#39;-&#39;) %&gt;% mutate(date = parse_date(date, &quot;%Y-%m-%d&quot;)) flights_2day %&gt;% ggplot() + geom_point(mapping = aes(x = date, y = delay, color = mode)) + geom_line(mapping = aes(x = date, y = delay, color = mode)) + geom_line(data = weather_2day, mapping = aes(x = date, y = (avg_visib-10)*5, color = &#39;Average visibility&#39;)) + scale_y_continuous(sec.axis = sec_axis(~./5 + 10, name = &quot;Average visibility (km)&quot;)) + facet_wrap(~mode, ncol = 1) + labs(x = &quot;Date&quot;, y = &quot;Average delay (minutes)&quot;, color = &#39;Legend&#39;, title = &quot;Average delay and average visibility&quot;) We have only plotted average delays with average visability. There seems to be (maybe only due to confirmation bias?) that high delays are related to low visibility. We can do similar plots for average delays with other weather conditions, but we will stop here. 5 - What does anti_join(flights, airports, by = c(&quot;dest&quot; = &quot;faa&quot;)) tell you? What does anti_join(airports, flights, by = c(&quot;faa&quot; = &quot;dest&quot;)) tell you? anti_join(flights, airports, by = c(&quot;dest&quot; = &quot;faa&quot;)) shows flight whose destinations are not included in the airports database. anti_join(airports, flights, by = c(&quot;faa&quot; = &quot;dest&quot;)) shows airport names and locations that flights from flights are not flying to. 6 - You might expect that there’s an implicit relationship between plane and airline, because each plane is flown by a single airline. Confirm or reject this hypothesis using the tools you’ve learned above. Applying a few functions with flights data: flights %&gt;% select(carrier, tailnum) %&gt;% group_by(tailnum) %&gt;% summarize(n = length(unique(carrier))) %&gt;% filter(n &gt; 1) ## # A tibble: 0 x 2 ## # ... with 2 variables: tailnum &lt;chr&gt;, n &lt;int&gt; There were planes that were flown by over 1 carrier. 13.6 Join problems No exercises. 13.7 Set operations No exercises. "],
["strings.html", "14 Strings 14.1 Introduction 14.2 String basics 14.3 Tools 14.4 Other types of pattern 14.5 Other uses of regular expressions 14.6 stringi", " 14 Strings 14.1 Introduction No exercises 14.2 String basics 14.2.1 Exercises library(tidyverse) library(stringr) 1 - In code that doesn’t use stringr, you’ll often see paste() and paste0(). What’s the difference between the two functions? What stringr function are they equivalent to? How do the functions differ in their handling of NA? paste0() is equivalent to paste(..., sep = &quot;&quot;). Both functions are equivalent to stringr function str_c(). In paste() andpaste0, NA are automaically converted to strings “NA”. in str_c(), NA remains NA. paste(&#39;a&#39;, &#39;b&#39;, NA, &#39;c&#39;) ## [1] &quot;a b NA c&quot; paste0(&#39;a&#39;, &#39;b&#39;, NA, &#39;c&#39;) ## [1] &quot;abNAc&quot; str_c(&#39;a&#39;, &#39;b&#39;, NA, &#39;c&#39;) ## [1] NA str_c(str_replace_na(c(&#39;a&#39;, &#39;b&#39;, NA, &#39;c&#39;)), collapse = &#39;&#39;) ## [1] &quot;abNAc&quot; 2 - In your own words, describe the difference between the sep and collapse arguments to str_c(). One uses sep if combining different strings: str_c(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, sep = &#39; &#39;) ## [1] &quot;a b c&quot; If the lengths of the input strings are greater than 1, the operation is done element wise: str_c(1:5, letters[1:5], LETTERS[1:5], sep = &#39; &#39;) ## [1] &quot;1 a A&quot; &quot;2 b B&quot; &quot;3 c C&quot; &quot;4 d D&quot; &quot;5 e E&quot; On the other hand, one uses collapse when combining the individual strings in a vector into a single string: str_c(c(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;), collapse = &#39;/&#39;) ## [1] &quot;a/b/c&quot; If sep and collapse are used together: str_c(1:5, letters[1:5], LETTERS[1:5], sep = &#39; &#39;, collapse = &#39;/&#39;) ## [1] &quot;1 a A/2 b B/3 c C/4 d D/5 e E&quot; 3 - Use str_length() and str_sub() to extract the middle character from a string. What will you do if the string has an even number of characters? If the string has an even number of characeters, let’s assume we want to return both characters in the middle position. We can write a simple function to do this job: middle_character &lt;- function(s){ s_length &lt;- str_length(s) if (s_length %% 2 == 1) { return(str_sub(s, start = ceiling(s_length /2), end = ceiling(s_length / 2))) } else{ return(str_sub(s, start = s_length /2, end = s_length / 2 + 1)) } } A string with odd number of characeters: middle_character(&#39;level&#39;) ## [1] &quot;v&quot; A string with even number of characeters: middle_character(&#39;middle&#39;) ## [1] &quot;dd&quot; 4 - What does str_wrap() do? When might you want to use it? In my own words, str_wrap() returns a long string of text into a “paragraph” format. At certain length, the function adds \\n to insert a new line. Indent and exdent character width can also be specified. For instance: long_text &lt;- &quot;This is the website for R for Data Science. This book will teach you how to do data science with R: You&#39;ll learn how to get your data into R, get it into the most useful structure, transform it, visualise it and model it. In this book, you will find a practicum of skills for data science. Just as a chemist learns how to clean test tubes and stock a lab, you&#39;ll learn how to clean data and draw plots-and many other things besides. These are the skills that allow data science to happen, and here you will find the best practices for doing each of these things with R. You&#39;ll learn how to use the grammar of graphics, literate programming, and reproducible research to save time. You&#39;ll also learn how to manage cognitive resources to facilitate discoveries when wrangling, visualising, and exploring data&quot; long_text_formatted &lt;- str_wrap(long_text, width = 60, indent = 3) long_text_formatted ## [1] &quot; This is the website for R for Data Science. This book will\\nteach you how to do data science with R: You&#39;ll learn how to\\nget your data into R, get it into the most useful structure,\\ntransform it, visualise it and model it. In this book, you\\nwill find a practicum of skills for data science. Just as\\na chemist learns how to clean test tubes and stock a lab,\\nyou&#39;ll learn how to clean data and draw plots-and many\\nother things besides. These are the skills that allow data\\nscience to happen, and here you will find the best practices\\nfor doing each of these things with R. You&#39;ll learn how\\nto use the grammar of graphics, literate programming, and\\nreproducible research to save time. You&#39;ll also learn how\\nto manage cognitive resources to facilitate discoveries when\\nwrangling, visualising, and exploring data&quot; Now we can use writeLines() to properly display the text: writeLines(long_text_formatted) ## This is the website for R for Data Science. This book will ## teach you how to do data science with R: You&#39;ll learn how to ## get your data into R, get it into the most useful structure, ## transform it, visualise it and model it. In this book, you ## will find a practicum of skills for data science. Just as ## a chemist learns how to clean test tubes and stock a lab, ## you&#39;ll learn how to clean data and draw plots-and many ## other things besides. These are the skills that allow data ## science to happen, and here you will find the best practices ## for doing each of these things with R. You&#39;ll learn how ## to use the grammar of graphics, literate programming, and ## reproducible research to save time. You&#39;ll also learn how ## to manage cognitive resources to facilitate discoveries when ## wrangling, visualising, and exploring data 5 - What does str_trim() do? What’s the opposite of str_trim()? str_trim() trims whitesapce from start and end of string. str_trim(&#39; white space &#39;) ## [1] &quot;white space&quot; The opposite if str_pad() adds whitespace, or other characeters, at the start and end of string. str_pad(&#39;interesting&#39;, width = 20, side = &#39;both&#39;, pad = &#39;_&#39;) ## [1] &quot;____interesting_____&quot; 6 - Write a function that turns (e.g.) a vector c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) into the string a, b, and c. Think carefully about what it should do if given a vector of length 0, 1, or 2. Let’s call the function custom_c: custom_c &lt;- function(s){ if (length(s) == 0){ return(NULL) } else if (length(s) == 1){ return(s) } else if (length(s) == 2){ return(str_c(s, collapse = &#39; and &#39;)) } else{ first_half &lt;- str_c(s[1:length(s) - 1], collapse = &#39;, &#39;) return(str_c(first_half, s[length(s)], sep = &#39;, and &#39;)) } } Testing: print(custom_c(c())) ## NULL print(custom_c(c(&#39;a&#39;))) ## [1] &quot;a&quot; print(custom_c(c(&#39;a&#39;,&#39;b&#39;))) ## [1] &quot;a and b&quot; print(custom_c(c(&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;,&#39;e&#39;))) ## [1] &quot;a, b, c, d, and e&quot; 14.2.2 Matching patterns with regular expressions 14.2.2.1 Basic matches 1. Explain why each of these strings don’t match a \\: &quot;\\&quot;, &quot;\\\\&quot;, &quot;\\\\\\&quot;. In &quot;\\&quot;, the single backlash “escapes” the special behavior of the close &quot;, and it’s waiting for the real second &quot; to close the string. We can use writeLines() to demonstrate: ## &gt; writeLines(&quot;\\&quot;) ## + The + is there waiting for more inputs. In &quot;\\\\&quot;, the first backlash “escapes” the second backlash, so the second backlash does not “escape” the &quot;. However, recall that we use strings to express regular expressions: writeLines(&quot;\\\\&quot;) ## \\ When evaluated, there is only one backlash, which is a special, escape character. Not the literal backlash. In &quot;\\\\\\&quot;, the third backlash “escapes” the &quot;, which makes the input incomplete: ## &gt; writeLines(&quot;\\\\\\&quot;) ## + In &quot;\\\\\\\\&quot;, when evaluated: writeLines(&quot;\\\\\\\\&quot;) ## \\\\ It returns two backlashes. The first escapes the second, so the regular expression is now going to match the single backlash in the string sequence. 2. How would you match the sequence &quot;'\\? str_view(&quot;\\&quot;&#39;\\\\&quot;, &quot;\\&quot;\\&#39;\\\\\\\\&quot;) 3. What patterns will the regular expression \\..\\..\\.. match? How would you represent it as a string? By now we should know that backlash itself is a special character and needs to be escaped in a string. To express the regular expression in a string, it should be \\\\..\\\\..\\\\... What it does is it matches a dot, then any character, a dot, then any character, a dot, then finally any character. str_view(c(&quot;.c.o.m&quot;, &quot;com&quot;, &quot;.o.m.e.l&quot;), &quot;\\\\..\\\\..\\\\..&quot;) 14.2.2.2 Anchors 1. How would you match the literal string &quot;$^$&quot;? str_view(&quot;$^$&quot;, &quot;\\\\$\\\\^\\\\$&quot;) 2. Given the corpus of common words in stringr::words, create regular expressions that find all words that: Start with “y”. str_view(stringr::words, &quot;^y.*&quot;, match = TRUE) To break down the regular expression &quot;^y.*&quot;, ^y specifies that I want to look for a word that starts with a y, followed by any character .. * matches 0 or more .. The whole expression will match a string starting with a letter, followed by 0 or more other characters. End with “x”. str_view(stringr::words, &quot;.*x$&quot;, match = TRUE) Again, .* specifies that it can start with any number of any characters, but x$ states that it has to end with x. Are exactly three letters long. (Don’t cheat by using str_length()!) str_view(stringr::words, &quot;^...$&quot;, match = TRUE) Have seven letters or more. str_view(stringr::words, &quot;^.{7,}&quot;, match = TRUE) 14.2.2.3 Character classes and alternatives 1. Create regular expressions to find all words that: Start with a vowel. str_view(stringr::words, &quot;^[aeiou].*&quot;, match = TRUE) That only contain consonants. (Hint: thinking about matching “not”-vowels.) str_view(stringr::words, &quot;^[^aeiou].*&quot;, match = TRUE) End with ed, but not with eed. str_view(stringr::words, &quot;.*([^e]ed)$&quot;, match = TRUE) End with ing or ise. str_view(stringr::words, &quot;.*(ing|ise)$&quot;, match = TRUE) 2. Empirically verify the rule “i before e except after c”. 3. Is “q” always followed by a “u”? str_view(stringr::words, &quot;(qu)&quot;, match = TRUE) At least it seemes like it for the 980 words included in stringr::words. 4. Write a regular expression that matches a word if it’s probably written in British English, not American English. British:analyse. American:analyze. str_view(c(&quot;analyse&quot;, &quot;analyze&quot;), &quot;.*(yse)$&quot;) 5. Create a regular expression that will match telephone numbers as commonly written in your country. Numbers in Hong Kong, SAR: str_view(c(&quot;38888888&quot;, &quot;3888-8888&quot;, &quot;3888 8888&quot;), &quot;^\\\\d{4,4}\\\\s?-?\\\\d{4,4}$&quot;, match = TRUE) 14.2.2.4 Repetition 1. Describe the equivalents of ?, +, \\* in {m,n} form. ? - {0,1} + - {1,} * - {0,} 2. Describe in words what these regular expressions match: (read carefully to see if I’m using a regular expression or a string that defines a regular expression.) ^.*$ Matches a string of any length that starts with, ends with, and contains any characters, except a new line. str_view(c(&#39;interesting&#39;, &#39;what is this&#39;, &#39;a new line \\n second line&#39;), &quot;^.*$&quot;) &quot;\\\\{.+\\\\}&quot; Matches a string with at least one character, enclosed by {}. str_view(c(&quot;{ok}&quot;, &quot;(ok)&quot;), &quot;\\\\{.+\\\\}&quot;) \\d{4}-\\d{2}-\\d{2} Matches a string of digits in this exact format: XXXX-XX-XX. str_view(c(&quot;1234-56-78&quot;, &quot;1234-56-789&quot;), &quot;\\\\d{4}-\\\\d{2}-\\\\d{2}&quot;) &quot;\\\\\\\\{4}&quot; Matches exactly 4 \\ str_view(c(&quot;\\\\\\\\\\\\\\\\&quot;, &quot;\\\\\\\\\\\\&quot;), &quot;\\\\\\\\{4}&quot;) 3. Create regular expressions to find all words that: Start with three consonants. ^[^aeiou]{3} Have three or more vowels in a row. [aeiou]{3,} Have two or more vowel-consonant pairs in a row. ([aeiou][^aeiou]){2,} str_view(c(&#39;ap&#39;, &#39;apap&#39;, &#39;apapap&#39;), &quot;([aeiou][^aeiou]){2,}&quot;) 14.2.2.5 Grouping and backreferences 1. Describe, in words, what these expressions will match: (.)\\1\\1 looks for two repeating characters: str_view(c(&quot;a&quot;,&quot;aa&quot;,&quot;aaa&quot;), &quot;(.)\\\\1&quot;) (.)(.)\\\\2\\\\1 matches strings in this pattern: xyyx str_view(c(&quot;awwa&quot;, &quot;byb&quot;), &quot;(.)(.)\\\\2\\\\1&quot;) (..)\\1 matches strings in this pattern: xyxy str_view(&quot;coco&quot;, &quot;(..)\\\\1&quot;) &quot;(.).\\\\1.\\\\1&quot; matches strings in this pattern: x.x.x str_view(c(&quot;a.a.a&quot;, &quot;com.com.com&quot;), &quot;(.).\\\\1.\\\\1&quot;) &quot;(.)(.)(.).*\\\\3\\\\2\\\\1&quot; matches strings that start with the pattern xyz, end with zyx, and any number of characters in between. str_view(c(&quot;abccba&quot;, &quot;abclevelcba&quot;), &quot;(.)(.)(.).*\\\\3\\\\2\\\\1&quot;) 2. Construct regular expressions to match words that: Start and end with the same character. &quot;^(.).*\\\\1$&quot; str_view(c(&quot;level&quot;, &quot;apple&quot;), &quot;^(.).*\\\\1$&quot;) Contain a repeated pair of letters (e.g. “church” contains “ch” repeated twice.) &quot;^(..).*\\\\1$&quot; str_view(c(&quot;level&quot;, &quot;church&quot;), &quot;^(..).*\\\\1$&quot;) Contain one letter repeated in at least three places (e.g. “eleven” contains three “e”s.) &quot;.*(.).*\\\\1.*\\\\1&quot; str_view(c(&quot;eleven&quot;, &quot;level&quot;, &quot;papaya&quot;), &quot;.*(.).*\\\\1.*\\\\1.*&quot;) 14.3 Tools 14.3.1 Detect matches No exercises 14.3.2 Exercises 1. For each of the following challenges, try solving it by using both a single regular expression, and a combination of multiple str_detect() calls. Find all words that start or end with x. start_x &lt;- str_detect(stringr::words, &quot;^x&quot;) end_x &lt;- str_detect(stringr::words, &quot;x$&quot;) stringr::words[start_x | end_x] ## [1] &quot;box&quot; &quot;sex&quot; &quot;six&quot; &quot;tax&quot; Find all words that start with a vowel and end with a consonant. start_vowel &lt;- str_detect(stringr::words, &quot;^[aeiou]&quot;) end_consonant &lt;- str_detect(stringr::words, &quot;[^aeiou]$&quot;) stringr::words[start_vowel &amp; end_consonant] ## [1] &quot;about&quot; &quot;accept&quot; &quot;account&quot; &quot;across&quot; &quot;act&quot; ## [6] &quot;actual&quot; &quot;add&quot; &quot;address&quot; &quot;admit&quot; &quot;affect&quot; ## [11] &quot;afford&quot; &quot;after&quot; &quot;afternoon&quot; &quot;again&quot; &quot;against&quot; ## [16] &quot;agent&quot; &quot;air&quot; &quot;all&quot; &quot;allow&quot; &quot;almost&quot; ## [21] &quot;along&quot; &quot;already&quot; &quot;alright&quot; &quot;although&quot; &quot;always&quot; ## [26] &quot;amount&quot; &quot;and&quot; &quot;another&quot; &quot;answer&quot; &quot;any&quot; ## [31] &quot;apart&quot; &quot;apparent&quot; &quot;appear&quot; &quot;apply&quot; &quot;appoint&quot; ## [36] &quot;approach&quot; &quot;arm&quot; &quot;around&quot; &quot;art&quot; &quot;as&quot; ## [41] &quot;ask&quot; &quot;at&quot; &quot;attend&quot; &quot;authority&quot; &quot;away&quot; ## [46] &quot;awful&quot; &quot;each&quot; &quot;early&quot; &quot;east&quot; &quot;easy&quot; ## [51] &quot;eat&quot; &quot;economy&quot; &quot;effect&quot; &quot;egg&quot; &quot;eight&quot; ## [56] &quot;either&quot; &quot;elect&quot; &quot;electric&quot; &quot;eleven&quot; &quot;employ&quot; ## [61] &quot;end&quot; &quot;english&quot; &quot;enjoy&quot; &quot;enough&quot; &quot;enter&quot; ## [66] &quot;environment&quot; &quot;equal&quot; &quot;especial&quot; &quot;even&quot; &quot;evening&quot; ## [71] &quot;ever&quot; &quot;every&quot; &quot;exact&quot; &quot;except&quot; &quot;exist&quot; ## [76] &quot;expect&quot; &quot;explain&quot; &quot;express&quot; &quot;identify&quot; &quot;if&quot; ## [81] &quot;important&quot; &quot;in&quot; &quot;indeed&quot; &quot;individual&quot; &quot;industry&quot; ## [86] &quot;inform&quot; &quot;instead&quot; &quot;interest&quot; &quot;invest&quot; &quot;it&quot; ## [91] &quot;item&quot; &quot;obvious&quot; &quot;occasion&quot; &quot;odd&quot; &quot;of&quot; ## [96] &quot;off&quot; &quot;offer&quot; &quot;often&quot; &quot;okay&quot; &quot;old&quot; ## [101] &quot;on&quot; &quot;only&quot; &quot;open&quot; &quot;opportunity&quot; &quot;or&quot; ## [106] &quot;order&quot; &quot;original&quot; &quot;other&quot; &quot;ought&quot; &quot;out&quot; ## [111] &quot;over&quot; &quot;own&quot; &quot;under&quot; &quot;understand&quot; &quot;union&quot; ## [116] &quot;unit&quot; &quot;university&quot; &quot;unless&quot; &quot;until&quot; &quot;up&quot; ## [121] &quot;upon&quot; &quot;usual&quot; Are there any words that contain at least one of each different vowel? contains_a &lt;- str_detect(stringr::words, &quot;a&quot;) contains_e &lt;- str_detect(stringr::words, &quot;e&quot;) contains_i &lt;- str_detect(stringr::words, &quot;i&quot;) contains_o &lt;- str_detect(stringr::words, &quot;o&quot;) contains_u &lt;- str_detect(stringr::words, &quot;u&quot;) stringr::words[contains_a &amp; contains_e &amp; contains_i &amp; contains_o &amp; contains_u] ## character(0) Not in stringr::words. 2. What word has the highest number of vowels? What word has the highest proportion of vowels? (Hint: what is the denominator?) word_tbl &lt;- tibble( words = stringr::words ) %&gt;% mutate(n_vowel = str_count(words, &quot;[aeiou]&quot;), n_consonant = str_count(words, &quot;[^aeiou]&quot;), n_chars = str_length(words), prop_vowel = n_vowel/n_chars, prop_consonant = n_consonant/n_chars) word_tbl ## # A tibble: 980 x 6 ## words n_vowel n_consonant n_chars prop_vowel prop_consonant ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 a 1 0 1 1.00 0 ## 2 able 2 2 4 0.500 0.500 ## 3 about 3 2 5 0.600 0.400 ## 4 absolute 4 4 8 0.500 0.500 ## 5 accept 2 4 6 0.333 0.667 ## 6 account 3 4 7 0.429 0.571 ## 7 achieve 4 3 7 0.571 0.429 ## 8 across 2 4 6 0.333 0.667 ## 9 act 1 2 3 0.333 0.667 ## 10 active 3 3 6 0.500 0.500 ## # ... with 970 more rows Highest number of vowels: word_tbl %&gt;% arrange(desc(n_vowel)) ## # A tibble: 980 x 6 ## words n_vowel n_consonant n_chars prop_vowel prop_consonant ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 appropriate 5 6 11 0.455 0.545 ## 2 associate 5 4 9 0.556 0.444 ## 3 available 5 4 9 0.556 0.444 ## 4 colleague 5 4 9 0.556 0.444 ## 5 encourage 5 4 9 0.556 0.444 ## 6 experience 5 5 10 0.500 0.500 ## 7 individual 5 5 10 0.500 0.500 ## 8 television 5 5 10 0.500 0.500 ## 9 absolute 4 4 8 0.500 0.500 ## 10 achieve 4 3 7 0.571 0.429 ## # ... with 970 more rows Highest proportion of vowels: word_tbl %&gt;% arrange(desc(prop_vowel)) ## # A tibble: 980 x 6 ## words n_vowel n_consonant n_chars prop_vowel prop_consonant ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 a 1 0 1 1.00 0 ## 2 area 3 1 4 0.750 0.250 ## 3 idea 3 1 4 0.750 0.250 ## 4 age 2 1 3 0.667 0.333 ## 5 ago 2 1 3 0.667 0.333 ## 6 air 2 1 3 0.667 0.333 ## 7 die 2 1 3 0.667 0.333 ## 8 due 2 1 3 0.667 0.333 ## 9 eat 2 1 3 0.667 0.333 ## 10 europe 4 2 6 0.667 0.333 ## # ... with 970 more rows 14.3.3 Extract matches 14.3.3.1 Exercises 1. In the previous example, you might have noticed that the regular expression matched “flickered”, which is not a colour. Modify the regex to fix the problem. In the original code, the regular expression is: colours &lt;- c(&quot;red&quot;, &quot;orange&quot;, &quot;yellow&quot;, &quot;green&quot;, &quot;blue&quot;, &quot;purple&quot;) colour_match &lt;- str_c(colours, collapse = &quot;|&quot;) colour_match ## [1] &quot;red|orange|yellow|green|blue|purple&quot; It matches all strings that have one of the colour words, even words like flickered. We can add \\b to include word boundary. The modified regular expression: colours &lt;- c(&quot;red&quot;, &quot;orange&quot;, &quot;yellow&quot;, &quot;green&quot;, &quot;blue&quot;, &quot;purple&quot;) colour_match &lt;- str_c(colours, collapse = &quot;|&quot;) colour_match &lt;- str_c(&quot;\\\\b(&quot;, colour_match, &quot;)\\\\b&quot;, sep =&#39;&#39;) colour_match ## [1] &quot;\\\\b(red|orange|yellow|green|blue|purple)\\\\b&quot; more &lt;- sentences[str_count(sentences, colour_match) &gt; 1] str_view_all(more, colour_match) 2. From the Harvard sentences data, extract: The first word from each sentence. str_extract(sentences, &quot;^[A-Za-z\\\\&#39;]+&quot;) %&gt;% head(10) ## [1] &quot;The&quot; &quot;Glue&quot; &quot;It&#39;s&quot; &quot;These&quot; &quot;Rice&quot; &quot;The&quot; &quot;The&quot; &quot;The&quot; ## [9] &quot;Four&quot; &quot;Large&quot; All words ending in ing. end_ing &lt;- str_subset(sentences, &quot;[A-Za-z]+ing\\\\b&quot;) str_extract(end_ing, &quot;[A-Za-z]+ing\\\\b&quot;) %&gt;% unlist() ## [1] &quot;spring&quot; &quot;evening&quot; &quot;morning&quot; &quot;winding&quot; &quot;living&quot; ## [6] &quot;king&quot; &quot;Adding&quot; &quot;making&quot; &quot;raging&quot; &quot;playing&quot; ## [11] &quot;sleeping&quot; &quot;ring&quot; &quot;glaring&quot; &quot;sinking&quot; &quot;dying&quot; ## [16] &quot;Bring&quot; &quot;lodging&quot; &quot;filing&quot; &quot;making&quot; &quot;morning&quot; ## [21] &quot;wearing&quot; &quot;Bring&quot; &quot;wading&quot; &quot;swing&quot; &quot;nothing&quot; ## [26] &quot;ring&quot; &quot;morning&quot; &quot;sing&quot; &quot;sleeping&quot; &quot;painting&quot; ## [31] &quot;king&quot; &quot;walking&quot; &quot;bring&quot; &quot;bring&quot; &quot;shipping&quot; ## [36] &quot;spring&quot; &quot;ring&quot; &quot;winding&quot; &quot;puzzling&quot; &quot;spring&quot; ## [41] &quot;landing&quot; &quot;thing&quot; &quot;waiting&quot; &quot;whistling&quot; &quot;nothing&quot; ## [46] &quot;timing&quot; &quot;thing&quot; &quot;spring&quot; &quot;changing&quot; &quot;drenching&quot; ## [51] &quot;moving&quot; &quot;working&quot; &quot;ring&quot; All plurals. This is a little tough, just thinking how to extract all the irregular plural nouns (e.g., men, teeth). To make things easier, I’m extract words that have at least 4 letters and end with a s. plurals &lt;- str_subset(sentences, &quot;[A-Za-z]{3,}s\\\\b&quot;) str_extract_all(plurals, &quot;[A-Za-z]{3,}s\\\\b&quot;) %&gt;% unlist() %&gt;% head(20) ## [1] &quot;planks&quot; &quot;days&quot; &quot;bowls&quot; &quot;lemons&quot; &quot;makes&quot; ## [6] &quot;hogs&quot; &quot;hours&quot; &quot;stockings&quot; &quot;helps&quot; &quot;pass&quot; ## [11] &quot;fires&quot; &quot;across&quot; &quot;bonds&quot; &quot;Press&quot; &quot;pants&quot; ## [16] &quot;useless&quot; &quot;kittens&quot; &quot;days&quot; &quot;Sickness&quot; &quot;grass&quot; Not so bad… but not so good either. Let’s stop here. 14.3.4 Grouped matches 14.3.4.1 Exercises 1. Find all words that come after a “number” like “one”, “two”, “three” etc. Pull out both the number and the word. number_word &lt;- &quot;\\\\b(one|two|three|four|five|six|seven|eight|nine|ten)\\\\b\\\\s([A-Za-z]+)&quot; sentences[str_detect(sentences, number_word)] %&gt;% str_match(number_word) ## [,1] [,2] [,3] ## [1,] &quot;seven books&quot; &quot;seven&quot; &quot;books&quot; ## [2,] &quot;two met&quot; &quot;two&quot; &quot;met&quot; ## [3,] &quot;two factors&quot; &quot;two&quot; &quot;factors&quot; ## [4,] &quot;three lists&quot; &quot;three&quot; &quot;lists&quot; ## [5,] &quot;seven is&quot; &quot;seven&quot; &quot;is&quot; ## [6,] &quot;two when&quot; &quot;two&quot; &quot;when&quot; ## [7,] &quot;ten inches&quot; &quot;ten&quot; &quot;inches&quot; ## [8,] &quot;one war&quot; &quot;one&quot; &quot;war&quot; ## [9,] &quot;one button&quot; &quot;one&quot; &quot;button&quot; ## [10,] &quot;six minutes&quot; &quot;six&quot; &quot;minutes&quot; ## [11,] &quot;ten years&quot; &quot;ten&quot; &quot;years&quot; ## [12,] &quot;two shares&quot; &quot;two&quot; &quot;shares&quot; ## [13,] &quot;two distinct&quot; &quot;two&quot; &quot;distinct&quot; ## [14,] &quot;five cents&quot; &quot;five&quot; &quot;cents&quot; ## [15,] &quot;two pins&quot; &quot;two&quot; &quot;pins&quot; ## [16,] &quot;five robins&quot; &quot;five&quot; &quot;robins&quot; ## [17,] &quot;four kinds&quot; &quot;four&quot; &quot;kinds&quot; ## [18,] &quot;three story&quot; &quot;three&quot; &quot;story&quot; ## [19,] &quot;three inches&quot; &quot;three&quot; &quot;inches&quot; ## [20,] &quot;six comes&quot; &quot;six&quot; &quot;comes&quot; ## [21,] &quot;three batches&quot; &quot;three&quot; &quot;batches&quot; ## [22,] &quot;two leaves&quot; &quot;two&quot; &quot;leaves&quot; 2. Find all contractions. Separate out the pieces before and after the apostrophe. contractions &lt;- &quot;\\\\b([A-Za-z]+)&#39;([A-Za-z]+)&quot; sentences[str_detect(sentences, contractions)] %&gt;% str_match(contractions) ## [,1] [,2] [,3] ## [1,] &quot;It&#39;s&quot; &quot;It&quot; &quot;s&quot; ## [2,] &quot;man&#39;s&quot; &quot;man&quot; &quot;s&quot; ## [3,] &quot;don&#39;t&quot; &quot;don&quot; &quot;t&quot; ## [4,] &quot;store&#39;s&quot; &quot;store&quot; &quot;s&quot; ## [5,] &quot;workmen&#39;s&quot; &quot;workmen&quot; &quot;s&quot; ## [6,] &quot;Let&#39;s&quot; &quot;Let&quot; &quot;s&quot; ## [7,] &quot;sun&#39;s&quot; &quot;sun&quot; &quot;s&quot; ## [8,] &quot;child&#39;s&quot; &quot;child&quot; &quot;s&quot; ## [9,] &quot;king&#39;s&quot; &quot;king&quot; &quot;s&quot; ## [10,] &quot;It&#39;s&quot; &quot;It&quot; &quot;s&quot; ## [11,] &quot;don&#39;t&quot; &quot;don&quot; &quot;t&quot; ## [12,] &quot;queen&#39;s&quot; &quot;queen&quot; &quot;s&quot; ## [13,] &quot;don&#39;t&quot; &quot;don&quot; &quot;t&quot; ## [14,] &quot;pirate&#39;s&quot; &quot;pirate&quot; &quot;s&quot; ## [15,] &quot;neighbor&#39;s&quot; &quot;neighbor&quot; &quot;s&quot; 14.3.5 Replacing matches 14.3.5.1 Exercises 1. Replace all forward slashes in a string with backslashes. s &lt;- str_replace_all(&quot;C:/Users/Someone&quot;, &quot;/&quot;, &quot;\\\\\\\\&quot;) writeLines(s) ## C:\\Users\\Someone 2. Implement a simple version of str_to_lower() using replace_all(). str_replace_all(&quot;ABC&quot;, c(&quot;A&quot; = &quot;a&quot;, &quot;B&quot; = &quot;b&quot;, &quot;C&quot; = &quot;c&quot;)) ## [1] &quot;abc&quot; 3. Switch the first and last letters in words. Which of those strings are still words? reversed_words &lt;- words %&gt;% str_replace_all(&quot;(.)(.+)(.)&quot;, &quot;\\\\3\\\\2\\\\1&quot;) words[reversed_words == words] ## [1] &quot;a&quot; &quot;america&quot; &quot;area&quot; &quot;as&quot; &quot;at&quot; ## [6] &quot;be&quot; &quot;by&quot; &quot;dad&quot; &quot;dead&quot; &quot;depend&quot; ## [11] &quot;do&quot; &quot;educate&quot; &quot;else&quot; &quot;encourage&quot; &quot;engine&quot; ## [16] &quot;europe&quot; &quot;evidence&quot; &quot;example&quot; &quot;excuse&quot; &quot;exercise&quot; ## [21] &quot;expense&quot; &quot;experience&quot; &quot;eye&quot; &quot;go&quot; &quot;he&quot; ## [26] &quot;health&quot; &quot;high&quot; &quot;if&quot; &quot;in&quot; &quot;it&quot; ## [31] &quot;knock&quot; &quot;level&quot; &quot;local&quot; &quot;nation&quot; &quot;no&quot; ## [36] &quot;non&quot; &quot;of&quot; &quot;on&quot; &quot;or&quot; &quot;rather&quot; ## [41] &quot;refer&quot; &quot;remember&quot; &quot;serious&quot; &quot;so&quot; &quot;stairs&quot; ## [46] &quot;test&quot; &quot;to&quot; &quot;tonight&quot; &quot;transport&quot; &quot;treat&quot; ## [51] &quot;trust&quot; &quot;up&quot; &quot;we&quot; &quot;window&quot; &quot;yesterday&quot; 14.3.6 Splitting 14.3.6.1 Exercises 1. Split up a string like &quot;apples, pears, and bananas&quot; into individual components. str_split(&quot;apples, pears, and bananas&quot;, &quot;(, )|( )&quot;) %&gt;% .[[1]] ## [1] &quot;apples&quot; &quot;pears&quot; &quot;and&quot; &quot;bananas&quot; 2. Why is it better to split up by boundary(&quot;word&quot;) than &quot; &quot;? Because there can be more than one empty spaces between the words. str_split(&quot;This is an example.&quot;, &quot; &quot;) %&gt;% .[[1]] ## [1] &quot;This&quot; &quot;is&quot; &quot;an&quot; &quot;&quot; &quot;&quot; &quot;&quot; ## [7] &quot;&quot; &quot;&quot; &quot;&quot; &quot;example.&quot; Using boundary, it will not be a problem. str_split(&quot;This is an example.&quot;, boundary(&quot;word&quot;)) %&gt;% .[[1]] ## [1] &quot;This&quot; &quot;is&quot; &quot;an&quot; &quot;example&quot; 3. What does splitting with an empty string (“”) do? Experiment, and then read the documentation. str_split(&quot;This is an example.&quot;, &quot;&quot;) %&gt;% .[[1]] ## [1] &quot;T&quot; &quot;h&quot; &quot;i&quot; &quot;s&quot; &quot; &quot; &quot;i&quot; &quot;s&quot; &quot; &quot; &quot;a&quot; &quot;n&quot; &quot; &quot; &quot;e&quot; &quot;x&quot; &quot;a&quot; &quot;m&quot; &quot;p&quot; &quot;l&quot; ## [18] &quot;e&quot; &quot;.&quot; It splits the strings into individual characters. 14.3.7 Find matches No exercises 14.4 Other types of pattern 14.4.1 Exercises 1. How would you find all strings containing with regex() vs. with fixed()? str_view_all(&quot;\\\\&quot;, regex(&quot;\\\\\\\\&quot;)) str_view_all(&quot;\\\\&quot;, fixed(&quot;\\\\&quot;)) 2. What are the five most common words in sentences? Top 10 most frequent words: sentences %&gt;% str_split(boundary(&quot;word&quot;)) %&gt;% unlist() %&gt;% table() %&gt;% sort(decreasing = TRUE) %&gt;% head(10) ## . ## the The of a to and in is A was ## 489 262 132 130 119 118 85 81 72 66 Top 10 most frequnet words 14.5 Other uses of regular expressions No exercises 14.6 stringi 14.6.1 Exercises 1. Find the stringi functions that: Count the number of words. stringi::stri_count_words() stringi::stri_count_words(&quot;This is awesome and \\n great!.&quot;) ## [1] 5 Find duplicated strings. stringi::stri_duplicated() returns a vector of booleans, indicating which strings are duplicates. dup &lt;- &quot;this is super super super exciting.&quot; dup &lt;- stringr::str_split(dup, &quot; &quot;)[[1]] stringi::stri_duplicated(dup) ## [1] FALSE FALSE FALSE TRUE TRUE FALSE Subset the duplicated strings: dup[stringi::stri_duplicated(dup)] ## [1] &quot;super&quot; &quot;super&quot; Generate random text. stringi::stri_rand_lipsum() stringi::stri_rand_lipsum(1) ## [1] &quot;Lorem ipsum dolor sit amet, facilisis consequat erat in mattis pellentesque mauris nunc mi sed pulvinar vel ac. Sit bibendum mauris libero quis torquent risus dignissim primis sit dolor. Sodales, in, magna mattis est nec finibus nibh maecenas. At rhoncus eros et, dolor non. Arcu sed ac in semper cursus. Mi at nunc eu dis. Et, at erat platea, sapien, tincidunt accumsan volutpat parturient. Magnis risus quisque ante id consectetur purus posuere.&quot; 2. How do you control the language that stri_sort() uses for sorting? By including the argument locale = .... "],
["factors.html", "15 Factors 15.1 Introduction 15.2 Creating factors 15.3 General Social Survey 15.4 Modifying factor order 15.5 Modifying factor levels", " 15 Factors 15.1 Introduction No exercises. 15.2 Creating factors No exercises. 15.3 General Social Survey 15.3.1 Exercise library(tidyverse) library(forcats) 1 - Explore the distribution of rincome (reported income). What makes the default bar chart hard to understand? How could you improve the plot? gss_cat %&gt;% ggplot() + geom_bar(mapping = aes(x = rincome)) + theme(axis.text.x=element_text(angle=90, hjust=1)) The default bar chart is difficult to understand because Not applicable should be put in the front. Also with so many levels, a horizontal bar chart will look better. gss_cat %&gt;% ggplot() + geom_bar(mapping = aes(x = fct_relevel(rincome, &quot;Not applicable&quot;))) + coord_flip() 2 - What is the most common relig in this survey? What’s the most common partyid? For relig: gss_cat %&gt;% count(relig) %&gt;% arrange(desc(n)) ## # A tibble: 15 x 2 ## relig n ## &lt;fct&gt; &lt;int&gt; ## 1 Protestant 10846 ## 2 Catholic 5124 ## 3 None 3523 ## 4 Christian 689 ## 5 Jewish 388 ## 6 Other 224 ## 7 Buddhism 147 ## 8 Inter-nondenominational 109 ## 9 Moslem/islam 104 ## 10 Orthodox-christian 95 ## 11 No answer 93 ## 12 Hinduism 71 ## 13 Other eastern 32 ## 14 Native american 23 ## 15 Don&#39;t know 15 For partyid: gss_cat %&gt;% count(partyid) %&gt;% arrange(desc(n)) ## # A tibble: 10 x 2 ## partyid n ## &lt;fct&gt; &lt;int&gt; ## 1 Independent 4119 ## 2 Not str democrat 3690 ## 3 Strong democrat 3490 ## 4 Not str republican 3032 ## 5 Ind,near dem 2499 ## 6 Strong republican 2314 ## 7 Ind,near rep 1791 ## 8 Other party 393 ## 9 No answer 154 ## 10 Don&#39;t know 1 3 - Which relig does denom (denomination) apply to? How can you find out with a table? How can you find out with a visualisation? With table: table(gss_cat$relig, gss_cat$denom) ## ## No answer Don&#39;t know No denomination Other ## No answer 93 0 0 0 ## Don&#39;t know 0 0 0 0 ## Inter-nondenominational 0 0 0 0 ## Native american 0 0 0 0 ## Christian 2 11 452 0 ## Orthodox-christian 0 0 0 0 ## Moslem/islam 0 0 0 0 ## Other eastern 0 0 0 0 ## Hinduism 0 0 0 0 ## Buddhism 0 0 0 0 ## Other 0 0 7 0 ## None 0 0 0 0 ## Jewish 0 0 0 0 ## Catholic 0 0 0 0 ## Protestant 22 41 1224 2534 ## Not applicable 0 0 0 0 ## ## Episcopal Presbyterian-dk wh ## No answer 0 0 ## Don&#39;t know 0 0 ## Inter-nondenominational 0 0 ## Native american 0 0 ## Christian 0 0 ## Orthodox-christian 0 0 ## Moslem/islam 0 0 ## Other eastern 0 0 ## Hinduism 0 0 ## Buddhism 0 0 ## Other 0 0 ## None 0 0 ## Jewish 0 0 ## Catholic 0 0 ## Protestant 397 244 ## Not applicable 0 0 ## ## Presbyterian, merged Other presbyterian ## No answer 0 0 ## Don&#39;t know 0 0 ## Inter-nondenominational 0 0 ## Native american 0 0 ## Christian 0 0 ## Orthodox-christian 0 0 ## Moslem/islam 0 0 ## Other eastern 0 0 ## Hinduism 0 0 ## Buddhism 0 0 ## Other 0 0 ## None 0 0 ## Jewish 0 0 ## Catholic 0 0 ## Protestant 67 47 ## Not applicable 0 0 ## ## United pres ch in us Presbyterian c in us ## No answer 0 0 ## Don&#39;t know 0 0 ## Inter-nondenominational 0 0 ## Native american 0 0 ## Christian 0 0 ## Orthodox-christian 0 0 ## Moslem/islam 0 0 ## Other eastern 0 0 ## Hinduism 0 0 ## Buddhism 0 0 ## Other 0 0 ## None 0 0 ## Jewish 0 0 ## Catholic 0 0 ## Protestant 110 104 ## Not applicable 0 0 ## ## Lutheran-dk which Evangelical luth ## No answer 0 0 ## Don&#39;t know 0 0 ## Inter-nondenominational 0 0 ## Native american 0 0 ## Christian 0 0 ## Orthodox-christian 0 0 ## Moslem/islam 0 0 ## Other eastern 0 0 ## Hinduism 0 0 ## Buddhism 0 0 ## Other 0 0 ## None 0 0 ## Jewish 0 0 ## Catholic 0 0 ## Protestant 267 122 ## Not applicable 0 0 ## ## Other lutheran Wi evan luth synod ## No answer 0 0 ## Don&#39;t know 0 0 ## Inter-nondenominational 0 0 ## Native american 0 0 ## Christian 0 0 ## Orthodox-christian 0 0 ## Moslem/islam 0 0 ## Other eastern 0 0 ## Hinduism 0 0 ## Buddhism 0 0 ## Other 0 0 ## None 0 0 ## Jewish 0 0 ## Catholic 0 0 ## Protestant 30 71 ## Not applicable 0 0 ## ## Lutheran-mo synod Luth ch in america Am lutheran ## No answer 0 0 0 ## Don&#39;t know 0 0 0 ## Inter-nondenominational 0 0 0 ## Native american 0 0 0 ## Christian 0 0 0 ## Orthodox-christian 0 0 0 ## Moslem/islam 0 0 0 ## Other eastern 0 0 0 ## Hinduism 0 0 0 ## Buddhism 0 0 0 ## Other 0 0 0 ## None 0 0 0 ## Jewish 0 0 0 ## Catholic 0 0 0 ## Protestant 212 71 146 ## Not applicable 0 0 0 ## ## Methodist-dk which Other methodist ## No answer 0 0 ## Don&#39;t know 0 0 ## Inter-nondenominational 0 0 ## Native american 0 0 ## Christian 0 0 ## Orthodox-christian 0 0 ## Moslem/islam 0 0 ## Other eastern 0 0 ## Hinduism 0 0 ## Buddhism 0 0 ## Other 0 0 ## None 0 0 ## Jewish 0 0 ## Catholic 0 0 ## Protestant 239 33 ## Not applicable 0 0 ## ## United methodist Afr meth ep zion ## No answer 0 0 ## Don&#39;t know 0 0 ## Inter-nondenominational 0 0 ## Native american 0 0 ## Christian 0 0 ## Orthodox-christian 0 0 ## Moslem/islam 0 0 ## Other eastern 0 0 ## Hinduism 0 0 ## Buddhism 0 0 ## Other 0 0 ## None 0 0 ## Jewish 0 0 ## Catholic 0 0 ## Protestant 1067 32 ## Not applicable 0 0 ## ## Afr meth episcopal Baptist-dk which ## No answer 0 0 ## Don&#39;t know 0 0 ## Inter-nondenominational 0 0 ## Native american 0 0 ## Christian 0 0 ## Orthodox-christian 0 0 ## Moslem/islam 0 0 ## Other eastern 0 0 ## Hinduism 0 0 ## Buddhism 0 0 ## Other 0 0 ## None 0 0 ## Jewish 0 0 ## Catholic 0 0 ## Protestant 77 1457 ## Not applicable 0 0 ## ## Other baptists Southern baptist ## No answer 0 0 ## Don&#39;t know 0 0 ## Inter-nondenominational 0 0 ## Native american 0 0 ## Christian 0 0 ## Orthodox-christian 0 0 ## Moslem/islam 0 0 ## Other eastern 0 0 ## Hinduism 0 0 ## Buddhism 0 0 ## Other 0 0 ## None 0 0 ## Jewish 0 0 ## Catholic 0 0 ## Protestant 213 1536 ## Not applicable 0 0 ## ## Nat bapt conv usa Nat bapt conv of am ## No answer 0 0 ## Don&#39;t know 0 0 ## Inter-nondenominational 0 0 ## Native american 0 0 ## Christian 0 0 ## Orthodox-christian 0 0 ## Moslem/islam 0 0 ## Other eastern 0 0 ## Hinduism 0 0 ## Buddhism 0 0 ## Other 0 0 ## None 0 0 ## Jewish 0 0 ## Catholic 0 0 ## Protestant 40 76 ## Not applicable 0 0 ## ## Am bapt ch in usa Am baptist asso Not applicable ## No answer 0 0 0 ## Don&#39;t know 0 0 15 ## Inter-nondenominational 0 0 109 ## Native american 0 0 23 ## Christian 0 0 224 ## Orthodox-christian 0 0 95 ## Moslem/islam 0 0 104 ## Other eastern 0 0 32 ## Hinduism 0 0 71 ## Buddhism 0 0 147 ## Other 0 0 217 ## None 0 0 3523 ## Jewish 0 0 388 ## Catholic 0 0 5124 ## Protestant 130 237 0 ## Not applicable 0 0 0 With so many levels it is very hard to see. We can use geom_tile(): gss_cat %&gt;% group_by(relig, denom) %&gt;% summarize(n = n()) %&gt;% complete(relig, denom, fill = list(n = 0)) %&gt;% ggplot() + geom_tile(mapping = aes(x = relig, y = denom, fill = n)) + scale_fill_gradient(low = &#39;white&#39;, high = &#39;steelblue&#39;) + theme(axis.text.x=element_text(angle=90, hjust=1)) which gives us too much empty space. Perhaps a scatter plot with different point area will look better: gss_cat %&gt;% group_by(relig, denom) %&gt;% summarize(n = n()) %&gt;% ggplot() + geom_point(mapping = aes(x = relig, y = denom, size = n)) + theme(axis.text.x=element_text(angle=90, hjust=1)) 15.4 Modifying factor order 15.4.1 Exercises 1 - There are some suspiciously high numbers in tvhours. Is the mean a good summary? The distribution of tvhours is highly skewed. The mean might not be the best choice as it is heavily influenced by the extreme values in tvhours. Median would probably be a better choice. ggplot(gss_cat, mapping = aes(x = tvhours)) + geom_bar() ## Warning: Removed 10146 rows containing non-finite values (stat_count). 2 - For each factor in gss_cat identify whether the order of the levels is arbitrary or principled. There are 6 factor variables in gss_cat. marital - To me, they are arbitrary. At least it feels weird to order “Separated”, “Divorced”, and “Widowed”. levels(gss_cat$marital) ## [1] &quot;No answer&quot; &quot;Never married&quot; &quot;Separated&quot; &quot;Divorced&quot; ## [5] &quot;Widowed&quot; &quot;Married&quot; race - Arbitrary levels(gss_cat$race) ## [1] &quot;Other&quot; &quot;Black&quot; &quot;White&quot; &quot;Not applicable&quot; rincome - Principled levels(gss_cat$rincome) ## [1] &quot;No answer&quot; &quot;Don&#39;t know&quot; &quot;Refused&quot; &quot;$25000 or more&quot; ## [5] &quot;$20000 - 24999&quot; &quot;$15000 - 19999&quot; &quot;$10000 - 14999&quot; &quot;$8000 to 9999&quot; ## [9] &quot;$7000 to 7999&quot; &quot;$6000 to 6999&quot; &quot;$5000 to 5999&quot; &quot;$4000 to 4999&quot; ## [13] &quot;$3000 to 3999&quot; &quot;$1000 to 2999&quot; &quot;Lt $1000&quot; &quot;Not applicable&quot; partyid - Principled within party (i.e., not strong vs strong), but arbitrary between parties. levels(gss_cat$partyid) ## [1] &quot;No answer&quot; &quot;Don&#39;t know&quot; &quot;Other party&quot; ## [4] &quot;Strong republican&quot; &quot;Not str republican&quot; &quot;Ind,near rep&quot; ## [7] &quot;Independent&quot; &quot;Ind,near dem&quot; &quot;Not str democrat&quot; ## [10] &quot;Strong democrat&quot; relig - Arbitrary levels(gss_cat$relig) ## [1] &quot;No answer&quot; &quot;Don&#39;t know&quot; ## [3] &quot;Inter-nondenominational&quot; &quot;Native american&quot; ## [5] &quot;Christian&quot; &quot;Orthodox-christian&quot; ## [7] &quot;Moslem/islam&quot; &quot;Other eastern&quot; ## [9] &quot;Hinduism&quot; &quot;Buddhism&quot; ## [11] &quot;Other&quot; &quot;None&quot; ## [13] &quot;Jewish&quot; &quot;Catholic&quot; ## [15] &quot;Protestant&quot; &quot;Not applicable&quot; denom - Arbitrary levels(gss_cat$denom) ## [1] &quot;No answer&quot; &quot;Don&#39;t know&quot; &quot;No denomination&quot; ## [4] &quot;Other&quot; &quot;Episcopal&quot; &quot;Presbyterian-dk wh&quot; ## [7] &quot;Presbyterian, merged&quot; &quot;Other presbyterian&quot; &quot;United pres ch in us&quot; ## [10] &quot;Presbyterian c in us&quot; &quot;Lutheran-dk which&quot; &quot;Evangelical luth&quot; ## [13] &quot;Other lutheran&quot; &quot;Wi evan luth synod&quot; &quot;Lutheran-mo synod&quot; ## [16] &quot;Luth ch in america&quot; &quot;Am lutheran&quot; &quot;Methodist-dk which&quot; ## [19] &quot;Other methodist&quot; &quot;United methodist&quot; &quot;Afr meth ep zion&quot; ## [22] &quot;Afr meth episcopal&quot; &quot;Baptist-dk which&quot; &quot;Other baptists&quot; ## [25] &quot;Southern baptist&quot; &quot;Nat bapt conv usa&quot; &quot;Nat bapt conv of am&quot; ## [28] &quot;Am bapt ch in usa&quot; &quot;Am baptist asso&quot; &quot;Not applicable&quot; 3 - Why did moving “Not applicable”&quot; to the front of the levels move it to the bottom of the plot? The positions of the levels on the plot are determiend by the factor levels. The first level is placed at the bottom, and the last level is placed at the top. 15.5 Modifying factor levels 15.5.1 Exercises 1 - How have the proportions of people identifying as Democrat, Republican, and Independent changed over time? gss_cat %&gt;% mutate(partyid = fct_collapse(partyid, other = c(&quot;No answer&quot;, &quot;Don&#39;t know&quot;, &quot;Other party&quot;), rep = c(&quot;Strong republican&quot;, &quot;Not str republican&quot;), ind = c(&quot;Ind,near rep&quot;, &quot;Independent&quot;, &quot;Ind,near dem&quot;), dem = c(&quot;Not str democrat&quot;, &quot;Strong democrat&quot;))) %&gt;% group_by(year, partyid) %&gt;% summarize(n = n()) %&gt;% ggplot(mapping = aes(x = year, y = n, color = fct_reorder2(partyid, year, n))) + geom_point() + geom_line() + labs(color = &#39;Party&#39;, x = &#39;Year&#39;, y = &#39;Count&#39;) 2 - How could you collapse rincome into a small set of categories? We could collapse the lower levels so each the levels are consistently increments of $5000, collpase “No answer”, “Don’t know”, and “Refused” to a single category. gss_cat %&gt;% mutate(rincome = fct_collapse(rincome, &quot;No answer&quot; = c(&quot;No answer&quot;, &quot;Don&#39;t know&quot;, &quot;Refused&quot;), &quot;$0 to 4999&quot; = c(&quot;Lt $1000&quot;, &quot;$1000 to 2999&quot;, &quot;$3000 to 3999&quot;, &quot;$4000 to 4999&quot;), &quot;$5000 to 9999&quot; = c(&quot;$5000 to 5999&quot;, &quot;$6000 to 6999&quot;, &quot;$7000 to 7999&quot;, &quot;$8000 to 9999&quot;))) %&gt;% mutate(rincome = fct_relevel(rincome, &quot;Not applicable&quot;)) %&gt;% count(rincome) ## # A tibble: 8 x 2 ## rincome n ## &lt;fct&gt; &lt;int&gt; ## 1 Not applicable 7043 ## 2 No answer 1425 ## 3 $25000 or more 7363 ## 4 $20000 - 24999 1283 ## 5 $15000 - 19999 1048 ## 6 $10000 - 14999 1168 ## 7 $5000 to 9999 970 ## 8 $0 to 4999 1183 "],
["dates-and-times.html", "16 Dates and times 16.1 Introduction 16.2 Creating date/times 16.3 Date-time components 16.4 Time spans 16.5 Time zones", " 16 Dates and times 16.1 Introduction No exercises. 16.2 Creating date/times 16.2.1 Exercises library(tidyverse) library(lubridate) library(nycflights13) 1 - What happens if you parse a string that contains invalid dates? ymd(c(&quot;2010-10-10&quot;, &quot;bananas&quot;)) ## Warning: 1 failed to parse. ## [1] &quot;2010-10-10&quot; NA It will return NA. 2 - What does the tzone argument to today() do? Why is it important? tzone specifies which time zone you would like to find the current date of. It is important the dates of two different places in different timzones can differ. 3 - Use the appropriate lubridate function to parse each of the following dates: d1 &lt;- &quot;January 1, 2010&quot; mdy(d1) ## [1] &quot;2010-01-01&quot; d2 &lt;- &quot;2015-Mar-07&quot; ymd(d2) ## [1] &quot;2015-03-07&quot; d3 &lt;- &quot;06-Jun-2017&quot; dmy(d3) ## [1] &quot;2017-06-06&quot; d4 &lt;- c(&quot;August 19 (2015)&quot;, &quot;July 1 (2015)&quot;) mdy(d4) ## [1] &quot;2015-08-19&quot; &quot;2015-07-01&quot; d5 &lt;- &quot;12/30/14&quot; # Dec 30, 2014 mdy(d5) ## [1] &quot;2014-12-30&quot; 16.3 Date-time components 16.3.1 Exercises We use the flights_dt dataset (code is provided in the book) for the remaining exercises. make_datetime_100 &lt;- function(year, month, day, time) { make_datetime(year, month, day, time %/% 100, time %% 100) } flights_dt &lt;- flights %&gt;% filter(!is.na(dep_time), !is.na(arr_time)) %&gt;% mutate( dep_time = make_datetime_100(year, month, day, dep_time), arr_time = make_datetime_100(year, month, day, arr_time), sched_dep_time = make_datetime_100(year, month, day, sched_dep_time), sched_arr_time = make_datetime_100(year, month, day, sched_arr_time) ) %&gt;% select(origin, dest, ends_with(&quot;delay&quot;), ends_with(&quot;time&quot;)) 1 - How does the distribution of flight times within a day change over the course of the year? A distribution of flight times (departure by the hours) within a day looks something like this: flights_dt %&gt;% mutate(date = make_date(year(dep_time), month(dep_time), mday(dep_time)), hour = hour(dep_time)) %&gt;% group_by(date, hour) %&gt;% filter(date == &#39;2013-01-01&#39;) %&gt;% ggplot(mapping = aes(x = hour)) + geom_density() If we want to visualize the whole year: flights_dt %&gt;% mutate(date = make_date(year(dep_time), month(dep_time), mday(dep_time)), hour = hour(dep_time)) %&gt;% group_by(date, hour) %&gt;% ggplot(mapping = aes(x = hour, group = date)) + geom_density(alpha = .1) We see that the distributions for most days are very much the same. 2 - Compare dep_time, sched_dep_time and dep_delay. Are they consistent? Explain your findings. Let’s check if there are any inconsistent records: flights_dt %&gt;% select(contains(&#39;dep&#39;)) %&gt;% mutate(cal_delay = as.numeric(dep_time - sched_dep_time) / 60) %&gt;% filter(dep_delay != cal_delay) ## # A tibble: 810 x 5 ## dep_delay pre_dep_delay dep_time sched_dep_time ## &lt;dbl&gt; &lt;dbl&gt; &lt;dttm&gt; &lt;dttm&gt; ## 1 853 - 5.00 2013-01-01 08:48:00 2013-01-01 18:35:00 ## 2 43.0 - 3.00 2013-01-02 00:42:00 2013-01-02 23:59:00 ## 3 156 43.0 2013-01-02 01:26:00 2013-01-02 22:50:00 ## 4 33.0 - 5.00 2013-01-03 00:32:00 2013-01-03 23:59:00 ## 5 185 33.0 2013-01-03 00:50:00 2013-01-03 21:45:00 ## 6 156 185 2013-01-03 02:35:00 2013-01-03 23:59:00 ## 7 26.0 - 10.0 2013-01-04 00:25:00 2013-01-04 23:59:00 ## 8 141 26.0 2013-01-04 01:06:00 2013-01-04 22:45:00 ## 9 15.0 - 1.00 2013-01-05 00:14:00 2013-01-05 23:59:00 ## 10 127 15.0 2013-01-05 00:37:00 2013-01-05 22:30:00 ## # ... with 800 more rows, and 1 more variable: cal_delay &lt;dbl&gt; These inconsistent records have one thing in common. The dep_delay tells us the flights were delayed, but cal_delay tells us the flights departed early. The reason is that these delayed flights actually departed on the next day, and were not reflected in dep_time. If we add one day to the dep_time, the results should be consistent. flights_dt %&gt;% select(contains(&#39;dep&#39;)) %&gt;% mutate(cal_delay = as.numeric(dep_time - sched_dep_time) / 60) %&gt;% filter(dep_delay != cal_delay) %&gt;% mutate(dep_time = update(dep_time, mday = mday(dep_time) + 1)) %&gt;% mutate(cal_delay = as.numeric(dep_time - sched_dep_time)) %&gt;% filter(dep_delay != cal_delay) ## # A tibble: 0 x 5 ## # ... with 5 variables: dep_delay &lt;dbl&gt;, pre_dep_delay &lt;dbl&gt;, ## # dep_time &lt;dttm&gt;, sched_dep_time &lt;dttm&gt;, cal_delay &lt;dbl&gt; All records are now consistent. 3 - Compare air_time with the duration between the departure and arrival. Explain your findings. (Hint: consider the location of the airport.) To Do. 4 - How does the average delay time change over the course of a day? Should you use dep_time or sched_dep_time? Why? We should use sched_dep_time because it will tell us how much delay we should expect at the scheduled departure time. flights_dt %&gt;% mutate(hour = hour(sched_dep_time)) %&gt;% group_by(hour) %&gt;% summarize(avg_dep_delay = mean(dep_delay, na.rm = TRUE)) %&gt;% ggplot(mapping = aes(x = hour, y = avg_dep_delay)) + geom_point() + geom_smooth(se = FALSE) + labs(y = &quot;Average departure delay (in minutes)&quot;, x = &quot;Scheduled departure time (in hours)&quot;) ## `geom_smooth()` using method = &#39;loess&#39; 5 - On what day of the week should you leave if you want to minimise the chance of a delay? flights_dt %&gt;% mutate(dayweek = wday(sched_dep_time, label = TRUE)) %&gt;% group_by(dayweek) %&gt;% summarize(avg_dep_delay = mean(dep_delay, na.rm = TRUE), avg_arr_delay = mean(arr_delay, na.rm = TRUE)) %&gt;% gather(key = &#39;delay&#39;, value = &#39;minutes&#39;, 2:3) %&gt;% ggplot() + geom_col(mapping = aes(x = dayweek, y = minutes, fill = delay), position = &#39;dodge&#39;) It looks like Saturdays are the best days to fly. 6 - What makes the distribution of diamonds$carat and flights$sched_dep_time similar? In the distribution of diamonds$carat, we can see there are peaks at rounded numbers, like 0.3, 0.4, 0.5, 0.9, 1.0, 1.5, and 2.0. diamonds %&gt;% ggplot() + geom_freqpoly(mapping = aes(x = carat), binwidth = .02) In distribution of flights_dt%sched_dep_time, again we see peaks at rounded or nice numbers, such as 0, 5, 10, 15, etc. flights_dt %&gt;% mutate(minutes = minute(sched_dep_time)) %&gt;% ggplot() + geom_freqpoly(mapping = aes(x = minutes), binwidth = 1) As the book suggests, these are most likely cuased by human factors, namely the convenience in representing nice, rounded numbers. 7 - Confirm my hypothesis that the early departures of flights in minutes 20-30 and 50-60 are caused by scheduled flights that leave early. Hint: create a binary variable that tells you whether or not a flight was delayed. flights_dt %&gt;% mutate(delayed = dep_delay &gt; 0, minutes = minute(sched_dep_time) %/% 10 * 10, minutes = factor(minutes, levels = c(0,10,20,30,40,50), labels = c(&#39;0 - 9 mins&#39;, &#39;10 - 19 mins&#39;, &#39;20 - 29 mins&#39;, &#39;30 - 39 mins&#39;, &#39;40 - 49 mins&#39;, &#39;50 - 50 mins&#39;))) %&gt;% group_by(minutes) %&gt;% summarize(prop_early = 1 - mean(delayed, na.rm = TRUE)) %&gt;% ggplot() + geom_point(mapping = aes(x = minutes, y = prop_early)) + labs(x = &#39;Scheduled departure (minutes)&#39;, y = &#39;Proportion of early departures&#39;) 16.4 Time spans 16.4.1 Exercises 1 - Why is there months() but no dmonths()? Months do not have a fixed duration in seconds, unlike days, weeks, and years, because there are months with 28, 29, 30, and 31 days. 2 - Explain days(overnight \\* 1) to someone who has just started learning R. How does it work? overnight is a boolean variable. If arr_time is less than dep_time, then the flight arrives on the next day, and overnight is TRUE; otherise, FALSE. Actually, the underlying value of TRUE is 1, and FALSE is 0, so the * 0 can actually be omitted. If overnight is TRUE, or 1, days(overnight) will add one day to the arr_time and sched_arr_time datetime. flights_dt %&gt;% mutate( overnight = arr_time &lt; dep_time, arr_time = arr_time + days(overnight), sched_arr_time = sched_arr_time + days(overnight) ) ## # A tibble: 109,284 x 12 ## origin dest dep_delay arr_delay pre_dep_delay dep_time ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dttm&gt; ## 1 JFK MIA 2.00 33.0 0 2013-01-01 05:42:00 ## 2 JFK BQN - 1.00 -18.0 2.00 2013-01-01 05:44:00 ## 3 JFK MCO - 3.00 - 8.00 - 1.00 2013-01-01 05:57:00 ## 4 JFK PBI - 2.00 - 2.00 - 3.00 2013-01-01 05:58:00 ## 5 JFK TPA - 2.00 - 3.00 - 2.00 2013-01-01 05:58:00 ## 6 JFK LAX - 2.00 7.00 - 2.00 2013-01-01 05:58:00 ## 7 JFK BOS 0 - 4.00 - 2.00 2013-01-01 05:59:00 ## 8 JFK ATL - 4.00 - 8.00 0 2013-01-01 06:06:00 ## 9 JFK SFO 11.0 14.0 - 4.00 2013-01-01 06:11:00 ## 10 JFK RSW 3.00 4.00 11.0 2013-01-01 06:13:00 ## # ... with 109,274 more rows, and 6 more variables: sched_dep_time &lt;dttm&gt;, ## # arr_time &lt;dttm&gt;, sched_arr_time &lt;dttm&gt;, air_time &lt;dbl&gt;, ## # flight_time &lt;dbl&gt;, overnight &lt;lgl&gt; 3 - Create a vector of dates giving the first day of every month in 2015. Create a vector of dates giving the first day of every month in the current year. make_date(year = 2015, month = 1:12, day = 1) ## [1] &quot;2015-01-01&quot; &quot;2015-02-01&quot; &quot;2015-03-01&quot; &quot;2015-04-01&quot; &quot;2015-05-01&quot; ## [6] &quot;2015-06-01&quot; &quot;2015-07-01&quot; &quot;2015-08-01&quot; &quot;2015-09-01&quot; &quot;2015-10-01&quot; ## [11] &quot;2015-11-01&quot; &quot;2015-12-01&quot; make_date(year = year(today()), month = 1:12, day = 1) ## [1] &quot;2018-01-01&quot; &quot;2018-02-01&quot; &quot;2018-03-01&quot; &quot;2018-04-01&quot; &quot;2018-05-01&quot; ## [6] &quot;2018-06-01&quot; &quot;2018-07-01&quot; &quot;2018-08-01&quot; &quot;2018-09-01&quot; &quot;2018-10-01&quot; ## [11] &quot;2018-11-01&quot; &quot;2018-12-01&quot; 4 - Write a function that given your birthday (as a date), returns how old you are in years. howold &lt;- function(d) { age &lt;- today() - d return(floor(age/dyears(1))) } howold(ymd(19860701)) ## [1] 31 5 - Why can’t (today() %--% (today() + years(1))) / months(1) work? It works? (today() %--% (today() + years(1))) / months(1) ## [1] 12 The interval is defined as starting from today to a year from today, and there are 12 months in between. 16.5 Time zones No exercises. "],
["introduction-13.html", "17 Introduction", " 17 Introduction No exercises. "],
["pipes.html", "18 Pipes", " 18 Pipes No exercises. "],
["functions.html", "19 Functions 19.1 Introduction 19.2 When should you write a function? 19.3 Functions are for humans and computers 19.4 Conditional execution 19.5 Function arguments 19.6 Return values 19.7 Environment", " 19 Functions 19.1 Introduction No Exercises. 19.2 When should you write a function? 19.2.1 Practice 1- Why is TRUE not a parameter to rescale01()? What would happen if x contained a single missing value, and na.rm was FALSE? TRUE is not a parameter to rescale01() because we want na.rm to always be equal to TRUE. If na.rm is set to FALSE and there are missing values in the input vectors, the output vectors will be all NAs. rescale01 &lt;- function(x) { rng &lt;- range(x, na.rm = FALSE) (x - rng[1]) / (rng[2] - rng[1]) } rescale01(c(1,2,3,4,NA)) ## [1] NA NA NA NA NA 2 - In the second variant of rescale01(), infinite values are left unchanged. Rewrite rescale01() so that -Inf is mapped to 0, and Inf is mapped to 1. rescale01 &lt;- function(x) { rng &lt;- range(x, na.rm = TRUE, finite = TRUE) #replace -inf with 0 x[x == -Inf] &lt;- 0 #replace Inf with 1 x[x == Inf] &lt;- 1 (x - rng[1]) / (rng[2] - rng[1]) } rescale01(c(1,2,3,4,5,NA,6,7,8,-Inf,9,Inf)) ## [1] 0.000 0.125 0.250 0.375 0.500 NA 0.625 0.750 0.875 -0.125 ## [11] 1.000 0.000 3 - Practice turning the following code snippets into functions. Think about what each function does. What would you call it? How many arguments does it need? Can you rewrite it to be more expressive or less duplicative? mean(is.na(x)) x / sum(x, na.rm = TRUE) sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE) The first code returns the proportion of NA in a vector. I am giving the name prop_NA to the function. prop_NA &lt;- function(x){ return(mean(is.na(x))) } The second code converts the raw values to their weights. to_weights is the name. Note that the function will not work if there are negative numbers in the vector. to_weights &lt;- function(x){ x / sum(x, na.rm = TRUE) } The third code is the formula for coefficient of variation. So I am naming the fucntion coefvar. coefvar &lt;- function(x){ return(sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE)) } 4 - Follow http://nicercode.github.io/intro/writing-functions.html to write your own functions to compute the variance and skew of a numeric vector. Assuming we are referrring to the calculation of sample variance: my_variance &lt;- function(x){ #difference from the mean diff_from_mean &lt;- (x - mean(x, rm.na = TRUE)) #sum of squares sum_of_squares &lt;- sum(diff_from_mean^2, rm.na = TRUE) #return sample variance return(sum_of_squares/(sum(!is.na(x)) - 1)) } my_variance(c(1,2,3,4,3,2,3,4,5)) ## [1] 1.625 For skewness, we use ratio of the third moment and standard deviation cubed. my_skewness &lt;- function(x){ diff_from_mean &lt;- (x - mean(x, rm.na = TRUE)) third_moment &lt;- sum(diff_from_mean^3, na.rm = TRUE) std_cubed &lt;- sum(diff_from_mean^2, na.rm = TRUE)^(3/2)/sqrt(sum(!is.na(x))) return(third_moment/std_cubed) } my_skewness(c(1,2,3,2,1)) ## [1] 0.3436216 5 - Write both_na(), a function that takes two vectors of the same length and returns the number of positions that have an NA in both vectors. both_na &lt;- function(x, y){ #get positions of NA x &lt;- is.na(x) y &lt;- is.na(y) #return number of same positions that have NA return(sum(x &amp; y)) } both_na(c(1,2,NA,NA,5), c(5,4,3,NA,NA)) ## [1] 1 6 - What do the following functions do? Why are they useful even though they are so short? The first function returns either TRUE if x is a directory, and FALSE otherwise. is_directory &lt;- function(x) file.info(x)$isdir is_directory(&quot;../R4DS_Solutions&quot;) is_readable &lt;- function(x) file.access(x, 4) == 0 is_readable(&quot;Chapter10.html&quot;) ## Chapter10.html ## FALSE They are useful because the function names are more meaningful and interpretable than the codes themselves. 7 - Read the complete lyrics to “Little Bunny Foo Foo”. There’s a lot of duplication in this song. Extend the initial piping example to recreate the complete song, and use functions to reduce the duplication. foofoo &lt;- function(){ first &lt;- &quot;Little bunny Foo Foo\\nHopping through the forest\\nScooping up the field mice\\nAnd bopping them on the head&quot; second &lt;-&quot;Down came the Good Fairy, and she said\\n\\&quot;Little bunny Foo Foo\\nI don&#39;t want to see you\\nScooping up the field mice\\nAnd bopping them on the head.\\&quot;&quot; cat(second) i &lt;- 3 while(i &gt; 0){ word &lt;- switch(i, &#39;one&#39;, &#39;two&#39;, &#39;three&#39; ) third &lt;- paste0(&quot;I&#39;ll give you &quot;, word, &quot; chances,\\nAnd if you don&#39;t behave, I will turn you into a goon!\\&quot;\\nAnd the next day...&quot;) cat(first, second, third, sep = &quot;\\n\\n&quot;) i &lt;- i - 1 } final &lt;- &quot;I gave you three chances and you didn&#39;t behave so....\\nPOOF. She turned him into a Goon.&quot; cat(first, second, final, sep = &quot;\\n\\n&quot;) } foofoo() ## Down came the Good Fairy, and she said ## &quot;Little bunny Foo Foo ## I don&#39;t want to see you ## Scooping up the field mice ## And bopping them on the head.&quot;Little bunny Foo Foo ## Hopping through the forest ## Scooping up the field mice ## And bopping them on the head ## ## Down came the Good Fairy, and she said ## &quot;Little bunny Foo Foo ## I don&#39;t want to see you ## Scooping up the field mice ## And bopping them on the head.&quot; ## ## I&#39;ll give you three chances, ## And if you don&#39;t behave, I will turn you into a goon!&quot; ## And the next day... ## Little bunny Foo Foo ## Hopping through the forest ## Scooping up the field mice ## And bopping them on the head ## ## Down came the Good Fairy, and she said ## &quot;Little bunny Foo Foo ## I don&#39;t want to see you ## Scooping up the field mice ## And bopping them on the head.&quot; ## ## I&#39;ll give you two chances, ## And if you don&#39;t behave, I will turn you into a goon!&quot; ## And the next day... ## Little bunny Foo Foo ## Hopping through the forest ## Scooping up the field mice ## And bopping them on the head ## ## Down came the Good Fairy, and she said ## &quot;Little bunny Foo Foo ## I don&#39;t want to see you ## Scooping up the field mice ## And bopping them on the head.&quot; ## ## I&#39;ll give you one chances, ## And if you don&#39;t behave, I will turn you into a goon!&quot; ## And the next day... ## Little bunny Foo Foo ## Hopping through the forest ## Scooping up the field mice ## And bopping them on the head ## ## Down came the Good Fairy, and she said ## &quot;Little bunny Foo Foo ## I don&#39;t want to see you ## Scooping up the field mice ## And bopping them on the head.&quot; ## ## I gave you three chances and you didn&#39;t behave so.... ## POOF. She turned him into a Goon. 19.3 Functions are for humans and computers 19.3.1 Exercises 1 - Read the source code for each of the following three functions, puzzle out what they do, and then brainstorm better names. The first function checks whether the word starts with a given prefix. is_prefix can be the name of the function. is_prefix &lt;- function(string, prefix) { substr(string, 1, nchar(prefix)) == prefix } The second function removes the last element of a vector. If the vector length is less than or equal to 1, then the function returns NULL. remove_last is the name: remove_last &lt;- function(x) { if (length(x) &lt;= 1) return(NULL) x[-length(x)] } The third function repeats y and returns a vector of length x. repeat_max can be the name: repeat_max &lt;- function(x, y) { rep(y, length.out = length(x)) } 2 - Take a function that you’ve written recently and spend 5 minutes brainstorming a better name for it and its arguments. To Do. 3 - Compare and contrast rnorm() and MASS::mvrnorm(). How could you make them more consistent? rnorm() returns values drawn from a normal distribution. mvrnorm() returns values draw from a multivariable normal distribution. The names are self explanatory, and the argument names are correct, clear and already consistent. 4 - Make a case for why norm_r(), norm_d() etc would be better than rnorm(), dnorm(). Make a case for the opposite. It’s the opposite way of thinking. In rnomr(), the logic of thinking is “I want to generate random numbers from a normal distribution”. In norm_r(), the logic is “I want to use normal distribution to generate random numbers.” 19.4 Conditional execution 19.4.1 Exercises 1 - What’s the difference between if and ifelse()? Carefully read the help and construct three examples that illustrate the key differences. They are both used to execute conditional statements. ifelse() can be cleaner and easier to understand than using if statements in some caes. For example: age &lt;- 17 ifelse(age &gt;= 18, &#39;adult&#39;, &#39;child&#39;) ## [1] &quot;child&quot; If written with if structure: age &lt;- 17 f &lt;- function(x){ if (age &gt;= 18) { return(&#39;adult&#39;) } else { return(&#39;child&#39;) } } f(age) ## [1] &quot;child&quot; 2 - Write a greeting function that says “good morning”, “good afternoon”, or “good evening”, depending on the time of day. (Hint: use a time argument that defaults to lubridate::now(). That will make it easier to test your function.) greeting &lt;- function(){ h &lt;- lubridate::hour(lubridate::now()) if (dplyr::between(h, 12, 18)){ print(&quot;Good Afternoon.&quot;) } else if(dplyr::between(h, 18, 24)){ print(&quot;Good Evening&quot;) } else { print(&quot;Good Morning&quot;) } } greeting() ## [1] &quot;Good Evening&quot; 3 - Implement a fizzbuzz function. It takes a single number as input. If the number is divisible by three, it returns “fizz”. If it’s divisible by five it returns “buzz”. If it’s divisible by three and five, it returns “fizzbuzz”. Otherwise, it returns the number. Make sure you first write working code before you create the function. fizzbuzz &lt;- function(x){ if (x %% 3 == 0 &amp;&amp; x %% 5 == 0){ print(&#39;fizzbuzz&#39;) } else if (x %% 3 == 0) { print(&#39;fizz&#39;) } else if (x %% 5 == 0) { print(&#39;buzz&#39;) } else { print(x) } } fizzbuzz(15) ## [1] &quot;fizzbuzz&quot; 4 - How could you use cut() to simplify this set of nested if-else statements? if (temp &lt;= 0) { &quot;freezing&quot; } else if (temp &lt;= 10) { &quot;cold&quot; } else if (temp &lt;= 20) { &quot;cool&quot; } else if (temp &lt;= 30) { &quot;warm&quot; } else { &quot;hot&quot; } classify_temp &lt;- function(x){ cut(x, breaks = c(-Inf,0,10,20,30,Inf), labels = c(&#39;freezing&#39;,&#39;cold&#39;,&#39;cool&#39;,&#39;warm&#39;,&#39;hot&#39;)) } classify_temp(c(-10,0,15,25,30,35)) ## [1] freezing freezing cool warm warm hot ## Levels: freezing cold cool warm hot 4 - How would you change the call to cut() if I’d used &lt; instead of &lt;=? What is the other chief advantage of cut() for this problem? (Hint: what happens if you have many values in temp?) If &lt; is used instead of &lt;=, the arguemnt right = FALSE can be added to indicate the intervales should be closed on the left. The advantagne of using cut() is that the operation can be vectorized. 5 - What happens if you use switch() with numeric values? If if use switch() with numeric values, it will look for the ith option: switch(1, &#39;one&#39;, &#39;two&#39;) switch(2, &#39;one&#39;, &#39;two&#39;) ## [1] &quot;two&quot; 6 - What does this switch() call do? What happens if x is “e”? This switch() returns ab if x is equal to a or b, and returns cd if x is equal to c or d. Since no expression is define what value should be returned if x is e, it returns nothing. x &lt;- &#39;a&#39; switch(x, a = , b = &quot;ab&quot;, c = , d = &quot;cd&quot; ) 19.5 Function arguments 19.5.1 Exercises 1 - What does commas(letters, collapse = &quot;-&quot;) do? Why? commas &lt;- function(..., collapse = &#39;, &#39;) { stringr::str_c(..., collapse = collapse) } commas(letters, collapse = &quot;-&quot;) ## [1] &quot;a-b-c-d-e-f-g-h-i-j-k-l-m-n-o-p-q-r-s-t-u-v-w-x-y-z&quot; I don’t know if it was intentional or not, but we should define an additional argument that allows users to specify the collapse character. The default collapse character is “,”. commas(letters, collapse = &quot;-&quot;) will change the collapse character to “-”. 2 - It’d be nice if you could supply multiple characters to the pad argument, e.g. rule(&quot;Title&quot;, pad = &quot;-+&quot;). Why doesn’t this currently work? How could you fix it? rule &lt;- function(..., pad = &quot;-&quot;) { title &lt;- paste0(...) width &lt;- getOption(&quot;width&quot;) - nchar(title) - 5 cat(title, &quot; &quot;, stringr::str_dup(pad, width), &quot;\\n&quot;, sep = &quot;&quot;) } rule(&quot;Title&quot;, pad = &quot;-+*&quot;) ## Title -+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+*-+* Not sure what it means by it does not currectly work. It works for me. 3 - What does the trim argument to mean() do? When might you use it? The trim method excludes a fraction of observations from the calculation of the mean. It would be useful if the vector is ordered and contains outliers at either end. 4 - The default value for the method argument to cor() is c(&quot;pearson&quot;, &quot;kendall&quot;, &quot;spearman&quot;). What does that mean? What value is used by default? It means that the method argument can take on one of those values. “pearson” is the default value. 19.6 Return values No exercises. 19.7 Environment No exercises. "],
["vectors.html", "20 Vectors 20.1 Introduction 20.2 Vector basics 20.3 Important types of atomic vector 20.4 Using atomic vectors 20.5 Recursive vectors (lists) 20.6 Attributes 20.7 Augmented vectors", " 20 Vectors 20.1 Introduction No exercises. 20.2 Vector basics No exercises. 20.3 Important types of atomic vector 20.3.1 Exercises library(tidyverse) 1 - Describe the difference between is.finite(x) and !is.infinite(x). is.finite(x) returns TRUE if x is a finite value, hence not NA, NaN, or Inf. is.finite(c(123, NA, NaN, Inf)) ## [1] TRUE FALSE FALSE FALSE is.infinite(x) returns TRUE if x is either Inf or -Inf. The ! at the front means ‘not’, and changes the return value from TRUE to FALSE, or vice verse. !is.infinite(c(123, NA, NaN, Inf)) ## [1] TRUE TRUE TRUE FALSE 2 - Read the source code for dplyr::near() (Hint: to see the source code, drop the ()). How does it work? function (x, y, tol = .Machine$double.eps^0.5) { abs(x - y) &lt; tol } .Machine$double.eps^0.5 is equal to 1.490116e-08. If the absolute difference between x and y is less than 1.490116e-08, then x and y are esentially equal, and the function returns TRUE. 3 - A logical vector can take 3 possible values. How many possible values can an integer vector take? How many possible values can a double take? Use google to do some research. The largest possible integer is: .Machine$integer.max ## [1] 2147483647 Including negative integers, zero, and NA, the number of possible values an integer vector can take is: .Machine$integer.max * 2 + 1 + 1 ## [1] 4294967296 .Machine$double.xmax ## [1] 1.797693e+308 4 - Brainstorm at least four functions that allow you to convert a double to an integer. How do they differ? Be precise. as.integer() removes the decimal points and converts the type to integer: as.integer(11.23) ## [1] 11 as.integer(-11.23) ## [1] -11 typeof(as.integer(11.23)) ## [1] &quot;integer&quot; floor() removes the decimal points and returns the largest integer not greater than the input values. However, the type of the value returned is double: floor(11.23) ## [1] 11 floor(-11.23) ## [1] -12 typeof(floor(11.23)) ## [1] &quot;double&quot; trunc() removes the decimal points and truncates the values toward 0. The returned value is double: trunc(11.23) ## [1] 11 trunc(-11.23) ## [1] -11 typeof(trunc(11.23)) ## [1] &quot;double&quot; There are also ceiling(), round(), and signif() that removes the decimal places and returns an integer. However, only as.integer() truly returns a value of type integer. 5 - What functions from the readr package allow you to turn a string into logical, integer, and double vector? parse_logical(), parse_integer(), and parse_double(). 20.4 Using atomic vectors 20.4.1 Exercises 1 - What does mean(is.na(x)) tell you about a vector x? What about sum(!is.finite(x))? mean(is.na(x)) tells you the proportion of values in a vector that are NA: x &lt;- c(1,2,3,4,NA,NA, Inf) mean(is.na(x)) ## [1] 0.2857143 sum(!is.finite(x)) tells you the number of non-finite values in a vector: x &lt;- c(1,2,3,4,NA,NA, Inf) sum(!is.finite(x)) ## [1] 3 2 - Carefully read the documentation of is.vector(). What does it actually test for? Why does is.atomic() not agree with the definition of atomic vectors above? is.atomic() does one simply job only, and that is the test whether the vector is an atomic vector: is.atomic(c(1,2,3,4)) ## [1] TRUE is.atomic(c(&quot;Am&quot;, &quot;I&quot;, &quot;atomic?&quot;)) ## [1] TRUE is.vector() returns TRUE only if the vector has no attributes other than names: #vector with no attributes x &lt;- c(1,2,3,4) #vector with names attribute y &lt;- c(x = 1, y = 2, z = 3, zz = 4) #vector with two attributes: names and awesome z &lt;- c(x = 1, y = 2, z = 3, zz = 4) attr(z, &quot;awesome&quot;) &lt;- &quot;extreme&quot; is.vector(x) ## [1] TRUE is.vector(y) ## [1] TRUE is.vector(z) ## [1] FALSE 3 - Compare and contrast setNames() with purrr::set_names() In setNames(), you must provide the vector to be named and the vector of names. In purrr::set_names(), three things can happen. You can provide the vector to be named and the vector of names, just like in setNames(). purrr::set_names(c(1,2,3), c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)) ## a b c ## 1 2 3 If the vector of names is not provided, the input vector is named after itself: purrr::set_names(c(1,2,3)) ## 1 2 3 ## 1 2 3 If the input vector is already named, a function can be provided to transform the original names: purrr::set_names(c(x = 1, y = 2, z = 3), toupper) ## X Y Z ## 1 2 3 4. Create functions that take a vector as input and returns: The last value. Should you use [ or [[? Using [[ will ensure the last value will be returned even input vector is a list. fun1 &lt;- function(x) { x[[length(x)]] } fun1(c(1,2,3,4,5)) ## [1] 5 The elements at even numbered positions. fun2 &lt;- function(x) { x[seq_len(length(x)) %% 2 == 0] } fun2(c(1:10)) ## [1] 2 4 6 8 10 Every element except the last value. fun3 &lt;- function(x){ x[1:length(x) - 1] } fun3(1:10) ## [1] 1 2 3 4 5 6 7 8 9 Only even numbers (and no missing values). fun4 &lt;- function(x){ iseven &lt;- x %% 2 == 0 nonNA &lt;- !is.na(x) x[iseven &amp; nonNA] } fun4(c(1:10, NA, NA, 11:16)) ## [1] 2 4 6 8 10 12 14 16 20.5 Recursive vectors (lists) 20.5.1 Exercise 1. Draw the following lists as nested sets: list(a, b, list(c, d), list(e, f)) list(list(list(list(list(list(a)))))) 2. What happens if you subset a tibble as if you’re subsetting a list? What are the key differences between a list and a tibble? Subsetting a tibble with [ will return a tibble: tblmtcars &lt;- as.tibble(mtcars) tblmtcars[&#39;cyl&#39;] ## # A tibble: 32 x 1 ## cyl ## &lt;dbl&gt; ## 1 6.00 ## 2 6.00 ## 3 4.00 ## 4 6.00 ## 5 8.00 ## 6 6.00 ## 7 8.00 ## 8 4.00 ## 9 4.00 ## 10 6.00 ## # ... with 22 more rows and [[ will return a vector: tblmtcars[[&#39;cyl&#39;]] ## [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4 Which is very similiar to subsetting in lists. ([ returns a list, and [[ returns a value inside the list) 20.6 Attributes No exercises. 20.7 Augmented vectors 1. What does hms::hms(3600) return? How does it print? What primitive type is the augmented vector built on top of? What attributes does it use? hms::hms(3600) returns the time in the format “hours:minutes:seconds”. hms::hms(3600) ## 01:00:00 It is stored as a double, and the attributes are: attributes(hms::hms(3600)) ## $units ## [1] &quot;secs&quot; ## ## $class ## [1] &quot;hms&quot; &quot;difftime&quot; 2. Try and make a tibble that has columns with different lengths. What happens? If the column has length of 1, it will be repeated: tibble(x = 1:6, y = 1) ## # A tibble: 6 x 2 ## x y ## &lt;int&gt; &lt;dbl&gt; ## 1 1 1.00 ## 2 2 1.00 ## 3 3 1.00 ## 4 4 1.00 ## 5 5 1.00 ## 6 6 1.00 Otherwise, if the columns are of different lengths, the shorter column will not be repeated and it will return an error: &gt; tibble(x = 1:6, y = 1:2) # Error: Column `y` must be length 1 or 6, not 2 3. Based on the definition above, is it ok to have a list as a column of a tibble? A list can have vectors of varying lengths, while a tibble must consist of columns of the same length. As long as the elements of the lists have the same length, otherwise it is not okay to have a list as a column of a tibble. "],
["iteration.html", "21 Iteration 21.1 Introduction 21.2 For loops 21.3 For loop variations 21.4 For loops vs. functionals 21.5 The map functions 21.6 Dealing with failure 21.7 Mapping over multiple arguments 21.8 Walk 21.9 Other patterns of for loops", " 21 Iteration 21.1 Introduction No exercises. 21.2 For loops 21.2.1 Exercises library(tidyverse) 1. Write for loops to: Compute the mean of every column in mtcars. for (i in seq_along(mtcars)){ print(paste(&quot;Mean of&quot;, colnames(mtcars)[i], &quot;:&quot;, mean(mtcars[,i]))) } ## [1] &quot;Mean of mpg : 20.090625&quot; ## [1] &quot;Mean of cyl : 6.1875&quot; ## [1] &quot;Mean of disp : 230.721875&quot; ## [1] &quot;Mean of hp : 146.6875&quot; ## [1] &quot;Mean of drat : 3.5965625&quot; ## [1] &quot;Mean of wt : 3.21725&quot; ## [1] &quot;Mean of qsec : 17.84875&quot; ## [1] &quot;Mean of vs : 0.4375&quot; ## [1] &quot;Mean of am : 0.40625&quot; ## [1] &quot;Mean of gear : 3.6875&quot; ## [1] &quot;Mean of carb : 2.8125&quot; Determine the type of each column in nycflights13::flights. for (i in seq_along(nycflights13::flights)){ print(paste(colnames(nycflights13::flights)[i], &quot;:&quot;, typeof(nycflights13::flights[[i]]))) } ## [1] &quot;year : integer&quot; ## [1] &quot;month : integer&quot; ## [1] &quot;day : integer&quot; ## [1] &quot;dep_time : integer&quot; ## [1] &quot;sched_dep_time : integer&quot; ## [1] &quot;dep_delay : double&quot; ## [1] &quot;arr_time : integer&quot; ## [1] &quot;sched_arr_time : integer&quot; ## [1] &quot;arr_delay : double&quot; ## [1] &quot;carrier : character&quot; ## [1] &quot;flight : integer&quot; ## [1] &quot;tailnum : character&quot; ## [1] &quot;origin : character&quot; ## [1] &quot;dest : character&quot; ## [1] &quot;air_time : double&quot; ## [1] &quot;distance : double&quot; ## [1] &quot;hour : double&quot; ## [1] &quot;minute : double&quot; ## [1] &quot;time_hour : double&quot; Compute the number of unique values in each column of iris. for (i in seq_along(iris)){ print(paste(&quot;Number of unique values in&quot;, colnames(iris)[i], &quot;:&quot;, length(unique(iris[[i]])))) } ## [1] &quot;Number of unique values in Sepal.Length : 35&quot; ## [1] &quot;Number of unique values in Sepal.Width : 23&quot; ## [1] &quot;Number of unique values in Petal.Length : 43&quot; ## [1] &quot;Number of unique values in Petal.Width : 22&quot; ## [1] &quot;Number of unique values in Species : 3&quot; Generate 10 random normals for each of mean = -10, 0, 10, 100. normal_means &lt;- c(-10, 0, 10, 100) for (i in seq_along(normal_means)){ print(paste(&quot;mean:&quot;, normal_means[i])) print(rnorm(n = 10, mean = normal_means[i], sd = 1)) } ## [1] &quot;mean: -10&quot; ## [1] -10.563361 -11.547105 -9.610006 -10.858433 -9.490059 -7.914735 ## [7] -8.990751 -9.686510 -9.093097 -9.651672 ## [1] &quot;mean: 0&quot; ## [1] -1.33475894 1.17713077 -0.10370554 0.97529669 1.04746760 ## [6] 0.09859368 1.48150980 0.16286577 -0.47510215 -2.18748446 ## [1] &quot;mean: 10&quot; ## [1] 9.745161 10.866080 10.357796 9.209245 11.428380 9.668677 10.087604 ## [8] 9.033929 10.788375 11.936990 ## [1] &quot;mean: 100&quot; ## [1] 100.72270 99.32493 99.66521 99.72944 99.46105 99.84259 100.85896 ## [8] 98.57499 100.40620 98.81463 2. Eliminate the for loop in each of the following examples by taking advantage of an existing function that works with vectors: out &lt;- &quot;&quot; for (x in letters) { out &lt;- stringr::str_c(out, x) } is the same as: stringr::str_c(letters, collapse = &quot;&quot;) x &lt;- sample(100) sd &lt;- 0 for (i in seq_along(x)) { sd &lt;- sd + (x[i] - mean(x)) ^ 2 } sd &lt;- sqrt(sd / (length(x) - 1)) is the same as: x &lt;- sample(100) sd(x) x &lt;- runif(100) out &lt;- vector(&quot;numeric&quot;, length(x)) out[1] &lt;- x[1] for (i in 2:length(x)) { out[i] &lt;- out[i - 1] + x[i] } is the same as: cumsum(x) 3. Combine your function writing and for loop skills: Write a for loop that prints() the lyrics to the children’s song “Alice the camel”. alice_the_camel &lt;- function(x){ for (i in x:0){ if (i &gt;= 2){ writeLines(rep(paste(&quot;Alice the camel has&quot;, i, &quot;humps.&quot;), 3)) } else if (i == 1){ writeLines(rep(paste(&quot;Alice the camel has&quot;, i, &quot;hump.&quot;), 3)) } else { writeLines(rep(&quot;Alice the camel has no humps.&quot;, 3)) } if (i &gt;= 1){ writeLines(&quot;So go, Alice, go.\\n&quot;) } else { writeLines(&quot;Now Alice is a horse&quot;) } } } alice_the_camel(5) ## Alice the camel has 5 humps. ## Alice the camel has 5 humps. ## Alice the camel has 5 humps. ## So go, Alice, go. ## ## Alice the camel has 4 humps. ## Alice the camel has 4 humps. ## Alice the camel has 4 humps. ## So go, Alice, go. ## ## Alice the camel has 3 humps. ## Alice the camel has 3 humps. ## Alice the camel has 3 humps. ## So go, Alice, go. ## ## Alice the camel has 2 humps. ## Alice the camel has 2 humps. ## Alice the camel has 2 humps. ## So go, Alice, go. ## ## Alice the camel has 1 hump. ## Alice the camel has 1 hump. ## Alice the camel has 1 hump. ## So go, Alice, go. ## ## Alice the camel has no humps. ## Alice the camel has no humps. ## Alice the camel has no humps. ## Now Alice is a horse Convert the nursery rhyme “ten in the bed” to a function. Generalise it to any number of people in any sleeping structure. ten_in_the_bed &lt;- function(x){ for (i in x:1){ writeLines(paste(&quot;There were&quot;, i, &quot;in the bed&quot;)) writeLines(&quot;And the little one said,&quot;) if (i &gt;= 2){ writeLines(&quot;\\&quot;Roll over! Roll over!\\&quot;&quot;) writeLines(&quot;So they all rolled over and one fell out\\n&quot;) } else { writeLines(&quot;\\&quot;Alone at last!\\&quot;&quot;) } } } ten_in_the_bed(5) ## There were 5 in the bed ## And the little one said, ## &quot;Roll over! Roll over!&quot; ## So they all rolled over and one fell out ## ## There were 4 in the bed ## And the little one said, ## &quot;Roll over! Roll over!&quot; ## So they all rolled over and one fell out ## ## There were 3 in the bed ## And the little one said, ## &quot;Roll over! Roll over!&quot; ## So they all rolled over and one fell out ## ## There were 2 in the bed ## And the little one said, ## &quot;Roll over! Roll over!&quot; ## So they all rolled over and one fell out ## ## There were 1 in the bed ## And the little one said, ## &quot;Alone at last!&quot; Convert the song “99 bottles of beer on the wall” to a function. Generalise to any number of any vessel containing any liquid on any surface. beer &lt;- function(x){ for (i in x:0){ if (i &gt;= 2){ writeLines(paste(i, &quot;bottles of beer on the wall,&quot; ,i, &quot;bottles of beer.&quot;)) } else if (i == 1){ writeLines(&quot;1 bottle of beer on the wall, 1 bottle of beer.&quot;) } else { writeLines(&quot;No more bottles of beer on the wall, no more bottles of beer.&quot;) } if (i - 1 &gt;= 2){ writeLines(paste(&quot;Take one down and pass it around,&quot;, i - 1, &quot;bottles of beer on the wall.\\n&quot;)) } else if (i - 1 == 1){ writeLines(&quot;Take one down and pass it around, 1 bottle of beer on the wall.\\n&quot;) } else if (i - 1 == 0){ writeLines(&quot;Take one down and pass it around, no more bottles of beer on the wall.\\n&quot;) } else{ writeLines(paste(&quot;Go to the store and buy some more,&quot;, x, &quot;bottles of beer on the wall.&quot;)) } } } beer(5) ## 5 bottles of beer on the wall, 5 bottles of beer. ## Take one down and pass it around, 4 bottles of beer on the wall. ## ## 4 bottles of beer on the wall, 4 bottles of beer. ## Take one down and pass it around, 3 bottles of beer on the wall. ## ## 3 bottles of beer on the wall, 3 bottles of beer. ## Take one down and pass it around, 2 bottles of beer on the wall. ## ## 2 bottles of beer on the wall, 2 bottles of beer. ## Take one down and pass it around, 1 bottle of beer on the wall. ## ## 1 bottle of beer on the wall, 1 bottle of beer. ## Take one down and pass it around, no more bottles of beer on the wall. ## ## No more bottles of beer on the wall, no more bottles of beer. ## Go to the store and buy some more, 5 bottles of beer on the wall. 4. It’s common to see for loops that don’t preallocate the output and instead increase the length of a vector at each step: output &lt;- vector(&quot;integer&quot;, 0) for (i in seq_along(x)) { output &lt;- c(output, lengths(x[[i]])) } output How does this affect performance? Design and execute an experiment. As pointed in the text in late section, this is not very efficient because in each iteration, R has to copy all the data from the previous iterations. Instead, create an empty list, store the values in the list, and flatten the list to a vector with unlist() at the end. output &lt;- vector(&quot;list&quot;, length(x)) for (i in seq_along(x)) { output[[i]] &lt;- lengths(x[[i]]) } unlist(output) To Do. 21.3 For loop variations 21.3.1 Exercises 1. Imagine you have a directory full of CSV files that you want to read in. You have their paths in a vector, files &lt;- dir(&quot;data/&quot;, pattern = &quot;\\\\.csv$&quot;, full.names = TRUE), and now want to read each one with read_csv(). Write the for loop that will load them into a single data frame. files &lt;- dir(&quot;data/&quot;, pattern = &quot;\\\\.csv$&quot;, full.names = TRUE) csv_list &lt;- vector(&quot;list&quot;, length(files)) for (i in seq_along(files)){ csv_list[[i]] &lt;- read.csv(files[i]) } dplyr::bind_rows(csv_list) 2. What happens if you use for (nm in names(x)) and x has no names? What if only some of the elements are named? What if the names are not unique? If x has no names: x &lt;- c(1:10) for (nm in names(x)){ print(nm) } Nothing is printed, since names(x) returns NULL, the for loop does not run. If only some of the elements are named: x &lt;- c(&quot;a&quot; = 1, 2, 3, &quot;d&quot; = 4) for (nm in names(x)){ print(nm) } ## [1] &quot;a&quot; ## [1] &quot;&quot; ## [1] &quot;&quot; ## [1] &quot;d&quot; The unnamed elements are given an empty character, and the number of iterations is equal to the length of the vector. If the vector has non-unique names: x &lt;- setNames(1:4, c(&quot;a&quot;,&quot;b&quot;,&quot;b&quot;,&quot;c&quot;)) for (nm in names(x)){ print(nm) } ## [1] &quot;a&quot; ## [1] &quot;b&quot; ## [1] &quot;b&quot; ## [1] &quot;c&quot; Again, the number of iterations is equal to the length of the vector. 3. Write a function that prints the mean of each numeric column in a data frame, along with its name. For example, show_mean(iris) would print: show_mean(iris) #&gt; Sepal.Length: 5.84 #&gt; Sepal.Width: 3.06 #&gt; Petal.Length: 3.76 #&gt; Petal.Width: 1.20 (Extra challenge: what function did I use to make sure that the numbers lined up nicely, even though the variable names had different lengths?) show_mean &lt;- function(df){ #empty vectors to store variable names and means start_sentence &lt;- vector(&#39;character&#39;, ncol(df)) col_means &lt;- vector(&#39;double&#39;, ncol(df)) #get names and means for (i in seq_len(ncol(df))){ start_sentence[i] &lt;- paste0(names(df)[i], &quot;:&quot;) col_means[i] &lt;- round(mean(df[[i]]),2) } #get max length of names and pad the shorter names start_sentence &lt;- stringr::str_pad(start_sentence, max(nchar(start_sentence)), side = &quot;right&quot;, pad = &quot; &quot;) #writeLines writeLines(paste(start_sentence, col_means)) } show_mean(mtcars) ## mpg: 20.09 ## cyl: 6.19 ## disp: 230.72 ## hp: 146.69 ## drat: 3.6 ## wt: 3.22 ## qsec: 17.85 ## vs: 0.44 ## am: 0.41 ## gear: 3.69 ## carb: 2.81 4. What does this code do? How does it work? trans &lt;- list( disp = function(x) x * 0.0163871, am = function(x) { factor(x, labels = c(&quot;auto&quot;, &quot;manual&quot;)) } ) for (var in names(trans)) { mtcars[[var]] &lt;- trans[[var]](mtcars[[var]]) } A list can be used to store functions. The list trans stores two functions: disp to multiply the numerical values by a constant, and am creates a factor of two levels. The for loop runs through the names in the list trans (in this case, only disp and am), then call the appropriate function, converts the values in the column and saves it. 21.4 For loops vs. functionals 21.4.1 Exercises 1. Read the documentation for apply(). In the 2d case, what two for loops does it generalise? By rows and by columns. 2. Adapt col_summary() so that it only applies to numeric columns. You might want to start with an is_numeric() function that returns a logical vector that has a TRUE corresponding to each numeric column. col_summary &lt;- function(df, fun){ df2 &lt;- df[,sapply(df, is.numeric)] start_sentence &lt;- vector(&#39;character&#39;, ncol(df2)) col_means &lt;- vector(&#39;double&#39;, ncol(df2)) #get names and means for (i in seq_len(ncol(df2))){ start_sentence[i] &lt;- paste0(names(df2)[i], &quot;:&quot;) col_means[i] &lt;- round(fun(df2[[i]]),2) } #get max length of names and pad the shorter names start_sentence &lt;- stringr::str_pad(start_sentence, max(nchar(start_sentence)), side = &quot;right&quot;, pad = &quot; &quot;) #writeLines writeLines(paste(start_sentence, col_means)) } col_summary(iris, mean) ## Sepal.Length: 5.84 ## Sepal.Width: 3.06 ## Petal.Length: 3.76 ## Petal.Width: 1.2 21.5 The map functions 21.5.1 Exercises 1. Write code that uses one of the map functions to: Compute the mean of every column in mtcars. map_dbl(mtcars, mean) %&gt;% round(2) ## mpg cyl disp hp drat wt qsec vs am gear ## 20.09 6.19 230.72 146.69 3.60 3.22 17.85 0.44 0.41 3.69 ## carb ## 2.81 Determine the type of each column in nycflights13::flights. map_chr(nycflights13::flights, typeof) ## year month day dep_time sched_dep_time ## &quot;integer&quot; &quot;integer&quot; &quot;integer&quot; &quot;integer&quot; &quot;integer&quot; ## dep_delay arr_time sched_arr_time arr_delay carrier ## &quot;double&quot; &quot;integer&quot; &quot;integer&quot; &quot;double&quot; &quot;character&quot; ## flight tailnum origin dest air_time ## &quot;integer&quot; &quot;character&quot; &quot;character&quot; &quot;character&quot; &quot;double&quot; ## distance hour minute time_hour ## &quot;double&quot; &quot;double&quot; &quot;double&quot; &quot;double&quot; Compute the number of unique values in each column of iris. map_int(iris, dplyr::n_distinct) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 35 23 43 22 3 Generate 10 random normals for each of mean = -10, 0, 10, 100 r_means &lt;- c(-10, 0, 10, 100) purrr::map(r_means, rnorm, n = 10) ## [[1]] ## [1] -9.439750 -8.803203 -11.033268 -8.932672 -10.200627 -9.910421 ## [7] -10.013396 -10.490332 -10.948487 -9.757642 ## ## [[2]] ## [1] -0.5364204 1.4800243 -0.7883756 -1.0642365 -0.1955066 -0.4340894 ## [7] -0.1565100 1.3706622 -1.1438224 -0.1054658 ## ## [[3]] ## [1] 9.420518 10.631077 9.986825 10.452168 7.210611 10.360478 10.445818 ## [8] 9.250952 11.334013 10.488257 ## ## [[4]] ## [1] 101.05380 99.10756 99.24149 101.22868 100.70151 100.12729 101.41284 ## [8] 100.78254 101.19970 102.00230 2. How can you create a single vector that for each column in a data frame indicates whether or not it’s a factor? map_lgl(mtcars, is.factor) ## mpg cyl disp hp drat wt qsec vs am gear carb ## FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE 3. What happens when you use the map functions on vectors that aren’t lists? What does map(1:5, runif) do? Why? purrr::map(1:5, runif) ## [[1]] ## [1] 0.2212084 ## ## [[2]] ## [1] 0.004146634 0.928893832 ## ## [[3]] ## [1] 0.9507205 0.2135208 0.8999193 ## ## [[4]] ## [1] 0.5345054 0.6522360 0.8355621 0.3297500 ## ## [[5]] ## [1] 0.396253151 0.367061472 0.004636787 0.290923828 0.312653029 It applies the function on each element in the vector. map(1:5, runif) applies the function runif() on 1, 2, 3, 4, and 5 individual, and return the results in a list (of length of 5). 4. What does map(-2:2, rnorm, n = 5) do? Why? What does map_dbl(-2:2, rnorm, n = 5) do? Why? purrr::map(-2:2, rnorm, n = 5) ## [[1]] ## [1] -2.4413302 -1.5927285 -2.5425904 -1.5266702 -0.3473109 ## ## [[2]] ## [1] -1.503954 -1.283089 -0.306981 -1.252188 -2.619766 ## ## [[3]] ## [1] 0.1844547 1.0780249 0.8851634 0.8101881 0.2684200 ## ## [[4]] ## [1] 0.4162352 0.5131799 -1.1057388 0.6057158 0.7301846 ## ## [[5]] ## [1] 0.06345205 1.29128753 3.25939610 2.38084050 1.33280825 map(-2:2, rnorm, n = 5) applies the function rnorm(), with the argument n = 5 on each of the element in -2:2. rnorm() treats -2:2 as the input for its first remaining argument by position, which is the mean of the normal distribution. The function returns a list. &gt; map_dbl(-2:2, rnorm, n = 5) #Error: Result 1 is not a length 1 atomic vector map_dbl(-2:2, rnorm, n = 5) will not work because map_dbl returns an atomic vector. Each element can only store value of length of 1. If we change n = 5 to n = 1: map_dbl(-2:2, rnorm, n = 1) ## [1] -3.1958272 -1.3122468 -0.5312978 2.4671638 0.6778924 Then it will work. 5. Rewrite map(x, function(df) lm(mpg ~ wt, data = df)) to eliminate the anonymous function. purrr::map(list(mtcars), ~lm(mpg ~ wt, data = .)) ## [[1]] ## ## Call: ## lm(formula = mpg ~ wt, data = .) ## ## Coefficients: ## (Intercept) wt ## 37.285 -5.344 21.6 Dealing with failure No exercises. 21.7 Mapping over multiple arguments No exercises. 21.8 Walk No exercises 21.9 Other patterns of for loops 21.9.1 Exercises 1. Implement your own version of every() using a for loop. Compare it with purrr::every(). What does purrr’s version do that your version doesn’t? my_every &lt;- function(x, .p){ check &lt;- sapply(x, .p) if (mean(check) == 1){ return(TRUE) } else { return(FALSE) } } my_every(mtcars, is.numeric) ## [1] TRUE 2. Create an enhanced col_sum() that applies a summary function to every numeric column in a data frame. col_sum &lt;- function(df){ df &lt;- keep(df, is.numeric) return(purrr::map(df, summary)) } col_sum(iris) ## $Sepal.Length ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 4.300 5.100 5.800 5.843 6.400 7.900 ## ## $Sepal.Width ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 2.000 2.800 3.000 3.057 3.300 4.400 ## ## $Petal.Length ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.000 1.600 4.350 3.758 5.100 6.900 ## ## $Petal.Width ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.100 0.300 1.300 1.199 1.800 2.500 3. A possible base R equivalent of col_sum() is: col_sum3 &lt;- function(df, f) { is_num &lt;- sapply(df, is.numeric) df_num &lt;- df[, is_num] sapply(df_num, f) } But it has a number of bugs as illustrated with the following inputs: df &lt;- tibble( x = 1:3, y = 3:1, z = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) ) # OK col_sum3(df, mean) # Has problems: don&#39;t always return numeric vector col_sum3(df[1:2], mean) col_sum3(df[1], mean) col_sum3(df[0], mean) What causes the bugs? The function fails if the filtered data frame has zero columns. Here is a modified version of col_num3() that will prevent the problem: col_sum3 &lt;- function(df, f) { is_num &lt;- sapply(df, is.numeric) if (sum(is_num) &gt;= 1){ df_num &lt;- df[, is_num] sapply(df_num, f) } else{ NULL } } "],
["introduction-17.html", "22 Introduction", " 22 Introduction No exercises. "]
]
